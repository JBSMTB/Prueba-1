{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "import numpy as np\n",
    "import json\n",
    "import gc\n",
    "import urllib\n",
    "import sys\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "import geoviews.tile_sources as gts\n",
    "from cartopy import crs\n",
    "from geoviews import opts\n",
    "import geoviews as gv\n",
    "import datashader as ds\n",
    "from holoviews.operation.datashader import rasterize, shade, spread\n",
    "import dask.dataframe as dd\n",
    "import multiprocessing as mp\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from bokeh.plotting import figure, curdoc\n",
    "from bokeh.models import Row,ColumnDataSource\n",
    "from bokeh.layouts import layout\n",
    "from bokeh.application.handlers import FunctionHandler\n",
    "# from bokeh.resources import CDN\n",
    "# from bokeh.embed import file_html, components\n",
    "# from bokeh.io import show, output_notebook\n",
    "from tornado.web import Application, RequestHandler\n",
    "from bokeh.server.server import Server\n",
    "import panel as pn\n",
    "from bokeh.palettes import brewer\n",
    "from bokeh.models import GeoJSONDataSource, LinearColorMapper, ColorBar\n",
    "import bokeh, bokeh.plotting, bokeh.models\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "from colorcet import cm_n\n",
    "import param , parambokeh, paramnb\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from requests_negotiate_sspi import HttpNegotiateAuth\n",
    "\n",
    "from holoviews.operation.datashader import aggregate\n",
    "\n",
    "from pysal.viz import mapclassify as mc\n",
    "import pysal.lib as libpysal\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import NearestNeighbors \n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import pysal.lib.weights as lp\n",
    "\n",
    "import seaborn as sns\n",
    "#para instalar hvplot tngo que rebajar la version de holoviews, de momento no lo hago, seria asi:\n",
    "#conda install holoviews=1.11\n",
    "#import hvplot\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "gv.extension('bokeh',  'matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL=\"\"\"SELECT *  FROM PROVEEDOR.PRVCUAMED  WHERE PCMRCD IN (1 , 2) AND PCMLPR=50\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bCalculate=0\n",
    "bRestauraconXls=0\n",
    "bObtieneFactu=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn=None\n",
    "\n",
    "if cnxn:\n",
    "    cnxn.close()\n",
    "    \n",
    "cnxn = pyodbc.connect(\"dsn=PRODUCCION\",UID=\"JAVIERBS\",PWD=\"ANASERJBS123456\")\n",
    "\n",
    "\n",
    "datos_cm= pd.read_sql(SQL,cnxn)\n",
    "datos_cm=datos_cm.loc[ (datos_cm['PCMNPR'] != 'PRUEBAS')]\n",
    "datos_cm.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bObtieneFactu==1:\n",
    "    try:\n",
    "        if not cnxn:\n",
    "            cnxn = pyodbc.connect(\"dsn=PRODUCCION\",UID=\"JAVIERBS\",PWD=\"ANASERJBS123456\")\n",
    "\n",
    "        SQL_FACTU=\"\"\"SELECT PPSIUN, SUM(ACQIMP)  / COUNT( DISTINCT ((ACQFCA*100) + ACQFCM))  AS facturacion_mensual \n",
    "        , COUNT(DISTINCT ACQDEL CONCAT ACQOFN CONCAT ACQRAM CONCAT ACQPOL CONCAT ACQORD CONCAT ACQBEF) AS AAT\n",
    "        , SUM(ACQACT) AS ACTOS\n",
    "        FROM (SELECT * FROM QS36F.ACUCHEQAC UNION SELECT * FROM QS36F.ACUCHEQ18) T1 \n",
    "        LEFT JOIN PROVEEDOR.PRVPTOSER T2 ON PPSSUC=ACQSUC AND PPSCIA=1 AND PPSFAC=ACQNFA AND PPSCEN=ACQDSR\n",
    "        WHERE ( DATE(ACQFCA CONCAT '-'  CONCAT ACQFCM CONCAT '-' CONCAT ACQFCD)<=\n",
    "             DATE(PPSABA CONCAT '-' CONCAT PPSMBA CONCAT '-' CONCAT PPSDBA) OR PPSABA=0 ) \n",
    "             AND DATE(ACQFCA CONCAT '-' CONCAT ACQFCM CONCAT '-' CONCAT ACQFCD)  <= LAST_DAY(CURRENT_DATE - 3 MONTHS)\n",
    "             AND PPSCIA=1 AND ACQSUC=50\n",
    "        GROUP BY PPSIUN\"\"\"\n",
    "\n",
    "\n",
    "        datos_factu= pd.read_sql(SQL_FACTU,cnxn)\n",
    "        \n",
    "        SQL_PRIMAS=\"\"\"SELECT T0.CODPER,  VALUE( SUBSTR(LPAD(  CURRENT_DATE - FECHA_NACIMIENTO , 6, '0'),1,2) , 30) AS EDAD_ASE,\n",
    "        COALESCE(T3.PRIIM1,0)*12  AS PRIMA_BENEFICIARIO_MUFACE,\n",
    "        (COALESCE(T3.PRIIM1,0)*12) + PRIMA_BENEFICIARIO AS PRIMA_RESULTANTE,\n",
    "         T1.* FROM CRM.CRMASE T1 \n",
    "        INNER JOIN CRM.CRMPER T0 ON T1.CODIGO_PERSONA = T0.CODIGO_PERSONA\n",
    "        INNER JOIN\n",
    "        (SELECT BENDEL, BENOFI, BENRAM, BENPOL, 0 AS ORDCOL, BENORD FROM QS36F.BENEFID WHERE BENDEL=50  --R000\n",
    "        UNION\n",
    "        SELECT SM2DEL, SM2OFI, SM2RAM, SM2POL, 0, SM2ORD   FROM QS36F.SGMU3002 WHERE SM2DEL=50  --R043\n",
    "        UNION\n",
    "        SELECT B41SUC, B41OFI, B41RAM, B41POL, B41ORD, B41BEN FROM QS36F.SGMU4002 WHERE B41SUC=50 --R041\n",
    "        UNION \n",
    "        SELECT B01SUC, B01OFI, B01RAM, B01POL, B01ORD, B01BEN FROM QS36F.MAECOL02 WHERE B01SUC=50--R001\n",
    "        UNION\n",
    "        SELECT MUTSUC, 0 , MUTRAM, MUTPOL, MUTORD, MUTORB FROM  QS36F.MUMPATIT WHERE MUTSUC=50--R005\n",
    "        UNION\n",
    "        SELECT MUBSUC, 0 , MUBRAM, MUBPOL, MUBORD, MUBORB FROM  QS36F.MUMPABEN WHERE MUBSUC=50--R005\n",
    "        UNION\n",
    "        SELECT SF2DEL, SF2OFI, SF2RAM, SF2POL,0, SF2NUM  FROM QS36F.SGFAM002 WHERE SF2DEL=50 --R100\n",
    "        UNION\n",
    "        SELECT FC2DEL, FC2OFI, FC2RAM, FC2POL, FC2ORP, FC2ORB FROM QS36F.SGFAC002 WHERE FC2DEL=50\n",
    "        UNION\n",
    "        SELECT SA2DEL, SA2OFN, SA2RAM, SA2POL, 0, SA2NUM  FROM QS36F.SGAUT002 WHERE SA2DEL=50 \n",
    "        UNION\n",
    "        SELECT MUFDEL, MUFOFN, 3,  SUBSTR(LPAD(MUFCL1, 10,'0') , 1,5) , SUBSTR( LPAD(MUFCL1, 10,'0') , 6,5) , 0  \n",
    "        FROM QS36F.MUFACE1\n",
    "        UNION\n",
    "        SELECT MUBDEL, MUBOFN, 3,  SUBSTR(LPAD(MUBCL1, 10,'0') , 1,5) , SUBSTR( LPAD(MUBCL1, 10,'0') , 6,5) , MUBCL2  \n",
    "        FROM QS36F.MUFACE2\n",
    "        UNION\n",
    "        SELECT MGJDEP, 0, 4, 2859, SUBSTR(MGJNMU, 5,5), MGJORD FROM QS36F.MUGEJU1 \n",
    "        UNION\n",
    "        SELECT MG2SUC, 0, 4, 2859, SUBSTR(MG2NMU, 5,5), MG2ORD FROM QS36F.MUGEJU2 \n",
    "        ) T2 (BENDEL, BENOFI, BENRAM, BENPOL,ORDCOL, BENORD)  ON T1.SUCURSAL=T2.BENDEL AND T1.OFICINA=T2.BENOFI \n",
    "        AND T1.RAMO=T2.BENRAM AND T1.NUMERO_POLIZA=T2.BENPOL AND T1.ORDEN_POLIZA=T2.ORDCOL \n",
    "        AND T1.ORDEN_BENEFICIARIO=T2.BENORD\n",
    "        LEFT JOIN  QS36F.PRICNAPF T3 \n",
    "            ON  CASE WHEN VALUE( SUBSTR(LPAD(  CURRENT_DATE - FECHA_NACIMIENTO , 6, '0'),1,2) , 30) > 99 THEN 99 \n",
    "                ELSE  VALUE( SUBSTR(LPAD(  CURRENT_DATE - FECHA_NACIMIENTO , 6, '0'),1,2) , 30) END = T3.PRIEDA \n",
    "                AND PRIANO=YEAR(CURRENT_DATE) AND T3.PRIRAM=T1.RAMO\n",
    "\n",
    "        \"\"\"\n",
    "        datos_primas= pd.read_sql(SQL_PRIMAS,cnxn)\n",
    "        #como antes utilize la PRIMA_BENEFICIARIO y en esta faltaba las primas de Muface, ahora reemplazo este\n",
    "        #valor con el vaor de PRIMA_RESULTANTE que incluye las primas de CCNN, asi no tengo necesidad de\n",
    "        #reemplazar el código\n",
    "        datos_primas['PRIMA_BENEFICIARIO']=datos_primas['PRIMA_RESULTANTE']\n",
    "        datos_primas['PRIBEN']=datos_primas['PRIMA_RESULTANTE']\n",
    "    except:\n",
    "        cnxn=None\n",
    "\n",
    "\n",
    "datos_primas.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def componeDireccion(df):\n",
    "    arrDir=[]\n",
    "    \n",
    "    for id, row in df.iterrows():\n",
    "        #print(row)\n",
    "        if pd.isnull(row['PCMDTP']): \n",
    "            tvia= ' ' \n",
    "        else: \n",
    "            tvia=str( row['PCMDTP'] )\n",
    "        \n",
    "        if pd.isnull(row['PCMDVI']): \n",
    "            via= ' ' \n",
    "        else: \n",
    "            via=str( row['PCMDVI'] )\n",
    "        \n",
    "        if pd.isnull(row['PCMDN1']): \n",
    "            num1= ' ' \n",
    "        else: \n",
    "            num1=str( row['PCMDN1'] )\n",
    "            \n",
    "        if pd.isnull(row['PCMDN2']): \n",
    "            num2= ' ' \n",
    "        else: \n",
    "            num2=str( row['PCMDN2'] )\n",
    "\n",
    "        if pd.isnull(row['PCMDRD']): \n",
    "            rdir= ' ' \n",
    "        else: \n",
    "            rdir=str( row['PCMDRD'] )\n",
    "            \n",
    "        if pd.isnull(row['PCMDLC']): \n",
    "            localidad= ' ' \n",
    "        else: \n",
    "            localidad=str( row['PCMDLC'] )\n",
    "        \n",
    "        try:\n",
    "            dir=tvia.strip() + ' ' + via.strip() + ' ' \\\n",
    "                                 + num1.strip()  + ' ' + num2.strip() + ' ' + rdir.strip() + ' ' + localidad.strip() +', Spain'\n",
    "            \n",
    "        except:\n",
    "            dir=None\n",
    "            pass\n",
    "        \n",
    "        arrDir.append(dir)\n",
    "        \n",
    "    return arrDir\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datos_cm.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (bRestauraconXls==1):\n",
    "#     datos_cm=pd.read_excel('datos_proveedores_cm_red_Muface_y_Privada_con_dircompleta.xlsx',sheet_name=\"Hoja1\" )\n",
    "#     datos_cm.head()\n",
    "\n",
    "# datos_cm=pd.read_excel('datos_proveedores_cm_red_Muface_y_Privada_con_dircompleta.xlsx',sheet_name=\"Sheet1\" )\n",
    "# datos_cm.head()\n",
    "# datos_cm=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# datos_cm['dircompleta']=componeDireccion(datos_cm) \n",
    "# datos_cm.to_excel('datos_proveedores_cm_red_Muface_y_Privada_con_dircompleta.xlsx')\n",
    "# datos_cm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps \n",
    "from urllib.error import HTTPError, URLError\n",
    "import socket\n",
    "\n",
    "gmaps = googlemaps.Client ( key = 'AIzaSyC5KU755KKzQsMw9dHkM2p5alN3AUjmUYA' )\n",
    "\n",
    "def GetCoordenadas(df ):\n",
    "    global gmaps\n",
    "    #gmaps = googlemaps.Client ( key = 'AIzaSyC5KU755KKzQsMw9dHkM2p5alN3AUjmUYA' )\n",
    "    #AIzaSyBKf_r6ZfZVw-06MAT2bRLQLCE0t3pzLz8\n",
    "    Coordenadas=[]\n",
    "    for n, row in df.iterrows():\n",
    "        geocode_result = gmaps.geocode(row['dircompleta'])\n",
    "        if geocode_result:\n",
    "            lng=geocode_result[0]['geometry']['location']['lng'] #.geometry.location\n",
    "            lat=geocode_result[0]['geometry']['location']['lat'] #.geometry.location\n",
    "        else:\n",
    "            lng=None\n",
    "            lat=None\n",
    "#         if tipo=='lng':\n",
    "#             Coordenadas.append(lng)\n",
    "#         else:\n",
    "#             Coordenadas.append(lat)\n",
    "        tupla=(lng,lat)\n",
    "        Coordenadas.append([lng, lat])\n",
    "    return Coordenadas\n",
    "\n",
    "#cambios en urllib\n",
    "#urllib.parse.urlencode(), and the urllib.urlopen() function is now urllib.request.urlopen().\n",
    "def GetCoordenadas_def(df):\n",
    "    global gmaps\n",
    "    #AIzaSyBKf_r6ZfZVw-06MAT2bRLQLCE0t3pzLz8\n",
    "    Coordenadas=[]\n",
    "    log=[]\n",
    "    time.sleep(.1)\n",
    "    prefix = 'https://maps.googleapis.com/maps/api/geocode/json?'\n",
    "   \n",
    "    \n",
    "    for n, row in df.iterrows():\n",
    "        data = urllib.parse.urlencode({\"address\" : row['dircompleta'], \"key\": \"AIzaSyC5KU755KKzQsMw9dHkM2p5alN3AUjmUYA\" })\n",
    "        url = prefix+data\n",
    "        #print(url)\n",
    "        try:\n",
    "            \n",
    "            gresp = urllib.request.urlopen(url , timeout=10)\n",
    "            jresp = json.loads(gresp.read())\n",
    "            if jresp['status'] == 'OK':\n",
    "                lat = jresp['results'][0]['geometry']['location']['lat']\n",
    "                lng = jresp['results'][0]['geometry']['location']['lng']\n",
    "                estado='OK'\n",
    "                #print (str(lat)+\"; \"+str(lng))\n",
    "                \n",
    "            else:\n",
    "                lat=None\n",
    "                lng=None\n",
    "                estado= jresp['status']\n",
    "                \n",
    "        except HTTPError as error:\n",
    "            lat=None\n",
    "            lng=None\n",
    "            estado= \"error request\"\n",
    "            \n",
    "            log.append ([row.index, 'Datos no devueltos por %s\\nURL: %s', error, url ])\n",
    "            \n",
    "        except URLError as error:\n",
    "            lat=None\n",
    "            lng=None\n",
    "            estado= \"error request\"\n",
    "            \n",
    "            if isinstance(error.reason, socket.timeout):\n",
    "                log.append([row.index, 'request error tiemout - URL %s', url ])\n",
    "            else:\n",
    "                log.append([row.index, 'ha ocurrido algún error'])\n",
    "        else:\n",
    "            log.append([row.index, 'OK'])\n",
    "        \n",
    "        \n",
    "        Coordenadas.append([lng, lat, estado])\n",
    "    return Coordenadas\n",
    "    \n",
    "# pbaCoord=datos_cm.iloc[0:50]\n",
    "# pbaCoord['lng'], pbaCoord['lat'] = zip(*GetCoordenadas(pbaCoord))\n",
    "# pbaCoord.head()       \n",
    "\n",
    "#pbaCoord.to_excel('dircompletas.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bCalculate==0:\n",
    "    _parquet_kwargs = { \"engine\": \"pyarrow\",\n",
    "                       \"compression\": \"snappy\",\n",
    "                       \"index\": False}\n",
    "   \n",
    "    cli_R000=None\n",
    "    cli_R003=None\n",
    "    dcm=None\n",
    "    \n",
    "    #total_result.to_parquet(\"clientes_muface_zaragoza.parquet\", **_parquet_kwargs)\n",
    "    #datos_clientes=dd.read_parquet('clientes_muface_zaragoza.parquet', engine=\"pyarrow\")\n",
    "    \n",
    "    cli_R000 = dd.read_parquet('clientes_R000_zaragoza.parquet')\n",
    "    table = pa.Table.from_pandas(cli_R000.compute())\n",
    "    #print(table.schema)\n",
    "    cli_R000=cli_R000.loc[cli_R000['estado_gmaps']=='OK'].copy()\n",
    "    print(\"shape cli_R000: \", cli_R000.compute().shape)\n",
    "    \n",
    "    cli_R003=dd.read_parquet('clientes_muface_zaragoza.parquet')\n",
    "    cli_R003=cli_R003.loc[cli_R003['estado_gmaps']=='OK'].copy()\n",
    "    print(\"shape cli_R003: \", cli_R003.compute().shape)\n",
    "    \n",
    "    cli_R001=dd.read_parquet('clientes_R001_zaragoza.parquet')\n",
    "    cli_R001=cli_R001.loc[cli_R001['estado_gmaps']=='OK'].copy()\n",
    "    print(\"shape cli_R001: \", cli_R001.compute().shape)\n",
    "    \n",
    "    cli_R043=dd.read_parquet('clientes_R043_zaragoza.parquet')\n",
    "    cli_R043=cli_R043.loc[cli_R043['estado_gmaps']=='OK'].copy()\n",
    "    print(\"shape cli_R043: \", cli_R043.compute().shape)\n",
    "    \n",
    "    datos_clientes=dd.concat([cli_R000,cli_R003,cli_R001, cli_R043],axis=0,interleave_partitions=True)\n",
    "    print(\"shape total: \", datos_clientes.compute().shape)\n",
    "    \n",
    "    #dcm = dd.read_parquet('geodatos_proveedores_cm_red_Muface_y_Privada_con_dircompleta.parquet', engine=\"pyarrow\")\n",
    "    datos_cm = pd.read_parquet('geodatos_proveedores_cm_red_Muface_y_Privada_con_dircompleta.parquet', engine=\"pyarrow\"  )\n",
    "    # table = pa.Table.from_pandas(dcm)\n",
    "    # #print(table.schema)\n",
    "    datos_cm.head()\n",
    "    datos_clientes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_censo=\"./data/censo_municipios/pobmun18.xlsx\"\n",
    "censo=pd.read_excel(file_censo, sheet_name='Hoja1', header=1)\n",
    "#C_MUN_PRO\n",
    "censo['CMUN']=censo['CMUN'].apply(np.int64).astype(str)\n",
    "censo['CPRO']=censo['CPRO'].apply(np.int64).astype(str)\n",
    "\n",
    "censo['CMUN']=censo['CMUN'].apply(lambda x: x.zfill(3))\n",
    "censo['CMUN']=censo['CMUN'].apply(lambda x: x[:3])\n",
    "censo['CPRO']=censo['CPRO'].apply(lambda x: x.zfill(2))\n",
    "\n",
    "censo['C_MUN_PRO']=censo['CPRO'] + censo['CMUN']\n",
    "censo=censo[['C_MUN_PRO', 'POB18', 'HOMBRES', 'MUJERES']]\n",
    "censo['C_MUN_PRO']=censo['C_MUN_PRO'].astype(float)\n",
    "\n",
    "datos_cm['CPRO']=datos_cm['PCMLPR'].apply(np.int64).astype(str)\n",
    "datos_cm['CMUN']=datos_cm['PCMLLC'].apply(np.int64).astype(str)\n",
    "datos_cm['CMUN']=datos_cm['CMUN'].apply(lambda x: x.zfill(4))\n",
    "datos_cm['CMUN']=datos_cm['CMUN'].apply(lambda x: x[:3])\n",
    "datos_cm['CPRO']=datos_cm['CPRO'].apply(lambda x: x.zfill(2))\n",
    "datos_cm['CMUN_PRO']= datos_cm['CPRO'] + datos_cm['CMUN']\n",
    "datos_cm['CMUN_PRO']=datos_cm['CMUN_PRO'].astype('float')\n",
    "\n",
    "datos_cm=datos_cm.merge(censo, left_on='CMUN_PRO', right_on='C_MUN_PRO', how='left')\n",
    "\n",
    "datos_cm['POB18'].fillna(value=0, inplace=True)\n",
    "datos_cm['HOMBRES'].fillna(value=0, inplace=True)\n",
    "datos_cm['MUJERES'].fillna(value=0, inplace=True)\n",
    "\n",
    "datos_cm[['CMUN_PRO', 'POB18', 'HOMBRES', 'MUJERES']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_clientes['RAMO'].unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bCalculate==0:\n",
    "    # clientes_sin_geo=datos_clientes.loc[datos_clientes['estado_gmaps'] != 'OK']\n",
    "    # clientes_sin_geo.head()\n",
    "    \n",
    "    info_clientes=datos_clientes.compute() #convierto dask a dataframe normal para pasarlo a excel\n",
    "    \n",
    "    info_clientes['dircompleta']=info_clientes['dircompleta'].apply(lambda x: x.replace('\"', \" \" ))\n",
    "    info_clientes['dircompleta']=info_clientes['dircompleta'].apply(lambda x: x.replace(\"'\", \" \" ))\n",
    "    \n",
    "    #info_clientes=info_clientes.iloc[130:138]\n",
    "    #obtengo los datos qu me faltan de geolocalizar\n",
    "#     info_clientes['lng'], info_clientes['lat'], info_clientes['estado_gmaps']\\\n",
    "#     = zip(*GetCoordenadas_def(info_clientes, 'lng', 'lat'))\n",
    "    \n",
    "    #de momento no he podido rascar mas direciones estan dan error, tengo que rhacer el codigo\n",
    "    #para configurar una url con filtros aceptados por el serivicio geocoding de google:\n",
    "    #https://developers.google.com/maps/documentation/geocoding/intro#ComponentFiltering\n",
    "    \n",
    "    info_clientes=info_clientes.loc[info_clientes['estado_gmaps'] == 'OK']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_clientes.loc[info_clientes['estado_gmaps'] != 'OK'].head(2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SQL_PRIMAS=\"\"\"SELECT CLSUC, PRIBEN, CODPER FROM CRM.CRMASE WHERE CLSUC=50\"\"\"\n",
    "cnxn2 = pyodbc.connect(\"dsn=PRODUCCION\",UID=\"JAVIERBS\",PWD=\"ANASERJBS123456\")\n",
    "datos_primas= pd.read_sql(SQL_PRIMAS,cnxn2)\n",
    "datos_primas.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info_clientes=info_clientes.merge(datos_primas[['CODPER', 'PRIBEN']], how='left', left_on='CODIGO_PERSONA',\n",
    "                                 right_on='CODPER')\n",
    "info_clientes['PRIBEN'].fillna(0, inplace=True)\n",
    "info_clientes.head(2)\n",
    "#DEL RAMO 3 NO TENEMOS PRIMAS EN CRM. TENGO QUE CREAR LA CONSULTA..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'https://maps.googleapis.com/maps/api/geocode/json?'\n",
    "data = urllib.parse.urlencode({\"address\" : \"CAL Santander 10 12  Zaragoza, Spain\", \"key\": \"AIzaSyC5KU755KKzQsMw9dHkM2p5alN3AUjmUYA\"})\n",
    "url = prefix+data\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una vez que ya hemos obtenido los datos de las coordenadas no vuelvo a realizar los pasos previos anteriores, ya que tengo un archivo en parquet donde tengo los resultados y de ahí es de donde obtengo el dataframe, puedo usar los pasos previos para hacer una nueva pasada con las direcciones que no he obtenido resultado bien por over_limit o porque la dirección no ha sido encontrada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #agregamos la info obtenida con los datos de  lat y lng\n",
    "# with pd.ExcelWriter('geo_domicilios_aseg_r003_zaragoza.xlsx') as writer:  # doctest: +SKIP\n",
    "#     datos_cm.to_excel(writer, sheet_name='Hoja1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'estado_gmaps' not in datos_cm.columns:\n",
    "    datos_cm['estado_gmaps']=''\n",
    "print(datos_cm.columns)\n",
    "datos_cm[['PCMLPR', 'PCMLLC', 'PCMLNP', 'PCMLCP']].head(2)\n",
    "#PCMLPR: cod rov, PCMLLC: cod muni, PCMLNP: nombre muni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bCalculate=0\n",
    "if bCalculate==1:\n",
    "    bloques_de=50\n",
    "    registros=datos_cm.shape[0]\n",
    "    resto_particiones=registros % bloques_de\n",
    "\n",
    "    if resto_particiones==0:\n",
    "        nparticiones=int(registros/bloques_de)\n",
    "    else:\n",
    "        nparticiones=int(registros/bloques_de) +1\n",
    "\n",
    "    n=0\n",
    "\n",
    "    total_result=None\n",
    "    gc.collect()\n",
    "\n",
    "    for n in range(nparticiones + 1):\n",
    "    #for n in range(2):\n",
    "        tmp=datos_cm.iloc[(n*bloques_de):(n*bloques_de)+bloques_de]\n",
    "\n",
    "\n",
    "        tmp['lng'] ,  tmp['lat'], tmp['estado_gmaps']=zip(*GetCoordenadas_def( tmp ))\n",
    "\n",
    "        datos_cm.iloc[(n*bloques_de):(n*bloques_de)+bloques_de]['lng']=tmp['lng']\n",
    "        datos_cm.iloc[(n*bloques_de):(n*bloques_de)+bloques_de]['lat']=tmp['lat']\n",
    "        datos_cm.iloc[(n*bloques_de):(n*bloques_de)+bloques_de]['estado_gmaps']=tmp['estado_gmaps']\n",
    "        #print(tmp['lng'].shape[0], datos_cm.iloc[(n*bloques_de):(n*bloques_de)+bloques_de]['lng'].shape[0] )\n",
    "\n",
    "        if n==0:\n",
    "            total_result=tmp\n",
    "        else:\n",
    "            total_result=pd.concat([total_result, tmp])\n",
    "\n",
    "        print('procesado bloque ', n+1 , ' de ' , nparticiones ,' particiones.')\n",
    "\n",
    "    total_result.head(2)   \n",
    "    # HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with \n",
    "    #     url: /maps/api/geocode/json?address=+Justicia+Mayor+de+Aragon+47++4%C2%BA+Dch+Ejea+de+los+Caballer%2C+Spain\n",
    "    #         &key=AIzaSyC5KU755KKzQsMw9dHkM2p5alN3AUjmUYA \n",
    "    #         (Caused by ProxyError('Cannot connect to proxy.'\n",
    "    #                               , OSError('Tunnel connection failed: 407 Proxy Authentication Required',)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bCalculate==1:\n",
    "    _parquet_kwargs = {\"engine\": \"pyarrow\",\n",
    "                       \"compression\": \"snappy\",\n",
    "                       \"index\": False}\n",
    "    _parquet_kwargs = {\"engine\": \"pyarrow\",\n",
    "                       \"compression\": \"snappy\"}\n",
    "\n",
    "    total_result.to_parquet(\"geodatos_proveedores_cm_red_Muface_y_Privada_con_dircompleta.parquet\", **_parquet_kwargs)\n",
    "\n",
    "    # #dcm = dd.read_parquet('clientes_muface_zaragoza.parquet')\n",
    "    # dcm = pd.read_parquet('clientes_muface_zaragoza.parquet')\n",
    "    # table = pa.Table.from_pandas(dcm)\n",
    "    # #print(table.schema)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bCalculate==1:\n",
    "    #agregamos la info obtenida con los datos de  lat y lng\n",
    "    with pd.ExcelWriter('datos_proveedores_cm_red_Muface_y_Privada_con_dircompleta.xlsx') as writer:  # doctest: +SKIP\n",
    "        total_result.to_excel(writer, sheet_name='Hoja1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trabajamos la geometria obtenida mediante geocodifcacion de la direccion: agregamos la columna geometry mediante la fx gpd.points_from_xy y unimos con sjoin a prov_df y muni_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "#si la info la obtenemos del fichero guardado reasignamos total_result aqui.\n",
    "if bCalculate==0:\n",
    "    total_result=datos_cm\n",
    "    \n",
    "fp2='data/maps/provincias/Inmigración_por_provincias.shp'\n",
    "fp1='data/maps/municipios INE/Municipios_IGN.shp'\n",
    "\n",
    "pba1=None\n",
    "gc.collect()\n",
    "prov_df = gpd.read_file (fp2, encoding='utf-8', enabled_drivers=['GeoJSON', 'ESRI Shapefile'])\n",
    "muni_df = gpd.read_file (fp1, encoding='utf-8', enabled_drivers=['GeoJSON', 'ESRI Shapefile'])\n",
    "#uso el metodo copy() para no crear una vista que podria cambiar el objeto original si hicieramos cualquier\n",
    "#cambio en la nueva variable creada, asi con copy() crea una copia y el objeto original no se cambia.\n",
    "#muni_df=muni_df.loc[muni_df['NAMEUNIT']=='Zaragoza'].copy()\n",
    "prov_df=prov_df.loc[prov_df['Texto']=='Zaragoza'].copy()\n",
    "pba1=total_result.copy()\n",
    "pba1=pba1.loc[pba1['estado_gmaps']=='OK'].copy()\n",
    "pba1[[\"lng\", \"lat\"]] = pba1[[\"lng\", \"lat\"]].apply(pd.to_numeric)\n",
    "\n",
    "\n",
    "#pba1['geometry']=pba1[['lng', 'lat']].apply(lambda x: 'POINT(' + str(x['lng'])+ ' , ' + str(x['lat']) + ')' , axis=1 )\n",
    "\n",
    "#asi pasamos la info de coordenadas de un dataframe normal a un geodataframe geopandas:\n",
    "# ************************************************************************************\n",
    "gdf_cmedico = gpd.GeoDataFrame( pba1, geometry=gpd.points_from_xy(pba1.lng, pba1.lat))\n",
    "#de esta forma hacemos la union con otro geodatafraem por la inteseccion \"within\" de las geometrias\n",
    "#en este caso lo unimos con la geometria de municipio (habiamos seleccionado Zaragoza)\n",
    "geo_completa=gdf_cmedico.geometry.within(muni_df.geometry)\n",
    "\n",
    "#union x la capital, me interesa la provincia\n",
    "#geo_completa = gpd.sjoin(gdf_cmedico, muni_df, how='inner',op='within') \n",
    "#union con la provincia de Zaragoza:\n",
    "geo_completa = gpd.sjoin(gdf_cmedico, prov_df, how='inner',op='within') \n",
    "geo_completa[['geometry','Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cmedico.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5 = mc.Quantiles(muni_df.Shape__Len, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5.yb[0:10]  # -->  nos da información de a que grup pertenece cada registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s5=mc.StdMean(muni_df.Shape__Len)\n",
    "s5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ei5=mc.EqualInterval(muni_df.Shape__Are)\n",
    "ei5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bp5=mc.BoxPlot(muni_df.Shape__Are)\n",
    "bp5 #este no puedo utilizarlo en "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_fit=[ c.adcm / 10000 for c in [ei5 , bp5, s5, q5]]\n",
    "class_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#como se puede ver el clasificador de quiantiles (q5) es el de menor adcm (absolute desviation sobre la meidana)\n",
    "#por lo tanto es el que elegiremos para el proposito de hacer un mapa de cloropetas\n",
    "# x lo tanto quedaria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mc.CLASSIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysal.lib as libpysal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"censo: \" ,censo.columns)\n",
    "print(\"muni: \", muni_df.columns)\n",
    "municipios=muni_df.copy()\n",
    "municipios['CODIGOINE']=municipios['CODIGOINE'].astype('float')\n",
    "muni_censo=municipios.merge(censo, how=\"left\",  left_on='CODIGOINE',\n",
    "                                 right_on='C_MUN_PRO')\n",
    "muni_censo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq = libpysal.weights.Queen.from_dataframe(muni_censo[['geometry'\n",
    "                                                       , 'POB18']])\n",
    "wq.transform='r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muni_censo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muni_censo['POB18'].fillna(0,inplace=True)\n",
    "y = muni_censo['POB18']\n",
    "ylag = libpysal.weights.lag_spatial(wq, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylag[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylagq5 = mc.Quantiles(ylag, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylagq5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(15, 13))\n",
    "# Plot unique values choropleth including a legend and with no boundary lines\n",
    "muni_censo.assign(lbl_ylagq5=ylagq5.yb).plot(column='lbl_ylagq5',k=5\n",
    "                                                                                 , scheme='quantiles'\n",
    "                                     , categorical=True, legend=True, linewidth=0.5, ax=ax)\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Keep axes proportionate\n",
    "plt.axis('equal')\n",
    "# Add title\n",
    "plt.title(r'población*weight queen')\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias=['0: outliers x abajo', '1: minimo no outlier'\n",
    "            , '2: Q2', '3: Q3', '4: maximo no outlier', '5: outliers x encima']\n",
    "categorias\n",
    "bpl=[categorias[b] for b in ylagq5.yb]\n",
    "\n",
    "muni_censo['class']=bpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax=plt.subplots( figsize=(15,13), subplot_kw={\"aspect\": \"equal\"} )\n",
    "\n",
    "#gdf_cmedico.plot( column='POB18', scheme='Quantiles', k=9, legend=True, ax=ax)\n",
    "muni_censo.plot(column='class', categorical=True, k=5,cmap='OrRd'\n",
    "             ,linewidth=0.05, legend=True, ax=ax, edgecolors='grey')\n",
    "#plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "yex=muni_censo[[ 'POB18']] .values\n",
    "\n",
    "plt.figure(figsize=(15, 13))\n",
    "plt.title(\"Dendogramas clusteers precios vivienda\")\n",
    "dend = shc.dendrogram(shc.linkage(yex, method='ward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A la vista del dendograma vemos 4 clusters si trazamos la horizontal más alta sin que cruce con ninguna\n",
    "#horizontal de las pintadas, estamos hablando de una linea que quedaria sobre el 0.57-0.58 +-.\n",
    "yq=np.asarray([1,5,7])\n",
    "type(wq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2k = AgglomerativeClustering(linkage='ward',\n",
    "                                connectivity=wq.sparse,\n",
    "                                n_clusters=2)\n",
    "model2k.fit(muni_censo[ 'POB18'].values.reshape(-1,1))\n",
    "\n",
    "model3k = AgglomerativeClustering(linkage='ward',\n",
    "                                connectivity=wq.sparse,\n",
    "                                n_clusters=3)\n",
    "model3k.fit(muni_censo[ 'POB18'].values.reshape(-1,1))\n",
    "\n",
    "model4k = AgglomerativeClustering(linkage='ward',\n",
    "                                connectivity=wq.sparse,\n",
    "                                n_clusters=4)\n",
    "model4k.fit(muni_censo[ 'POB18'].values.reshape(-1,1))\n",
    "\n",
    "model5k = AgglomerativeClustering(linkage='ward',\n",
    "                                connectivity=wq.sparse,\n",
    "                                n_clusters=5)\n",
    "model5k.fit(muni_censo[ 'POB18'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score \n",
    "\n",
    "# apuntando el score en cada modelo\n",
    "silhouette_scores = [] \n",
    "silhouette_scores.append( \n",
    "        silhouette_score(muni_censo[ 'POB18'].values.reshape(-1,1)\n",
    "                         , model2k.fit_predict(muni_censo[ 'POB18'].values.reshape(-1,1)))) \n",
    "silhouette_scores.append( \n",
    "        silhouette_score(muni_censo[ 'POB18'].values.reshape(-1,1)\n",
    "                         , model3k.fit_predict(muni_censo[ 'POB18'].values.reshape(-1,1)))) \n",
    "silhouette_scores.append( \n",
    "        silhouette_score(muni_censo[ 'POB18'].values.reshape(-1,1)\n",
    "                         , model4k.fit_predict(muni_censo[ 'POB18'].values.reshape(-1,1)))) \n",
    "silhouette_scores.append( \n",
    "        silhouette_score(muni_censo[ 'POB18'].values.reshape(-1,1)\n",
    "                         , model5k.fit_predict(muni_censo[ 'POB18'].values.reshape(-1,1)))) \n",
    "silhouette_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muni_df['ward5wq'] = model5k.labels_\n",
    "# Setup figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(15, 12))\n",
    "# Plot unique values choropleth including a legend and with no boundary lines\n",
    "muni_df.plot(column='ward5wq', categorical=True, legend=True,cmap='OrRd', linewidth=0, ax=ax)\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Keep axes proportionate\n",
    "plt.axis('equal')\n",
    "# Add title\n",
    "plt.title(r'Poblacion (Ward, $k=2$, Queen Contiguity)')\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wq=lp.Queen.from_dataframe(muni_df)\n",
    "wq.transform='r'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp=muni_df['Shape__Are']\n",
    "ylag=lp.lag_spatial(wq, yp)\n",
    "ylag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ylag5=mc.Quantiles(ylag, k=5)\n",
    "ylag5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots( figsize=(15,13), subplot_kw={\"aspect\": \"equal\"} )\n",
    "\n",
    "#gdf_cmedico.plot( column='POB18', scheme='Quantiles', k=9, legend=True, ax=ax)\n",
    "muni_df['lag']=ylag5\n",
    "muni_df.plot(column='lag', categorical=True, k=5,cmap='OrRd', edgecolor=\"grey\"\n",
    "             ,linewidth=0.1, legend=False, ax=ax)\n",
    "#plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp=yp > yp.median()\n",
    "labels=['0: menos mediana', '1: mas mediana']\n",
    "deter=[labels[i] for i in yp*1]\n",
    "muni_df['class_biv']=deter\n",
    "\n",
    "fig, ax=plt.subplots( figsize=(15,13), subplot_kw={\"aspect\": \"equal\"} )\n",
    "\n",
    "#gdf_cmedico.plot( column='POB18', scheme='Quantiles', k=9, legend=True, ax=ax)\n",
    "muni_df['lag']=ylag5\n",
    "muni_df.plot(column='class_biv', categorical=True, cmap='OrRd', edgecolor=\"grey\"\n",
    "             ,linewidth=0.1, legend=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol=np.polyfit(muni_df.Shape__Are , ylag, 1)\n",
    "pol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors as skn\n",
    "import sklearn.metrics as skm\n",
    "coordenadas=np.vstack( muni_df['geometry'].apply( lambda p: np.hstack(p.centroid.xy) ).values )\n",
    "coordenadas\n",
    "Y=np.log(muni_df['Shape__Are'])\n",
    "\n",
    "hasta=int(len(Y)*0.8)\n",
    "barajear=np.random.permutation(len(Y))\n",
    "train,test=barajear[: hasta], barajear[hasta :]\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Y.values\n",
    "Y=Y.reshape(-1,1)\n",
    "len(coordenadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNR=skn.KNeighborsRegressor(weights='distance', n_neighbors=50)\n",
    "espacial=KNNR.fit(coordenadas[train,:], Y[train,:])\n",
    "espacial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "espacial_pred=espacial.predict(coordenadas[test,:])\n",
    "print(espacial_pred[0:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)\n",
    "Y[test,:][0:10,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordenadas\n",
    "cl=DBSCAN(eps=1).fit(coordenadas)\n",
    "comp=cl.components_\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #PCMLPR: cod rov, PCMLLC: cod muni, PCMLNP: nombre muni\n",
    "# total_result['CMUN']=total_result['PCMLLC'].apply(lambda x: str(x).replace('.0','').zfill(4))\n",
    "# #total_result['CMUN2']=total_result['CMUN2'].apply(lambda x: x[:3])\n",
    "# total_result['CPRO']=total_result['PCMLPR'].apply(lambda x: str(x).replace('.0','').zfill(2))\n",
    "\n",
    "# total_result['CMUN_PRO']= total_result['CPRO'] + total_result['CMUN']\n",
    "# total_result['CMUN_PRO']=total_result['CMUN_PRO'].astype('float')\n",
    "# total_result.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(total_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_completa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(geo_completa.crs)\n",
    "# geo_completa.crs = {'init' :'epsg:4326'}  \n",
    "geo_completa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(geo_completa.shape)\n",
    "print(\"no son de Zaragoza provincia: \", geo_completa.loc[geo_completa['Texto'] != 'Zaragoza'].shape )\n",
    "print(\"casos con marca no aparece en cm=N: \", geo_completa.loc[geo_completa['PCMACM'] == 'N'].shape )\n",
    "print(\"casos con marca aparece en cm=S: \", geo_completa.loc[geo_completa['PCMACM'] == 'S'].shape )\n",
    "print(\"sin localización geo: \", geo_completa.loc[ geo_completa['estado_gmaps']!='OK'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from holoviews.operation.datashader import datashade, shade, dynspread, rasterize , spread\n",
    "import holoviews.operation.datashader as hd\n",
    "from holoviews.streams import RangeXY\n",
    "from bokeh.models import WMTSTileSource\n",
    "from colorcet import fire\n",
    "import cartopy\n",
    "\n",
    "# def platcaree_to_mercator_vectorised(x, y):\n",
    "#     '''Use cartopy to convert Platecarree coords to Mercator.'''\n",
    "#     return(cartopy.crs.GOOGLE_MERCATOR.transform_points(\n",
    "#         cartopy.crs.PlateCarree(), x, y))\n",
    "\n",
    "use_data_plot=geo_completa.copy()\n",
    "if 'index_right' in use_data_plot.columns:\n",
    "    use_data_plot.drop(columns=['index_right'], inplace=True)\n",
    "    \n",
    "use_data_plot=use_data_plot.rename(columns={\"Shape__Are\": \"Area_Provincia\"     })\n",
    "use_data_plot = gpd.sjoin(use_data_plot, muni_df[['Shape__Are', 'NAMEUNIT', 'geometry']], how='left',op='within') \n",
    "\n",
    "use_data_plot['PCMDLC']=use_data_plot['PCMDLC'].apply(lambda x: x.lower().capitalize())\n",
    "use_data_plot['PCMNFC']=use_data_plot['PCMNFC'].apply(lambda x: x.strip())\n",
    "use_data_plot['PCMNPR']=use_data_plot['PCMNPR'].apply(lambda x: x.strip())\n",
    "use_data_plot['PCMNFC']=use_data_plot['PCMNFC'].apply(lambda x: \"sin denominacion facturador\" if len(x) < 2 else x )\n",
    "use_data_plot['PCMNPR']=use_data_plot['PCMNPR'].apply(lambda x: \"sin profesional asignado\" if len(x) < 2 else x )\n",
    "use_data_plot['PCMNPR']=use_data_plot['PCMNPR'].apply(lambda x: x.strip())\n",
    "use_data_plot['PCMNFC'].fillna('no disponible', inplace=True)\n",
    "use_data_plot['PCMNPR'].fillna('no disponible', inplace=True)\n",
    "use_data_plot['PCMDLC']=use_data_plot['PCMDLC'].apply(lambda x: x.strip())\n",
    "use_data_plot['PCMNFC']=use_data_plot['PCMNFC'].apply(lambda x: x.strip())\n",
    "use_data_plot['PCMNPR']=use_data_plot['PCMNPR'].apply(lambda x: x.strip())\n",
    "use_data_plot['PCMEDS']=use_data_plot['PCMEDS'].apply(lambda x: x.strip())\n",
    "use_data_plot['PCMNPS']=use_data_plot['PCMNPS'].apply(lambda x: x.strip())\n",
    "use_data_plot['PCMNAT']=use_data_plot['PCMNAT'].apply(lambda x: x.strip())\n",
    "use_data_plot['PCMRDS']=use_data_plot['PCMRDS'].apply(lambda x: x.strip())\n",
    "use_data_plot['PCMEGD']=use_data_plot['PCMEGD'].apply(lambda x: x.strip())\n",
    "\n",
    "\n",
    "use_data_plot['Shape__Are'].fillna(1, inplace=True) #hay municipios que no han enlzado con la info de geo_completa\n",
    "#a estos les incluyo 1 hectarea como dato para Shape__Are\n",
    "use_data_plot['NAMEUNIT'].fillna( use_data_plot['PCMDLC'] , inplace=True)\n",
    "\n",
    "use_data_plot=use_data_plot.merge(datos_factu, how='left', left_on='PCMIUN',\n",
    "                                 right_on='PPSIUN')\n",
    "use_data_plot['FACTURACION_MENSUAL'].fillna(0, inplace=True)\n",
    "use_data_plot=use_data_plot.loc[(use_data_plot['estado_gmaps']=='OK') & (use_data_plot['Texto']=='Zaragoza')].copy()\n",
    "#sólo selecciono los que aparecen en el cuadro médico, también hay servicios concertados para facturación pero no\n",
    "#es el objeto de este informe\n",
    "use_data_plot=use_data_plot.loc[(use_data_plot['PCMACM']=='S')].copy()\n",
    "use_data_plot.reset_index(inplace=True, drop=True)\n",
    "use_data_plot[['geometry','Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR', 'PPSIUN', 'FACTURACION_MENSUAL' ]].head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data_plot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para reproyecto un geodataframe a Mercator:\n",
    "#world = world.to_crs({'init': 'epsg:3395'}) # world.to_crs(epsg=3395) would also work\n",
    "#primero asignamos el crs en el que viene lat/lon sino dara error:\n",
    "use_data_plot.crs = {'init' :'epsg:4326'}  \n",
    "#ahora reprogamamos al crs de mercator para q coincida con los tiles a superponer\n",
    "use_data_plot=use_data_plot.to_crs({'init': 'epsg:3857'})\n",
    "\n",
    "lst_direcciones=use_data_plot['dircompleta'].unique()\n",
    "lst_direcciones=list(lst_direcciones)\n",
    "\n",
    "use_color=fire[::-1]\n",
    "#quito algunos colores por delante y por detras, por detrás es importante sino muestra un color del\n",
    "#punto negro y no se ve con el fondo negro del tile.\n",
    "use_color=use_color[int(len(use_color)/4) : len(use_color)-int(len(use_color)/4)]\n",
    "dopts = dict(width=800, height=600, tools=['hover', 'save', 'undo', 'redo'], colorbar=True ,cmap=use_color)\n",
    "dopts_sin_hover = dict(width=800, height=600, tools=[ 'save', 'undo', 'redo'], colorbar=True ,cmap=use_color)\n",
    "\n",
    "\n",
    "dopts_ds = dict(width=800, height=600, x_sampling=0.8, y_sampling=0.8)\n",
    "dopts_ds = dict(x_sampling=10, y_sampling=10, width=1000, height=1000, normalization='eq_hist'\n",
    "                      , precompute=True, expand=False\n",
    "                      ,cmap=use_color)\n",
    "\n",
    "topts = dict(width=600, height=500, bgcolor='black', xaxis=None, yaxis=None, show_grid=False)\n",
    "\n",
    "layer1=gts.EsriImagery.opts(width=300, height=200, global_extent=False, alpha=0.8) * gts.StamenLabels.options(level='annotation')\n",
    "layer2= gv.tile_sources.CartoDark ()\n",
    "layer3=gts.EsriImagery.opts(width=800, height=600, global_extent=False, alpha=0.6) \n",
    "#cmedico_con_geoloc=total_result.loc[(total_result['estado_gmaps']=='OK') & (total_result['CODIGO_PROVINCIA_COBRO']==50)]\n",
    "#cmedico_con_geoloc[[\"lng\", \"lat\"]] = cmedico_con_geoloc[[\"lng\", \"lat\"]].apply(pd.to_numeric)\n",
    "#reproyectamos pq gts en hv esta en otras coordenadas\n",
    "#cuando reproyecto lo hace mal, la lat queda en blanco en muchos registros, puede que sea por el formato númerico\n",
    "#lo hago (el Dataset, tiles y Points) con gv en lugar de hv que asi no es necesario reproyectar.\n",
    "#pbaCoord.loc[:, 'lng'], pbaCoord.loc[:, 'lat'] = ds.utils.lnglat_to_meters(pbaCoord.lng,pbaCoord.lat)\n",
    "datos=hv.Dataset(use_data_plot[['geometry','Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ]]\n",
    "                 , kdims=['Longitude', 'Latitude']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta',  'PCMDLC', 'PCMNFC', 'PCMNPR' ])\n",
    "\n",
    "#tiles = gv.tile_sources.ESRI.clone(crs=ccrs.PlateCarree()).options(**topts)\n",
    "#tiles=gv.tile_sources.ESRI\n",
    "Puntos=hv.Points(datos, kdims=['Longitude', 'Latitude'] \n",
    "                 , vdims=['PCMNFC', 'PCMNPR' , 'dircompleta', 'PCMDLC', 'Texto', 'Cod_CCAA']) \\\n",
    "        .redim.values(dircompleta=lst_direcciones) \\\n",
    "        .opts( **dopts_sin_hover )\n",
    "\n",
    "# #no necesario. Dejo como notas tecnicas\n",
    "# pointerx = hv.streams.PointerX(x=np.mean(Puntos.range('Longitude')), source=Puntos)\n",
    "# pointery = hv.streams.PointerY(y=np.mean(Puntos.range('Latitude')), source=Puntos)\n",
    "# vline = hv.DynamicMap(lambda x: hv.VLine(x), streams=[pointerx]).opts(width=800, height=600)\n",
    "# hline = hv.DynamicMap(lambda y: hv.HLine(y), streams=[pointery]).opts(width=800, height=600)\n",
    "# InfoPunto=(vline*hline)\n",
    "\n",
    "# sombreador= datashade(Puntos, expand=False, height=2000, width=2000,\n",
    "#                 cmap=use_color, normalization='eq_hist', precompute=True)\n",
    "sombreador= datashade(Puntos, **dopts_ds)\n",
    "#.opts(style=dict(alpha=0.3))\n",
    "#Puntos * gv.tile_sources.ESRI\n",
    "#profs = datashade(Puntos, cmap=fire, **dopts)\n",
    "#gts.EsriImagery*Puntos\n",
    "#layer1*profs\n",
    "#plot=layer2.opts(alpha=0.8)*dynspread(sombreador.opts(tools=['save', 'undo', 'redo']))\n",
    "\n",
    "\n",
    "# plot=layer2.opts(alpha=0.8)*spread(sombreador, px=1)\n",
    "#plot=layer2.opts(alpha=0.8)*dynspread(sombreador,threshold=0.5, max_px=3, how='over')\n",
    "#* InfoPunto.opts(tools=[\"hover\"])) \n",
    "\n",
    "dsp_sombreador=dynspread(sombreador,threshold=0.5, max_px=3, how='over')\n",
    "capa_Quadmesh=(hv.util.Dynamic(hd.aggregate(Puntos, streams=[RangeXY])\n",
    "                 , operation=hv.QuadMesh )).opts(tools=[\"hover\",\"save\", \"undo\", \"redo\"], width=800, height=600\n",
    "                                               , alpha=0  , hover_alpha=0.2, hover_color=\"white\")\n",
    "#la capa Quadmesh es la que permite hacer hover y tener el recuento de proveedore\n",
    "plot=(layer2.opts(alpha=0.7) * dsp_sombreador)\n",
    "Resultado_plot=(plot.opts(width=800, height=600, bgcolor='black', tools=[\"hover\", \"save\"])) * capa_Quadmesh\n",
    "\n",
    "#pn.Column(Resultado_plot.redim.values(PCMDLC=sel_loc))\n",
    "pn.Column(Resultado_plot)\n",
    "#Resultado_plot.redim(  count=dict(range=(1, 10)))\n",
    "\n",
    "#con hv.util.Dyanmic --> hd.aggregate -->streams y operation hv.QuadMesh conseguimos incluir un\n",
    "#tooltip indicando la cuenta de proveedores en el arco de hv width 300, height 300.\n",
    "# (hv.util.Dynamic(hd.aggregate(dsp_sombreador, width=150, height=150, streams=[RangeXY])\n",
    "#                  , operation=hv.QuadMesh)).opts(width=800, height=600\n",
    "#                                                 , tools=[\"hover\",\"save\"],alpha=0, hover_alpha=0.2), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_cm.loc[(datos_cm[\"PCMECD\"]==16000) & (datos_cm[\"PCMACM\"]=='S') & (datos_cm[\"PCMRCD\"]==1)].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resultado_plot.pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.data.shape[0]\n",
    "datos.data['PCMDLC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hv.DynamicMap(Puntos)\n",
    "#c=datos[datos['Texto']=='Zaragoza']\n",
    "#c.dframe()\n",
    "lst_muni=datos.data['PCMDLC'].unique()\n",
    "lst_dir=datos.data['dircompleta'].unique()\n",
    "#sel_loc=np.array(list(lst_muni))\n",
    "sel_loc=lst_muni\n",
    "lst_dir.sort()\n",
    "\n",
    "muni_seleccionado='Zaragoza'\n",
    "\n",
    "\n",
    "#def getPlot(PCMDLC, DIR):\n",
    "def getPlot(PCMDLC):    \n",
    "    \n",
    "    PCMDLC.strip()\n",
    "    c=datos[datos['PCMDLC']==PCMDLC]\n",
    "    #c=datos[datos['dircompleta']==DIR]\n",
    "    nReg=c.data.shape[0]\n",
    "    \n",
    "#     xmax= c['Longitude'].max() +1000 #son coordenadas mercator (metros) +1000 es un 1km mas a la derecha\n",
    "#     xmin= c['Longitude'].min() -1000 #son coordenadas mercator (metros) -1000 es un 1km mas a la izquierda\n",
    "#     ymax= c['Latitude'].max() +1000 #son coordenadas mercator (metros) +1000 es un 1km mas hacia arriba\n",
    "#     ymin= c['Latitude'].min() -1000 #son coordenadas mercator (metros) -1000 es un 1km mas hacia abajo\n",
    "    \n",
    "    #print(c.data.shape[0], PCMDLC,   (xmin,xmax) , (ymin, ymax))\n",
    "    print(nReg, PCMDLC)\n",
    "    Puntos=hv.Points(c , kdims=['Longitude', 'Latitude']\n",
    "                     , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR'])\n",
    "    Puntos_filtrado=Puntos.select(PCMDLC=PCMDLC)\n",
    "    #return hd.aggregate(Puntos, width=100, height=100, streams=[RangeXY], dynamic=False).opts(alpha=0.3)   *layer2\n",
    "    \n",
    "    tiles_plot= gv.tile_sources.CartoDark ( ).opts(alpha=0.7 )\n",
    "    #tiles_plot=(tiles_plot*Puntos_filtrado)\n",
    "    #layer2._x_limits=(xmin, xmax)\n",
    "    #layer2._y_limits=(ymin, ymax)\n",
    "    #layer2=layer2*Puntos.select(PCMDLC=PCMDLC)\n",
    "    if nReg > 500:\n",
    "        return tiles_plot*Puntos.opts(framewise=True) #la opción framewise = True es fundamental para que el\n",
    "        #mapa de tiles (fondo) se sincronice con las nuevas selecciones, sino se queda estático en la primera\n",
    "        #selección y no cambia cuando se seleccionan otras opciones.\n",
    "    else:\n",
    "        return tiles_plot*Puntos.opts(framewise=True, tools=[\"hover\"]) #la opción framewise = True es fundamental para que el\n",
    "        #mapa de tiles (fondo) se sincronice con las nuevas selecciones, sino se queda estático en la primera\n",
    "        #selección y no cambia cuando se seleccionan otras opciones.\n",
    "                             \n",
    "\n",
    "#layer2= gv.tile_sources.CartoDark ( xlim=(xmin,xmax) ,ylim=(ymin, ymax) )\n",
    "#sin el redim.values no presenta el selector ya que considera un rango ilimitado.\n",
    "dmap=hv.DynamicMap(getPlot, kdims=[( 'PCMDLC', 'Municipio') ])\\\n",
    "                .redim.values(PCMDLC=sel_loc )\\\n",
    "                .opts(width=600, height=600 ) \n",
    "dmap\n",
    "#dmap.select(PCMDLC=muni_seleccionado) * layer2\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "\n",
    "\n",
    "hv.extension('bokeh', logo=False)\n",
    "pn.extension()\n",
    "\n",
    "map_tiles=   gv.tile_sources.ESRI \n",
    "opts1=dict(width=600, height=600,xaxis=None, yaxis=None,bgcolor=\"black\")\n",
    "opts2=dict(width=600, height=600,x_sampling=0.00001, y_sampling=0.00001 ,dynamic=False)\n",
    "url = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{Z}/{Y}/{X}.jpg'\n",
    "map_tiles=gv.WMTS(url, crs=crs.GOOGLE_MERCATOR)\n",
    "\n",
    "class ExploraCMedico(hv.streams.Stream):\n",
    "    alpha=param.Magnitude(default=0.5, doc=\"Opacidad mapa\")\n",
    "    colormap=param.ObjectSelector(default=\"fire\", objects=list(cm_n.keys()))\n",
    "    ckecking=param.ObjectSelector(default=1, objects=[1,2,3])\n",
    "    output = parambokeh.view.Plot()\n",
    "    def prepara_grafico(self, x_range, y_range, **kwargs):\n",
    "        print(x_range, y_range,*kwargs)\n",
    "        tiles=map_tiles.options(alpha=self.alpha, **opts1)\n",
    "        points=hv.Points(use_data_plot, ['Longitude', 'Latitude'])\n",
    "        sombreador= datashade(points, cmap=cm_n[self.colormap], x_range=x_range, y_range=y_range, **opts2)\n",
    "        dsp_sombreador=dynspread(sombreador,threshold=0.5, max_px=3, how='over')\n",
    "        \n",
    "        return tiles * dsp_sombreador\n",
    "   \n",
    "    \n",
    "explorador=ExploraCMedico(name=\"Situación cuadro médico muface y privado\")\n",
    "dmap2=hv.DynamicMap(explorador.prepara_grafico, streams=[explorador, RangeXY()])\n",
    "\n",
    "# plot=hv.renderer('bokeh').instance(mode='server').get_plot(dmap2)\n",
    "plot=hv.renderer('bokeh').get_plot(dmap2)#para verlo aqui y que se ejecute el callback prepara_grafico\n",
    "#hay que quitar la ocpion instance(mode='server'), esto seria si lo ejecutasemos en un servidor de bokeh\n",
    "\n",
    "#parambokeh.Widgets(explorador, view_position='right', callback=explorador.event, plots=[plot.state], mode='server')\n",
    "parambokeh.Widgets(explorador, callback=explorador.event, plots=[plot.state], view_position='right')\n",
    "\n",
    "#server = renderer.app(plot, show=True, new_window=True)\n",
    "#renderer.app(plot, show=True, websocket_origin='localhost:8888')\n",
    "\n",
    "# server = renderer.app(parambokeh.Widgets(explorador, view_position='right', callback=explorador.event, plots=[plot.state])\n",
    "# .servable(), show=True, new_window=True)\n",
    "# server"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "hv.extension('bokeh', logo=False)\n",
    "pn.extension()\n",
    "\n",
    "\n",
    "map_tiles=   gv.tile_sources.ESRI \n",
    "opts1=dict(width=600, height=600,xaxis=None, yaxis=None,bgcolor=\"black\")\n",
    "opts2=dict(width=600, height=600,x_sampling=0.00001, y_sampling=0.00001 ,dynamic=False)\n",
    "url = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{Z}/{Y}/{X}.jpg'\n",
    "map_tiles=gv.WMTS(url, crs=crs.GOOGLE_MERCATOR)\n",
    "\n",
    "class ExploraCMedico(hv.streams.Stream):\n",
    "    alpha=param.Magnitude(default=0.5, doc=\"Opacidad mapa\")\n",
    "    colormap=param.ObjectSelector(default=\"fire\", objects=list(cm_n.keys()))\n",
    "   \n",
    "    #output = parambokeh.view.Plot()\n",
    "    \n",
    "    def prepara_grafico(self, x_range, y_range, **kwargs):\n",
    "        print(x_range, y_range,*kwargs)\n",
    "        tiles=map_tiles.options(alpha=self.alpha, **opts1)\n",
    "        points=hv.Points(use_data_plot, ['Longitude', 'Latitude'])\n",
    "        return tiles * datashade(points, cmap=cm_n[self.colormap], x_range=x_range, y_range=y_range, **opts2)\n",
    "    def event(self, **kwargs):\n",
    "    \n",
    "        #if not self.output or any(k in kwargs for k in ['colormap', 'alpha']):\n",
    "        if any(k in kwargs for k in ['colormap', 'alpha']):\n",
    "            print(\"pasa por no self.output\")\n",
    "            hv.DynamicMap(self.prepara_grafico, streams=[self], cache_size=0)\n",
    "        else:\n",
    "            super(ExploraCMedico, self).event(**kwargs)\n",
    "       \n",
    "   \n",
    "    \n",
    "explorador=ExploraCMedico(name=\"Situación cuadro médico muface y privado\")\n",
    "dmap2=hv.DynamicMap(explorador.prepara_grafico, streams=[explorador, RangeXY()])\n",
    "\n",
    "\n",
    "plot=hv.renderer('bokeh').get_plot(dmap2)#para verlo aqui y que se ejecute el callback prepara_grafico\n",
    "#hay que quitar la ocpion instance(mode='server'), esto seria si lo ejecutasemos en un servidor de bokeh\n",
    "\n",
    "#parambokeh.Widgets(explorador, view_position='right', callback=explorador.event, plots=[plot.state], mode='server')\n",
    "#parambokeh.Widgets(explorador, callback=explorador.event, plots=[plot.state], view_position='right')\n",
    "pn.Row(explorador, pn.Column( explorador.event ,plot.state))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "opts1=dict(width=900, height=600,xaxis=None, yaxis=None,bgcolor=\"black\")\n",
    "opts2=dict(width=900, height=600,x_sampling=0.00001, y_sampling=0.00001 ,dynamic=False )\n",
    "gopts  = hv.opts.WMTS(responsive=True, xaxis=None, yaxis=None, bgcolor='black', show_grid=False)\n",
    "\n",
    "\n",
    "url = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{Z}/{Y}/{X}.jpg'\n",
    "map_tiles=gv.WMTS(url, crs=crs.GOOGLE_MERCATOR)\n",
    "datos=use_data_plot\n",
    "\n",
    "lst_muni=datos['PCMDLC'].unique()\n",
    "lst_muni=list(lst_muni)\n",
    "lst_muni.sort()\n",
    "lst_muni.insert(0,'Todas')\n",
    "\n",
    "txt_info=pn.pane.Markdown(\"\")\n",
    "localidades =pn.widgets.Select(name='Todas' , value='Todas', options=lst_muni)\n",
    "colormap=pn.widgets.Select(name=\"colormap\", value=\"fire\", options=list(cm_n.keys()))\n",
    "val_alpha=pn.widgets.FloatSlider(\n",
    "    name='escala opacidad',\n",
    "    start=0, end=1, step=0.1,\n",
    "    value=0.5\n",
    ")\n",
    "\n",
    "\n",
    "# @pn.depends(val_alpha.param.value)\n",
    "# def update_tiles(alpha):\n",
    "#     return map_tiles.opts(alpha=alpha, **opts1)\n",
    "\n",
    "# @pn.depends(colormap.param.value)\n",
    "# def update_colormap(colormap):\n",
    "#     return colormap\n",
    "\n",
    "\n",
    "#watch_loc = localidades.param.watch(SeleccionaDatos, ['options', 'value'], onlychanged=True)\n",
    "# watch_cmap = colormap.param.watch(update_colormap, ['options', 'value'], onlychanged=True)\n",
    "# watch_alpha = val_alpha.param.watch(update_tiles, [ 'value'], onlychanged=True)\n",
    "\n",
    "#corremos la app con estos valores de inicio\n",
    "#localidades.param.trigger('value')\n",
    "#colormap.param.trigger('value')\n",
    "\n",
    "@pn.depends(val_alpha.param.value,  colormap.param.value ,localidades.param.value)\n",
    "def probando_args( alpha=0.5, colormap='fire', localidades='Todas',  x_range=None, y_range=None):\n",
    "    print(\"datos en events: \" ,  x_range, y_range, alpha, colormap, localidades)\n",
    "    print(val_alpha.param, type (val_alpha.param.value) )\n",
    "    ctl_alfa=val_alpha.param\n",
    "    ctl_alfa_val=val_alpha.param.value\n",
    "    print (dir(ctl_alfa.value) )\n",
    "    print(ctl_alfa.value.label)\n",
    "    print(ctl_alfa.value)\n",
    "    print(ctl_alfa_val , type(ctl_alfa_val) )\n",
    "    print ( ctl_alfa.value.constant)\n",
    "   \n",
    "    datos_ds=hv.Dataset(datos[['geometry','Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ]]\n",
    "             , kdims=['Longitude', 'Latitude']\n",
    "             , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ])\n",
    "    puntos=hv.Points(datos_ds, ['Longitude', 'Latitude'])#.opts(framewise=True)\n",
    "    \n",
    "    return hv.DynamicMap( puntos )\n",
    "    \n",
    "\n",
    "@pn.depends(val_alpha.param.value,  colormap.param.value ,localidades.param.value)\n",
    "def prepara_grafico(alpha ,colormap, localidades, x_range, y_range):\n",
    "    \n",
    "    global datos\n",
    "    #primero desactivamos cualquier filtro seleccionando todos los valores del indice\n",
    "    #idx_filtros=[True for i in range( datos.shape[0] ) ]\n",
    "    #plantilla para trabajar con mas de un campo a la vez x si lo necesito\n",
    "#         idx_filtros=[p and m and i and j for p, m, i, j in zip( seleccion.Texto == prov\n",
    "#                                                                    , seleccion.NAMEUNIT == muni \n",
    "#                                                                    , seleccion.POB18 >= lim_poblacion[0]\n",
    "#                                                                    , seleccion.POB18 <= max_poblacion)]\n",
    "    \n",
    "    mapa_fondo=map_tiles.opts(alpha=alpha, **opts1) #update_tiles(alpha)\n",
    "    \n",
    "   \n",
    "    \n",
    "    print(\"forma de datos: \", datos.shape, \"localidad: \", localidades, \"old_localidad: \", old_localidad,streams)\n",
    "    print(streams.x_range)\n",
    "    \n",
    "    datos=use_data_plot\n",
    "    if localidades=='Todas':\n",
    "        idx_filtros=[m  for m in ( datos['PCMDLC'] ==  datos['PCMDLC']) ]\n",
    "        datos = datos[idx_filtros]\n",
    "    else:\n",
    "        idx_filtros=[m  for m in ( datos['PCMDLC'] == localidades) ]\n",
    "        datos = datos[idx_filtros]\n",
    "\n",
    "    datos_ds=hv.Dataset(datos[['geometry','Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ]]\n",
    "             , kdims=['Longitude', 'Latitude']\n",
    "             , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ])\n",
    "    puntos=hv.Points(datos_ds, ['Longitude', 'Latitude']).opts(framewise=True)\n",
    "     \n",
    "    sombreador=datashade(puntos, cmap=cm_n[cmap], x_range=x_range, y_range=y_range,  **opts2)\n",
    "    dsp_sombreador=dynspread(sombreador, how='over')\n",
    "    plotear=mapa_fondo * dsp_sombreador\n",
    "    #return hv.DynamicMap(mapa_fondo) * hv.DynamicMap(plotear)\n",
    "    return plotear\n",
    "\n",
    "\n",
    "def evento ( alpha ,colormap, localidades):\n",
    "    \n",
    "    #return hv.DynamicMap(probando_args ) \n",
    "    #print(\"eventos en evento: \" , events)\n",
    "    \n",
    "    return hv.DynamicMap(probando_args )\n",
    "\n",
    "   \n",
    "dashboard = pn.Row( pn.Column (val_alpha, localidades, colormap,  txt_info), probando_args)\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#dashboard.show(websocket_origin='*')    #con esto conseguimos que pueda compartirse desde mi ip, sustituyendo\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "localidades=param.ObjectSelector(default=\"Todas\", objects=lst_muni )\n",
    "help(localidades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modifico datos_cientes (spark) para añadir un buffer radial a cada asegurado, coincidiendo con el parametro de radio de accion (de momento constante=7km) para unir con los proveedores de cmedico y asi poder computar cuantos se tocan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***************************************************************************************************************\n",
    "#                     no lo necestio opto por un cKDTree\n",
    "#***************************************************************************************************************\n",
    "\n",
    "def assign_interseccion_clientes_cmedico(df_points, df_poligonos, num_crs, lon_var, lat_var, locid_var):\n",
    "    \"\"\"Joins DataFrame with Taxi Zones shapefile.\n",
    "    This function takes longitude values provided by `lon_var`, and latitude\n",
    "    values provided by `lat_var` in DataFrame `df`, and performs a spatial join\n",
    "    with the NYC taxi_zones shapefile. \n",
    "    The shapefile is hard coded in, as this function makes a hard assumption of\n",
    "    latitude and longitude coordinates. It also assumes latitude=0 and \n",
    "    longitude=0 is not a datapoint that can exist in your dataset. Which is \n",
    "    reasonable for a dataset of New York, but bad for a global dataset.\n",
    "    Only rows where `df.lon_var`, `df.lat_var` are reasonably near New York,\n",
    "    and `df.locid_var` is set to np.nan are updated. \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame or dask.DataFrame\n",
    "        DataFrame containing latitudes, longitudes, and location_id columns.\n",
    "    lon_var : string\n",
    "        Name of column in `df` containing longitude values. Invalid values \n",
    "        should be np.nan.\n",
    "    lat_var : string\n",
    "        Name of column in `df` containing latitude values. Invalid values \n",
    "        should be np.nan\n",
    "    locid_var : string\n",
    "        Name of series to return. \n",
    "    \"\"\"\n",
    "\n",
    "    import geopandas\n",
    "    from shapely.geometry import Point\n",
    "\n",
    "\n",
    "    # make a copy since we will modify lats and lons\n",
    "    localdf = df_points[[lon_var, lat_var]].copy()\n",
    "    \n",
    "    # missing lat lon info is indicated by nan. Fill with zero\n",
    "    # which is outside nuestro mapa\n",
    "    localdf[lon_var] = localdf[lon_var].dropna()\n",
    "    localdf[lat_var] = localdf[lat_var].dropna()\n",
    "    localdf[lon_var] = localdf[lon_var].fillna(value=0.)\n",
    "    localdf[lat_var] = localdf[lat_var].fillna(value=0.)\n",
    "    \n",
    "\n",
    "#     shape_df = geopandas.read_file('../shapefiles/taxi_zones.shp')\n",
    "#     shape_df.drop(['OBJECTID', \"Shape_Area\", \"Shape_Leng\", \"borough\", \"zone\"],\n",
    "#                   axis=1, inplace=True)\n",
    "    shape_df=df_poligonos #ya constituido con un buffer de influencia para medicos cmedico\n",
    "    #shape_df = shape_df.to_crs({'init': 'epsg:' +str(num_crs) })\n",
    "\n",
    "    try:\n",
    "        #como es posible que pasemos un dask dataframe este lo convertimmos en un geodataframe\n",
    "        #ya que dask no tiene geometry ni permite operaciones within por eso mismo tambien\n",
    "        #como varible df tenemos que pasar el dataframe ue contenga los puntos no los\n",
    "        #poligonos\n",
    "        \n",
    "        local_gdf = gpd.GeoDataFrame(\n",
    "            localdf,# crs={'init': 'epsg:3857'}, \n",
    "            geometry=[Point(xy) for xy in\n",
    "                      zip(localdf[lon_var].compute(), localdf[lat_var].compute()   )]\n",
    "                    \n",
    "            \n",
    "            )\n",
    "\n",
    "        local_gdf = gpd.sjoin(\n",
    "            local_gdf, shape_df, how='left', op='within')\n",
    "\n",
    "        #return local_gdf.CODIGO_PERSONA #LocationID.rename(locid_var)\n",
    "        return local_gdf\n",
    "        \n",
    "    except ValueError as ve:\n",
    "        print(ve)\n",
    "        #print(ve.stacktrace())\n",
    "        series = localdf[lon_var]\n",
    "        series = np.nan\n",
    "        return series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_clientes.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from  pysal.lib.weights.distance import get_points_array #, get_points_array_shapefile\n",
    "cpy_data_plot=use_data_plot.copy()\n",
    "\n",
    "# del geo_clientes\n",
    "# del gdf_cmedico_spk\n",
    "# gc.collect()\n",
    "\n",
    "geo_clientes = gpd.GeoDataFrame( info_clientes, geometry=gpd.points_from_xy(info_clientes.lng, info_clientes.lat) )\n",
    "geo_clientes=geo_clientes[['SUCURSAL', 'OFICINA', 'RAMO', 'NUMERO_POLIZA', 'ORDEN_POLIZA', 'CODIGO_PERSONA'\n",
    "                           ,'PRIBEN', 'geometry', 'lng', 'lat']]\n",
    "geo_clientes.crs = {'init' :'epsg:4326'} \n",
    "geo_clientes=geo_clientes.to_crs({'init': 'epsg:3857'})\n",
    "geo_clientes.head(2)\n",
    "#***************************************************************************************************************\n",
    "#no lo hago con buffer y geopandas, no lo necesito porque lo hago con algoritmo scipy cDkTree\n",
    "#***************************************************************************************************************\n",
    "#geo_clientes['geometry']=geo_clientes['geometry'].buffer(500)\n",
    "#***************************************************************************************************************\n",
    "geo_clientes['wkt'] = pd.Series(\n",
    "        map(lambda geom: geom.to_wkt(), geo_clientes['geometry']),\n",
    "        index=geo_clientes.index, dtype='object')\n",
    "coordinates = get_points_array(geo_clientes.geometry)\n",
    "geo_clientes.loc[:, 'longitud'], geo_clientes.loc[:, 'latitud'] = ds.utils.lnglat_to_meters(geo_clientes.lng,geo_clientes.lat)\n",
    "\n",
    "#geo_clientes.drop(columns='geometry', inplace=True) #la eliminamos pq spark no lo admite\n",
    "geo_cli_forspk=geo_clientes.drop(columns='geometry') #la eliminamos pq spark no lo admite\n",
    "geo_clientes_spk = dd.from_pandas(geo_cli_forspk, npartitions=mp.cpu_count())\n",
    "geo_clientes_spk.head(2)\n",
    "\n",
    "gdf_cmedico = gpd.GeoDataFrame( cpy_data_plot, geometry=gpd.points_from_xy(cpy_data_plot.lng, cpy_data_plot.lat))\n",
    "#gdf_cmedico.dropna(inplace=True)\n",
    "#ya no necesito cambiar el crs a mercator, ya que use_data_plot ya lo tiene asi.\n",
    "#gdf_cmedico.crs = {'init' :'epsg:4326'} \n",
    "#gdf_cmedico=gdf_cmedico.to_crs({'init': 'epsg:3857'})\n",
    "gdf_cmedico['wkt'] = pd.Series(\n",
    "        map(lambda geom: geom.to_wkt(), gdf_cmedico['geometry']),\n",
    "        index=gdf_cmedico.index, dtype='object')\n",
    "gdf_cmedico.loc[:, 'longitud'], gdf_cmedico.loc[:, 'latitud'] = ds.utils.lnglat_to_meters(gdf_cmedico.lng, gdf_cmedico.lat)\n",
    "\n",
    "#guardo una copia de gdf_cmedico ahora que aun tiene geometry.\n",
    "gdf_cmedico_com=gdf_cmedico.copy()\n",
    "#gdf_cmedico.drop(columns='geometry', inplace=True) #la eliminamos pq spark no lo admite\n",
    "gdf_cmedico_forspk=gdf_cmedico.drop(columns='geometry') #la eliminamos pq spark no lo admite.drop(columns='geometry', inplace=True) #la eliminamos pq spark no lo admite\n",
    "\n",
    "gdf_cmedico_spk = dd.from_pandas(gdf_cmedico_forspk, npartitions=mp.cpu_count())\n",
    "gdf_cmedico_spk.head(2)\n",
    "#geo_clientes_spk.head(2)\n",
    "\n",
    "print(\"forma de gdf_cmedico_spk: \", gdf_cmedico_spk.count().compute())\n",
    "coordinates[0:10]\n",
    "#geo_clientes[:, 'longitud'], geo_clientes[:, 'latitud']=zip(*coordinates)\n",
    "geo_clientes.head(2)\n",
    "#_____________________________________________________________________________________________________________\n",
    "#gdf_cmedico_spk=gdf_cmedico_spk.loc[gdf_cmedico_spk['PCMNFC']=='Dadisa'].copy()\n",
    "#es necesario resetear el indice antes de operar si hemos hecho un filtro y copiado con copy(), ya que\n",
    "#genera un objeto nuevo no un objeto referenciado. Como el filtro lo he hecho pra probar lo quito y quito\n",
    "#tambien el reset index y la linea de drop.\n",
    "#gdf_cmedico_spk=gdf_cmedico_spk.reset_index()\n",
    "#gdf_cmedico_spk=gdf_cmedico_spk.drop('index', axis=1)\n",
    "#asignamos un indice a wkt\n",
    "#gdf_cmedico_spk.set_index('wkt')\n",
    "#_____________________________________________________________________________________________________________\n",
    "gdf_cmedico_spk.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #convierto el dask dataframe de nuevo a pandas dataframe parapoder exportarlo a excel\n",
    "# gdf_cmedico_spk.reset_index()\n",
    "# tmp_datos=gdf_cmedico_spk.compute()\n",
    "# tmp_datos.to_excel('tmp_dask_gdf_cmedico.xlsx')\n",
    "geo_clientes_spk.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***************************************************************************************************************\n",
    "#esto ya no lo tengo que hacer porque lohe hecho en un paso previo cargando con wkt\n",
    "#***************************************************************************************************************\n",
    "Puntos_cmedico=[ Point(xy) for xy in zip (gdf_cmedico_spk['longitud'].compute(), gdf_cmedico_spk['latitud'].compute())]\n",
    "Puntos_clientes=[ Point(xy) for xy in zip (geo_clientes_spk['longitud'].compute(), geo_clientes_spk['latitud'].compute())]\n",
    "\n",
    "#hago este procedimiento con el dataframe no spark, no me fio de que cada lote lo trate de distinta forma\n",
    "#el algoritmo\n",
    "# Puntos_cmedico=[ Point(xy) for xy in zip (gdf_cmedico['longitud'], gdf_cmedico['latitud']) ]\n",
    "# Puntos_clientes=[ Point(xy) for xy in zip (geo_clientes['longitud'], geo_clientes['latitud']) ]\n",
    "#***************************************************************************************************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cmedico_spk.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctl_sel_proximidad=widgets.IntSlider(min=0, max=6000, step=500, value= 1500, description=\"m prox.\")\n",
    "display(ctl_sel_proximidad)\n",
    "#dir(widgets.IntSlider)\n",
    "print(ctl_sel_proximidad.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial import cKDTree\n",
    "#referenia:\n",
    "#https://pysal.org/scipy2019-intermediate-gds/deterministic/gds1-relations.html\n",
    "\n",
    "#Puntos_cmedico=Puntos_cmedico[0:30] #para debug\n",
    "Puntos_cmedico=get_points_array(Puntos_cmedico)\n",
    "\n",
    "#Puntos_clientes=Puntos_clientes[0:30] #para debug\n",
    "Puntos_clientes=get_points_array(Puntos_clientes)\n",
    "\n",
    "#si queremos asociar un calculo / medida de nuestro dataframe geo a los datos de cercania, podemos calcularlo\n",
    "#por ejemplo algo del tipo facturción del proveedor o numero de aat:\n",
    "# aat= ...\n",
    "#a posterior podriamos totalizarlo n el summarize posterior con una media o mediana y asociarlo a la\n",
    "#posiion de cercania\n",
    "#en mi ejemplo de momento hasa que lo pienese el summarize lo utillizo para contar cuantos clientes estan\n",
    "#a esaa distancia del proveedor.\n",
    "\n",
    "kdt = cKDTree(Puntos_cmedico)\n",
    "kdt_cli = cKDTree(Puntos_clientes)\n",
    "\n",
    "neighbors = kdt.query_ball_tree(kdt_cli, ctl_sel_proximidad.value)\n",
    "#***************************************************************************************************************\n",
    "# presta Atención!!!: al hacer la funcion entre parentesis en lugar de entre corchetes lo que estamos\n",
    "#haciendo es crear un generador sino devolveriamos una lista\n",
    "#***************************************************************************************************************\n",
    "#debug_vecinos=[[other for other in i_neighbors if other != i] for i,i_neighbors in enumerate(neighbors)]\n",
    "neighbors = ([other for other in i_neighbors if other != i] for i,i_neighbors in enumerate(neighbors))\n",
    "#***************************************************************************************************************\n",
    "#print(type(neighbors))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISEÑO PREVIO PARA CUANDO TENGA TODOS LOS RAMOS GEOLOCALIZADOS Y TENGA QUE DISTINGUIR X REDES\n",
    "filtro_Es_CCNN= ('RAMO in (3, 4, 8)' )\n",
    "tmp_clientes=geo_clientes_spk.compute().copy()\n",
    "Es_CCNN=  tmp_clientes.query('RAMO in (3,4,8 )') .copy()\n",
    "NO_Es_CCNN=  tmp_clientes.query('RAMO not in (3,4,8 )') .copy()\n",
    "# Es_CCNN=geo_clientes_spk.compute().query(~ filtro_Es_CCNN).index\n",
    "# geo_clientes_spk.compute().iloc[Es_CCNN].head(2)\n",
    "NO_Es_CCNN[0:2]\n",
    "Es_CCNN[0:2]\n",
    "NO_Es_CCNN[0:2].index\n",
    "#Una vez que tenga los indices que corresponden con uno u otro grupo, podre asignar los valores\n",
    "#calculados con cdktree segun corrsponda a una u otra red.\n",
    "#Para ello en lugar de pasar en la funcion anterior kdt.query_ball_tree(kdt_cli, 1500), tendré\n",
    "#que hacerlo en dos partes:\n",
    "#Es_CCNN, hallar index de este ttipo en kdt (geo_cmedico) e indices de este ipo en clientes y\n",
    "#lo mismo para la parte contraria q NO_es_CCNN\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# debug_vecinos[0]\n",
    "#coordenadas = get_points_array(gdf_cmedico_spk.geometry)\n",
    "#geo_clientes_spk.compute().iloc[debug_vecinos[0]]['RAMO']\n",
    "gdf_cmedico.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACT_q5 = mc.Quantiles(gdf_cmedico.FACTURACION_MENSUAL, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FACT_q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_for_clust=gdf_cmedico[['NAMEUNIT', 'PPSIUN', 'Shape__Are', 'PCMNAT', 'FACTURACION_MENSUAL'\n",
    "                             , 'geometry', 'longitud', 'latitud']]\n",
    "# datos_for_clust.loc[:, 'lng_mercator'], datos_for_clust.loc[:, 'lat_mercator'] = \\\n",
    "#         ds.utils.lnglat_to_meters(datos_for_clust['longitud'] ,datos_for_clust['latitud'])\n",
    "datos_for_clust.crs={'init': 'epsg:4326'}\n",
    "datos_for_clust=datos_for_clust.to_crs({'init': 'epsg:3857'})\n",
    "datos_for_clust.geometry\n",
    "datos_for_clust['geo_bufer_2km']=datos_for_clust.geometry.apply(lambda x: x.buffer(750) )\n",
    "datos_for_clust['geometry']=datos_for_clust.geo_bufer_2km\n",
    "wq2=lp.Queen.from_dataframe(datos_for_clust)\n",
    "wq2.transform='r'\n",
    "datos_for_clust.geo_bufer_2km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = ['FACTURACION_MENSUAL']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "#no necesito la doble tipificacion de datos numericos y categoricos ya que PPSIUN es la clave no una varible a usar.\n",
    "#el codigo esta aqui par usar cuando tenga datos categoricos que quiera incluir en el algoritmo\n",
    "categorical_features = ['PCMNAT']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='01')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf_factu = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "clf_factu.fit(datos_for_clust[['FACTURACION_MENSUAL', 'PCMNAT']])\n",
    "\n",
    "#print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Pre=clf_factu['preprocessor']\n",
    "Dt=Pre.transform(datos_for_clust)\n",
    "print(dir(Pre))\n",
    "Dt.todense()\n",
    "Dt.toarray()\n",
    "val=Dt[:,:1].toarray()\n",
    "nat=Dt[:,1:].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelk = AgglomerativeClustering(linkage='ward',\n",
    "                                connectivity=wq2.sparse,\n",
    "                                n_clusters=5)\n",
    "modelk.fit(Dt.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus_agg_natu=modelk.labels_\n",
    "datos_for_clust['cluster_agg_natu']=clus_agg_natu\n",
    "datos_for_clust.groupby(['cluster_agg_natu','PCMNAT']).agg('count').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns that you with to use for the dissolve and that will be retained\n",
    "dis_x_municipio = datos_for_clust[['NAMEUNIT', 'geometry']]\n",
    "\n",
    "# dissolve the state boundary by region \n",
    "municipios = dis_x_municipio.dissolve(by='NAMEUNIT')\n",
    "municipios\n",
    "municipios.reset_index().plot(column = 'NAMEUNIT', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the plot\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "\n",
    "# plot the data \n",
    "municipios.reset_index().plot(column = 'NAMEUNIT', ax=ax)\n",
    "\n",
    "# Set plot axis to equal ratio\n",
    "ax.set_axis_off()\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup figure and ax\n",
    "f, ax = plt.subplots(1, figsize=(15, 12))\n",
    "# Plot unique values choropleth including a legend and with no boundary lines\n",
    "datos_for_clust.plot(column='cluster_agg_natu', categorical=True, legend=True,cmap='OrRd', linewidth=0, ax=ax)\n",
    "# Remove axis\n",
    "ax.set_axis_off()\n",
    "# Keep axes proportionate\n",
    "plt.axis('equal')\n",
    "# Add title\n",
    "plt.title(r'Facturación según natups (Ward, $k=5$, Queen Contiguity)')\n",
    "# Display the map\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "datos_for_clust_plot=datos_for_clust[[ 'geometry',  'longitud', 'latitud',  'FACTURACION_MENSUAL',  'cluster_agg_natu']]\n",
    "datos_for_clust_plot['FACTURACION_MENSUAL'].fillna(0,inplace=True)\n",
    "\n",
    "datos_for_clust_plot2=datos_for_clust[[  'FACTURACION_MENSUAL',  'cluster_agg_natu']]\n",
    "\n",
    "ds_=hv.Dataset(datos_for_clust_plot,kdims=['lng', 'lat'] , vdims=['FACTURACION_MENSUAL', 'cluster_agg_natu'])\n",
    "ds2=hv.Dataset(datos_for_clust_plot2,kdims=['cluster_agg_natu'] , vdims=['FACTURACION_MENSUAL'])\n",
    "# ds_=hv.Dataset(datos_for_clust[['FACTURACION_MENSUAL', 'cluster_agg_natu', 'PCMNAT']] \n",
    "#               ,kdims=['PCMNAT' , 'cluster_agg_natu'] )\n",
    "# shade(rasterize(hv.Polygons(ds,kdims=['lng', 'lat'] , vdims=['FACTURACION_MENSUAL']).opts(min_width=500\n",
    "#             , min_height=400, responsive=True))) \\\n",
    "#     * gv.tile_sources.ESRI \n",
    "# hv.HexTiles(ds,kdims=['lng', 'lat'] , vdims=['FACTURACION_MENSUAL']).opts(colorbar=True, min_width=500\n",
    "#             , min_height=400, responsive=True,alpha=0.2 , scale=(dim('sum').norm()) )  \\\n",
    "#             * gv.tile_sources.ESRI .opts(alpha=0.9)\n",
    "#datos_for_clust.columns\n",
    "\n",
    "# ras=rasterize(ds_, aggregator=ds.mean('FACTURACION_MENSUAL'))\\\n",
    "#      .opts(colorbar=True, min_width=500 \\\n",
    "#              , min_height=400, responsive=True,alpha=0.5\n",
    "#              ,clim=(ds_['FACTURACION_MENSUAL'].min(), ds_['FACTURACION_MENSUAL'].max() ) \\\n",
    "#              * gv.tile_sources.ESRI.opts(alpha=0.1)\n",
    "           \n",
    "\n",
    "grouped =datashade( ds_.to(hv.Points, kdims=['lng', 'lat'] \\\n",
    "                 , groupby=['cluster_agg_natu' ])  \\\n",
    "                 , aggregator=ds.count('FACTURACION_MENSUAL'))\n",
    "print(ds_.dimensions)\n",
    "dims=ds_.dimensions()\n",
    "dir(dims)\n",
    "print(dir(dims[0]) )\n",
    "dims[0].get_param_values()\n",
    "dims[0].name\n",
    "len(dims[2].values)\n",
    "#gv.tile_sources.ESRI.opts(alpha=0.4, bgcolor=\"black\") * datashade(grouped).opts(opts.RGB(width=600, height=500 \\\n",
    "#                                , xaxis=None, yaxis=None, tools=['hover']))\n",
    "#datos_for_clust.columns\n",
    "help(ds_.to.points)\n",
    "gv.tile_sources.ESRI.opts(alpha=0.4, bgcolor=\"black\") * shade(grouped).opts(min_width=350, max_height=300 \\\n",
    "                             ,responsive=True , xaxis=None, yaxis=None, tools=['hover'])\n",
    "# ds2.to(hv.Bars).opts(width=600, height=500 \\\n",
    "#                               , xaxis=None, yaxis=None, tools=['hover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#si queremos asociar un calculo / medida de nuestro dataframe geo a los datos de cercania, podemos calcularlo\n",
    "#por ejemplo algo del tipo facturción del proveedor o numero de aat:\n",
    "# aat= ...\n",
    "#a posterior podriamos totalizarlo n el summarize posterior con una media o mediana y asociarlo a la\n",
    "#posiion de cercania\n",
    "#en mi ejemplo de momento hasa que lo pienese el summarize lo utillizo para contar cuantos clientes estan\n",
    "#a esaa distancia del proveedor.\n",
    "reg=0\n",
    "reg2=0\n",
    "\n",
    "\n",
    "def summarize(ary):\n",
    "    global reg\n",
    "    #return np.median(ary), np.std(ary)\n",
    "    reg+=1\n",
    "    if reg < 2 :\n",
    "        print(len(ary), ary)\n",
    "    #arr=np.asarray(ary)\n",
    "    \n",
    "    return len(ary)\n",
    "\n",
    "def summarize2(col_var_cal , var_vecino):\n",
    "    global reg2\n",
    "    #return np.median(ary), np.std(ary)\n",
    "    reg2+=1\n",
    "#     if reg2 < 2 :\n",
    "#         print(len(var_vecino), var_vecino)\n",
    "    #arr=np.asarray(ary)\n",
    "    try:\n",
    "        if(len(var_vecino)==0 ):\n",
    "            mediana=0\n",
    "        elif (len(var_vecino) <2):\n",
    "            mediana=np.max(col_var_cal)\n",
    "        else:\n",
    "            mediana=np.median(col_var_cal)\n",
    "    except:\n",
    "        mediana=0\n",
    "    \n",
    "    try:\n",
    "        if(len(var_vecino)==0 ):\n",
    "            dstd=0\n",
    "        elif (len(var_vecino) <2):\n",
    "            dstd=np.max(col_var_cal)\n",
    "        else:\n",
    "            dstd=np.std(col_var_cal)\n",
    "    except:\n",
    "        dstd=0\n",
    "\n",
    "    try:\n",
    "        t_primas=np.sum(col_var_cal)\n",
    "    except:\n",
    "        t_primas=0\n",
    "        \n",
    "    return t_primas, mediana, dstd, len(var_vecino)\n",
    "    \n",
    "\n",
    "\n",
    "# for vecino in neighbors:\n",
    "#     print(vecino)\n",
    "\n",
    "#total_cercanos = np.asarray([summarize(vecino) for vecino in neighbors]) \n",
    "#factu_mediana, factu_dstd , total_cercanos= np.asarray([summarize2( gdf_cmedico_spk['FACTURACION_MENSUAL'].compute() , vecino)  for vecino in neighbors]) \n",
    "facturacion=gdf_cmedico_spk['FACTURACION_MENSUAL'].compute()\n",
    "primas=geo_clientes_spk['PRIBEN'].compute()\n",
    "primas=primas.values\n",
    "# totalizando=np.asarray([summarize2( facturacion[vecino]  , vecino)  for vecino in neighbors])\n",
    "totalizando=np.asarray([summarize2( primas[vecino]  , vecino)  for vecino in neighbors])\n",
    "#factu_mediana, factu_dstd, total_cercanos=  zip(*totalizando)\n",
    "total_primas, primas_mediana, primas_dstd, total_cercanos=  zip(*totalizando)\n",
    "\n",
    "#print(total_cercanos)\n",
    "total_cercanos=np.asarray(total_cercanos)\n",
    "resdo=total_cercanos.flatten()\n",
    "\n",
    "# factu_mediana=np.asarray(factu_mediana)\n",
    "# factu_mediana=factu_mediana.flatten()\n",
    "\n",
    "# factu_dstd=np.asarray(factu_dstd)\n",
    "# factu_dstd=factu_dstd.flatten()\n",
    "\n",
    "primas_mediana=np.asarray(primas_mediana)\n",
    "primas_mediana=primas_mediana.flatten()\n",
    "\n",
    "primas_dstd=np.asarray(primas_dstd)\n",
    "primas_dstd=primas_dstd.flatten()\n",
    "\n",
    "total_primas=np.asarray(total_primas)\n",
    "total_primas=total_primas.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.CLASSIFIERS\n",
    "qj=mc.FisherJenks(geo_clientes['PRIBEN'])\n",
    "geo_clientes['clus_primas']=qj.yb\n",
    "\n",
    "#para añadir una columna a un dask dataframe no es posible hacerlo como cuando trabajamos\n",
    "#con un pandas dataframe normal, hay que convertir la matriz (array) que queramos añadir\n",
    "#a un array de tipo dask con dd.from_array(arr), después darle un nombre que será el nombre\n",
    "#con el que denominaremos a nuestra columna nueva y finalmente añadir esta dask array\n",
    "#mediante merge. Ver:\n",
    "res_clus = dd.from_array(qj.yb)\n",
    "# incluimos un nombre para nombrar la columna:\n",
    "res_clus.name = 'clus_primas'\n",
    "#por ultimo fusionamos con merge:\n",
    "geo_clientes_spk = geo_clientes_spk.merge(res_clus.to_frame())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_clientes_spk['PRIBEN'].compute().shape[0]\n",
    "m_pri=geo_clientes_spk['PRIBEN'].compute()\n",
    "m_pri=m_pri.values\n",
    "m_pri[0:100]\n",
    "#total_primas[10:15]\n",
    "geo_clientes_spk['PRIBEN'].describe().compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primas_mediana[0:100]\n",
    "primas_mediana[0:100]\n",
    "total_cercanos[0:100]\n",
    "total_primas[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(gdf_cmedico_spk['FACTURACION_MENSUAL'].compute())\n",
    "geo_clientes_spk.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#************************************************************************************************************\n",
    "#                        asignamos la nueva columna calculada con scipy ckdtree\n",
    "#************************************************************************************************************\n",
    "#resdo_entendible_dask = dd.from_array(resdo)\n",
    "#resdo_entendible = pd.Series(resdo)\n",
    "#resdo_entendible = pd.DataFrame(resdo, columns=['n_clientes_a_radio'])\n",
    "\n",
    "\n",
    "#he intentado muchas alternativas antes de dar con la solucion, unas de tantas\n",
    "#gdf_cmedico_spk = gdf_cmedico_spk.assign(n_clientes_a_radio= dd.from_array(resdo) )\n",
    "#gdf_cmedico_spk.append(resdo_entendible)\n",
    "# gdf_cmedico_spk_['n_clientes_a_radio']\\\n",
    "#             .apply([lambda x: x[n] for n, i in enumerate(resdo)], meta=('n_clientes_a_radio','f8'))\n",
    "#newSerie = gdf_cmedico_spk_.target.apply([i  for n, i in enumerate(resdo)], meta=(None, 'f8'))\n",
    "# gdf_cmedico_spk_['n_clientes_a_radio']=gdf_cmedico_spk_['n_clientes_a_radio'].apply( lambda x:\n",
    "#              (i  for n, i in enumerate(resdo) ) , meta=(None, 'f8') )\n",
    "#    \n",
    "#plantilla tutor\n",
    "#SGSCData['IsWorkDay'] = SGSCData.apply(lambda row: int(row.weekday<6 and not row.Date in NSWholidays), axis=1, meta=(None, 'int64'))\n",
    "\n",
    "darr = dd.from_array(resdo)\n",
    "# incluimos un nombre para nombrar la columna, en este caso: n_clientes_a_radio\n",
    "darr.name = 'n_clientes_a_radio'\n",
    "#por ultimo fusionamos con merge:\n",
    "gdf_cmedico_spk = gdf_cmedico_spk.merge(darr.to_frame())\n",
    "#type(gdf_cmedico_spk)\n",
    "darr_pd=darr.compute()                                                                         \n",
    "\n",
    "#ahora haremos lo mimso para los datos de facturacion:\n",
    "#factu_mediana[0:100]\n",
    "#factu_dstd[0:100]\n",
    "darr_mediana_primas = dd.from_array(primas_mediana)\n",
    "darr_dstd_primas = dd.from_array(primas_dstd)\n",
    "darr_tprimas = dd.from_array(total_primas)\n",
    "darr_mediana_primas.name='mediana_primas'\n",
    "darr_dstd_primas.name='desvstd_factu'\n",
    "darr_tprimas.name='total_primas'\n",
    "#fusionamos los datos\n",
    "#esto datos no valen pq son de los facturaodres y deberina ser de los clientes\n",
    "gdf_cmedico_spk = gdf_cmedico_spk.merge(darr_mediana_primas.to_frame())\n",
    "gdf_cmedico_spk = gdf_cmedico_spk.merge(darr_dstd_primas.to_frame())\n",
    "gdf_cmedico_spk = gdf_cmedico_spk.merge(darr_tprimas.to_frame())\n",
    "\n",
    "print(\"forma de arr solucion proximidad: \" , len(darr), len(resdo))\n",
    "print(\"forma de gdf_cmedico_spk: \", gdf_cmedico_spk.count().compute())\n",
    "\n",
    "gdf_cmedico_spk.head(2)\n",
    "#rehacemos use_data_plot con el resultado del calculo de clientes a radio que tenemos en dataframe spark\n",
    "use_data_plot=gdf_cmedico_spk.compute()\n",
    "\n",
    "#gdf_cmedico_spk['n_clientes_a_radio']=gdf_cmedico_spk['n_clientes_a_radio'].fillna(0)\n",
    "#use_data_plot['n_clientes_a_radio']=use_data_plot['n_clientes_a_radio'].fillna(0)\n",
    "\n",
    "use_data_plot.head(5)\n",
    "\n",
    "#************************************************************************************************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #convierto el dask dataframe de nuevo a pandas dataframe parapoder exportarlo a excel\n",
    "# tmp_datos=gdf_cmedico_spk.compute()\n",
    "# tmp_datos.to_excel('tmp_dask_gdf_cmedico.xlsx')\n",
    "# darr_pd.to_excel('tmp_dask_resdo_proxim.xlsx')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#NOTAS DEL COIGO:\n",
    "#DASK no admite insertar nuevas columnas como pandas dataframe, solo permite fusionarse con otras series o dataframes\n",
    "#por ese motivo para añadir una columnas/s nuevas el procedimeinto es como sigue:\n",
    "\n",
    "df = pd.DataFrame({'x': range(30), 'y': range(0,300, 10)})\n",
    "arr = np.random.randint(0, 100, size=30)\n",
    "\n",
    "# create dask frame and series\n",
    "ddf = ddf = dd.from_pandas(df, npartitions=5)\n",
    "darr = dd.from_array(arr)\n",
    "# give it a name to use as a column head\n",
    "darr.name = 'z'\n",
    "\n",
    "ddf2 = ddf.merge(darr.to_frame())\n",
    "\n",
    "ddf2\n",
    "darr"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dates = pd.date_range(start='2010-01-01', end='2012-01-01', freq=\"10S\")\n",
    "ddf = pd.DataFrame({\"Date\":dates})\n",
    "ddf = dd.from_pandas(ddf, npartitions=10)\n",
    "\n",
    "ddf[\"IsWorkDay\"] = (~(ddf[\"Date\"].dt.weekday>=5) \n",
    "                      \n",
    "                   ).astype(int)\n",
    "ddf.compute()\n",
    "ddf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gdf_cmedico_spk['n_clientes_a_radio'].head(20)\n",
    "#cpy_data_plot['n_clientes_a_radio'].head(20)\n",
    "cpy_data_plot.head(20)\n",
    "gdf_cmedico_spk.head(2)\n",
    "#gdf_cmedico.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cmedico_spk.head(3)\n",
    "#use_data_plot.shape[0]\n",
    "gdf_cmedico_spk.loc[gdf_cmedico_spk['PCMNFC']=='Dadisa'].head(10)\n",
    "use_data_plot.loc[use_data_plot['PCMNFC']=='Dadisa'].head(20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#assign_interseccion_clientes_cmedico(df_points, df_poligonos, num_crs, lon_var, lat_var, locid_var):\n",
    "#print(\"registros antes intersect: \" , gdf_cmedico_spk.count().compute())\n",
    "geo_cm_cli=assign_interseccion_clientes_cmedico(gdf_cmedico_spk, geo_clientes, 3857, \"lng\", \"lat\", \"CODIGO_PERSONA\" )\n",
    "#print(\"registros post intersect: \" , gdf_cmedico_spk.count().compute())\n",
    "\n",
    "geo_cm_cli"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#la unión por sjoin es muy costosa y eso sólo con una provincia, en el caso que fuera toda España seria inviable.\n",
    "geo_cli_cm = gpd.sjoin(gdf_cmedico, geo_clientes, how='left',op='within') \n",
    "#geo_cli_cm[['geometry','Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ]].head()\n",
    "geo_cli_cm.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_factu=use_data_plot['PCMNFC'].unique()\n",
    "lst_factu=list(lst_factu)\n",
    "lst_factu=[ x.strip() for x in lst_factu]\n",
    "lst_factu.sort()\n",
    "lst_factu.insert(0, 'Todos')\n",
    "lst_factu\n",
    "lst_factu=np.asarray(lst_factu)\n",
    "lst_factu\n",
    "\n",
    "lst_prof=use_data_plot['PCMNPR'].unique()\n",
    "lst_prof=list(lst_prof)\n",
    "lst_prof=[ x.strip() for x in lst_prof]\n",
    "lst_prof.sort()\n",
    "lst_prof.insert(0, 'Todos')\n",
    "lst_prof\n",
    "lst_prof=np.asarray(lst_prof)\n",
    "lst_prof\n",
    "\n",
    "lst_espec=use_data_plot['PCMEDS'].unique()\n",
    "lst_espec=list(lst_espec)\n",
    "lst_espec=[ x.strip() for x in lst_espec]\n",
    "lst_espec.sort()\n",
    "lst_espec.insert(0, 'Todas')\n",
    "lst_espec\n",
    "lst_espec=np.asarray(lst_espec)\n",
    "lst_espec\n",
    "\n",
    "lst_nomps=use_data_plot['PCMNPS'].unique()\n",
    "lst_nomps=list(lst_nomps)\n",
    "lst_nomps=[ x.strip() for x in lst_nomps]\n",
    "lst_nomps.sort()\n",
    "lst_nomps.insert(0, 'Todos')\n",
    "lst_nomps\n",
    "lst_nomps=np.asarray(lst_nomps)\n",
    "lst_nomps\n",
    "\n",
    "lst_natups=use_data_plot['PCMNAT'].unique()\n",
    "lst_natups=list(lst_natups)\n",
    "lst_natups=[ x.strip() for x in lst_natups]\n",
    "lst_natups.sort()\n",
    "lst_natups.insert(0, 'Todas')\n",
    "lst_natups\n",
    "lst_natups=np.asarray(lst_natups)\n",
    "lst_natups\n",
    "\n",
    "lst_red=use_data_plot['PCMRDS'].unique()\n",
    "lst_red=list(lst_red)\n",
    "lst_red=[ x.strip() for x in lst_red]\n",
    "lst_red.sort()\n",
    "lst_red.insert(0, 'Todas')\n",
    "lst_red\n",
    "lst_red=np.asarray(lst_red)\n",
    "lst_red\n",
    "\n",
    "lst_direccion=use_data_plot['dircompleta'].unique()\n",
    "lst_direccion=list(lst_direccion)\n",
    "lst_direccion=[ x.strip() for x in lst_direccion]\n",
    "lst_direccion.sort\n",
    "lst_direccion.insert(0, 'Todas')\n",
    "lst_direccion=np.asarray(lst_direccion)\n",
    "\n",
    "lst_agrup_servicio=use_data_plot['PCMEGD'].unique()\n",
    "lst_agrup_servicio=list(lst_agrup_servicio)\n",
    "lst_agrup_servicio=[ x.strip() for x in lst_agrup_servicio]\n",
    "lst_agrup_servicio.sort()\n",
    "lst_agrup_servicio.insert(0, 'Todos')\n",
    "lst_agrup_servicio\n",
    "lst_agrup_servicio=np.asarray(lst_agrup_servicio)\n",
    "lst_agrup_servicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(use_data_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [t[0] + t[1] + t[2] for t in zip('abcdefghijklmnopqrstuvwxyz','bcdefghijklmnopqrstuvwxyza', 'cdefghijklmnopqrstuvwxyzab')]\n",
    "options = dict(zip(labels, range(len(labels))))\n",
    "\n",
    "multi = pn.widgets.MultiSelect(options=options)\n",
    "sort = pn.widgets.Button(name='▼', width=40)\n",
    "filt = pn.widgets.AutocompleteInput(options=list(options.keys()), placeholder='Filter')\n",
    "\n",
    "sort.jslink(multi, code={'clicks': \"\"\"\n",
    "source.label = source.clicks % 2 ? '▼' : '▲';\n",
    "target.options = source.clicks % 2 ? target.options.sort() : target.options.reverse();\n",
    "console.log(target.options[0]);\n",
    "console.log(source.clicks);\n",
    "\"\"\"})\n",
    "\n",
    "filt.jslink(multi, code={'value': \"\"\"\n",
    "target.value = target.options.filter(label => label.includes(source.value));\n",
    "console.log(target.value);\n",
    "\"\"\"})\n",
    "\n",
    "result = pn.pane.Str('')\n",
    "multi.link(result, value='object')\n",
    "\n",
    "pn.Column(pn.Row(sort, filt, margin=0), multi, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "filt = pn.widgets.AutocompleteInput(options=list(lst_direccion), placeholder='Filter')\n",
    "pn.Column(filt)\n",
    "#lst_direccion[1]\n",
    "\n",
    "\n",
    "dir(param.String)\n",
    "parte_direccion=param.String( default='', label='parte direccion')\n",
    "pn.Column(text1)\n",
    "idx_filtro=use_data_plot['dircompleta'].loc[use_data_plot['dircompleta'].str.contains('Augusto', regex=False)].index\n",
    "idx_filtro\n",
    "# idx_filtro[0:15]\n",
    "# use_data_plot['dircompleta'].iloc[idx_filtro].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = pn.widgets.MultiSelect(options=options)\n",
    "multi.size=3\n",
    "multi.value=[0]\n",
    "print(multi.value)\n",
    "pn.Column( multi, options)\n",
    "\n",
    "mul=pn.param.MultiSelect(options=options, size=3, value=[0])\n",
    "pn.Column(mul)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn = pyodbc.connect(\"dsn=PRODUCCION\",UID=\"JAVIERBS\",PWD=\"ANASERJBS123456\")\n",
    "\n",
    "SQL_tipo_facturador=\"\"\"SELECT * FROM (SELECT ACQSUC, PNMNV1, PNMNV2, PPSIUN , SUM(ACQIMP) AS TOTAL  FROM QS36F.ACUCHEQAC T1\n",
    "                            LEFT JOIN PROVEEDOR.PRVNOMEN T2 ON T1.ACQESP=T2.PNMESP AND T1.ACQBAR=T2.PNMACT\n",
    "                            INNER JOIN PROVEEDOR.PRVPTOSER T3 ON T1.ACQNFA=T3.PPSFAC AND T1.ACQDSR=T3.PPSCEN AND T1.ACQCSR=T3.PPSCIA AND T1.ACQSUC=T3.PPSSUC\n",
    "                             WHERE ACQSUC=50 AND DATE(ACQFCA CONCAT '-' CONCAT ACQFCM CONCAT '-' CONCAT ACQFCD ) < CURRENT_DATE - 3 MONTHS\n",
    "                            GROUP BY ACQSUC, PNMNV1, PNMNV2  , PPSIUN\n",
    "                            UNION \n",
    "                            SELECT ACQSUC, PNMNV1, PNMNV2, PPSIUN, SUM(ACQIMP) AS TOTAL  FROM QS36F.ACUCHEQ18 T1\n",
    "                            LEFT JOIN PROVEEDOR.PRVNOMEN T2 ON T1.ACQESP=T2.PNMESP AND T1.ACQBAR=T2.PNMACT\n",
    "                             INNER JOIN PROVEEDOR.PRVPTOSER T3 ON T1.ACQNFA=T3.PPSFAC AND T1.ACQDSR=T3.PPSCEN AND T1.ACQCSR=T3.PPSCIA AND T1.ACQSUC=T3.PPSSUC\n",
    "                             WHERE ACQSUC=50 AND DATE(ACQFCA CONCAT '-' CONCAT ACQFCM CONCAT '-' CONCAT ACQFCD ) < CURRENT_DATE - 3 MONTHS\n",
    "                            GROUP BY ACQSUC, PNMNV1, PNMNV2, PPSIUN  \n",
    "                           \n",
    "                             ) STROS \"\"\"\n",
    "datos_tipfac= pd.read_sql(SQL_tipo_facturador,cnxn)\n",
    "datos_tipfac.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_tipfac=datos_tipfac.loc[datos_tipfac['TOTAL'] >= 0].copy()\n",
    "datos_tipfac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos_tipfac['PNMNV2'].fillna(99, inplace=True)\n",
    "datos_tipfac['setagrup']=datos_tipfac[[\"PNMNV1\",\"PNMNV2\"]].apply(lambda row: str(row[\"PNMNV1\"]) + str(row[\"PNMNV2\"]) , axis=1)\n",
    "\n",
    "datos_tipfac[\"setagrup\"].unique()\n",
    "datos_tipfac.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_tipfac_totxagrup = datos_tipfac.groupby(['PPSIUN', 'setagrup']).agg({'TOTAL': 'sum'})\n",
    "datos_tipfac_pct = datos_tipfac_totxagrup.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))\n",
    "datos_tipfac_pct.reset_index(inplace=True)\n",
    "datos_tipfac_pct.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_tipfac=datos_tipfac_pct\n",
    "# datos_tipfac2=datos_tipfac.pivot_table(values='TOTAL', index='PPSIUN', columns='setagrup', \n",
    "#                          aggfunc=lambda x: len(x.dropna().unique())   )\n",
    "datos_tipfac2=datos_tipfac.pivot_table(values='TOTAL', index='PPSIUN', columns='setagrup', \n",
    "                         aggfunc=lambda x: x.sum()   )\n",
    "datos_tipfac2.fillna(0, inplace=True)\n",
    "#datos_tipfac2[\"ID\"]=datos_tipfac2.index\n",
    "datos_tipfac2=datos_tipfac2.reset_index()\n",
    "datos_tipfac2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducimos la dimensionalidad que nos da utilizar todos los tipos de combinacione del agrupador de pnmnv1 pnmnv2\n",
    "from sklearn.decomposition import PCA\n",
    "#pca = PCA(n_components=0.75, svd_solver = 'full')\n",
    "pca = PCA(n_components=5, svd_solver = 'full')\n",
    "vals=datos_tipfac2.values[:,1:]\n",
    "pca.fit(vals)\n",
    "X=pca.transform(vals)\n",
    "len(X[0])\n",
    "X[:,0]\n",
    "X\n",
    "col_pca=[]\n",
    "for i in range(0, len(X[0])):\n",
    "    #print(i)\n",
    "    col_pca.append(\"PCA_\" + str(i+1))\n",
    "col_pca\n",
    "red_dimen=pd.DataFrame(X, columns=col_pca)\n",
    "keys_ppsiun=datos_tipfac2[['PPSIUN']].copy()\n",
    "red_dimen.head(2)\n",
    "df_resultante=pd.concat([keys_ppsiun, red_dimen ], axis=1 , ignore_index=False)\n",
    "df_resultante.dropna(inplace=True)\n",
    "df_resultante.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultante.loc[pd.isna(df_resultante['PPSIUN'])==True].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import NearestNeighbors \n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "\n",
    "# enc = OneHotEncoder(handle_unknown='ignore')\n",
    "# X_array=np.asarray(df_resultante[\"setagrup\"].unique())\n",
    "# #enc.fit(X)\n",
    "# X_array=X_array.reshape(-1,1)\n",
    "# totales=df_resultante['TOTAL'].values\n",
    "# X_indice=pd.DataFrame(X_array, index=range(0, len(X_array)))\n",
    "# X_indice['idx']=X_indice.index\n",
    "# X=X_indice.values\n",
    "# X_fit= enc.fit(X)\n",
    "# X_codificada=enc.transform(X).toarray()\n",
    "\n",
    "\n",
    "#datos_tipfac=datos_tipfac[[\"PPSIUN\",\"setagrup\", \"TOTAL\"]]\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = col_pca\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "#no necesito la doble tipificacion de datos numericos y categoricos ya que PPSIUN es la clave no una varible a usar.\n",
    "#el codigo esta aqui par usar cuando tenga datos categoricos que quiera incluir en el algoritmo\n",
    "categorical_features = ['PPSIUN']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numeric_transformer, numeric_features),\n",
    "#         ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('vecinos',  NearestNeighbors(n_neighbors=20, algorithm='ball_tree')  )])\n",
    "\n",
    "clf.fit(df_resultante)\n",
    "#print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pre=clf['preprocessor']\n",
    "D=Pre.transform(df_resultante)\n",
    "print(\"forma de D\", D.shape)\n",
    "A = clf['vecinos']\n",
    "\n",
    "distancias, idx = A.kneighbors(D)\n",
    "distancias\n",
    "idx[20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distancias=np.sort(distancias, axis=0)\n",
    "print(distancias.ravel().shape)\n",
    "distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(distancias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#el eps (epsilon) optimo es el dpunto donde se da la maxima curvatura. En este caso es 0.8-0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultante.iloc[[  20, 317,  42,  33, 222, 363, 432, 248, 197, 345, 138, 169,  92,\n",
    "        93, 214, 128, 166, 410, 118, 103]]['PPSIUN'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdo = A.kneighbors_graph(D)\n",
    "rdo.toarray()[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### from sklearn.cluster import DBSCAN\n",
    "# Compute DBSCAN\n",
    "#db = DBSCAN(eps=1.26, min_samples=5 ).fit(D)\n",
    "db = DBSCAN(eps=0.9, min_samples=5 ).fit(D)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "labels\n",
    "core_samples_mask\n",
    "# # Number of clusters in labels, ignoring noise (-1) if present.\n",
    "# n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "# n_noise_ = list(labels).count(-1)\n",
    "# n_clusters_\n",
    "# db.core_sample_indices_\n",
    "print(set(db.labels_))\n",
    "\n",
    "for i in range(len(set(labels))-1):\n",
    "    print(\"cta de \", str(i), \": \", list(labels).count(i) )\n",
    "    \n",
    "print(\"cta de ruido (-1) \", list(labels).count(-1) )\n",
    "\n",
    "print(datos_tipfac.shape, df_resultante.shape)\n",
    "df_resultante[\"cluster\"]=labels\n",
    "df_resultante.head(10)\n",
    "df_resultante.loc[df_resultante[\"cluster\"]==2].head(2)\n",
    "rdo=df_resultante[['PPSIUN', 'cluster']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdo.loc[rdo[\"cluster\"] == 1].head(5)\n",
    "rdo.loc[rdo[\"cluster\"] == 0]['PPSIUN'].unique()\n",
    "rdo.to_excel(\"clusters_cm_Zaragoza.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst_clusters=df_resultante[\"cluster\"].unique()\n",
    "lst_clusters_dic=dict([( \"tipo_facturacion_\" + str(n) , n ) for n in lst_clusters[ (lst_clusters != -1 ) \\\n",
    "                                                            & (lst_clusters != 0) ] ])\n",
    "lst_clusters_dic\n",
    "#lst_clusters.sort()\n",
    "lst_clusters={}\n",
    "\n",
    "lst_clusters[\"Todos\"]=999\n",
    "lst_clusters[\"indeterminados\"]=-1\n",
    "lst_clusters[\"sin analizar\"]=-2\n",
    "lst_clusters[\"genéricos\"]=0\n",
    "lst_clusters_dic\n",
    "for k in lst_clusters_dic.keys():\n",
    "    lst_clusters[k]=lst_clusters_dic[k]\n",
    "lst_clusters\n",
    "# lst_clusters=list(lst_clusters)\n",
    "# #lst_clusters=[ x.strip() for x in lst_clusters]\n",
    "# lst_clusters.sort()\n",
    "# lst_clusters.insert(0, 'Todos')\n",
    "# lst_clusters\n",
    "# lst_clusters=np.asarray(lst_clusters)\n",
    "# lst_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rdo.head(2)\n",
    "use_data_plot=use_data_plot.merge(rdo, how='left', left_on='PCMIUN', right_on='PPSIUN')\n",
    "if 'PPSIUN_y' in use_data_plot.columns:\n",
    "    use_data_plot=use_data_plot.drop(columns=['PPSIUN_y'])\n",
    "    \n",
    "use_data_plot.fillna(-2, inplace=True) #sin analizar (-2)\n",
    "use_data_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn = pyodbc.connect(\"dsn=PRODUCCION\",UID=\"JAVIERBS\",PWD=\"ANASERJBS123456\")\n",
    "sql_encu=\"\"\"SELECT NIF_PROF_CENTRO, NOM_PROF_CENTRO, PREGUNTA\n",
    ", CAST(AVG( CAST(RESPUESTA_SRV AS NUMERIC(4,1))) AS NUMERIC(4,1))  AS PRESP, COUNT(*) AS CTA \n",
    "FROM QS36F.SURVEY_ENCUESTA_ECO WHERE PREGUNTA=5 GROUP BY NIF_PROF_CENTRO, NOM_PROF_CENTRO, PREGUNTA\"\"\"\n",
    "\n",
    "sql_encu=\"\"\"\n",
    "SELECT PNIFP  as nif_prof_centro, PMVAL AS PRESP FROM PROVEEDOR.PECPRANK WHERE PIPRE=5\n",
    "UNION\n",
    "SELECT  PCIF,  CAST (AVG(PMVAL)  AS NUMERIC(5,2) ) AS PMVAL FROM PROVEEDOR.PECCRANK WHERE PIPRE=5 GROUP BY PCIF \n",
    "--HACO MEDIA XQ EN CENTROS TENEMOS PSERVICIO PERO DE MOMENTO YO HAGO EL MERGE X NIF SI CAMBIASE DE OPINION ...\"\"\"\n",
    "datos_encu=pd.read_sql(sql_encu,cnxn)\n",
    "datos_encu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data_plot=use_data_plot.merge(datos_encu, how='left', left_on='PCMNFF', right_on='NIF_PROF_CENTRO')\n",
    "#use_data_plot=use_data_plot.drop(columns=['NIF_PROF_CENTRO','NOM_PROF_CENTRO' ,'PREGUNTA', 'CTA'])\n",
    "use_data_plot=use_data_plot.drop(columns=['NIF_PROF_CENTRO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bokeh.models import GeoJSONDataSource, HoverTool, CategoricalColorMapper, LinearColorMapper\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.palettes import Category10, Category20\n",
    "\n",
    "print(gdf_cmedico.columns)\n",
    "print(gdf_cmedico.shape)\n",
    "gdf_cmedico.geometry\n",
    "muni_df.geometry\n",
    "print(muni_df.columns)\n",
    "gdf_cmedico[['NAMEUNIT', 'CMUN_PRO', 'C_MUN_PRO']].describe()\n",
    "muni_df.head()\n",
    "\n",
    "muni_df.dtypes\n",
    "muni_df['CODIGOINE']=muni_df['CODIGOINE'].astype('float')\n",
    "combi1=gdf_cmedico.merge( muni_df, how='inner', left_on='C_MUN_PRO', right_on='CODIGOINE')\n",
    "#combi1.drop(columns='geometry_x', axis=1)\n",
    "combi1['geometry']=combi1['geometry_y']\n",
    "print(combi1.columns)\n",
    "#combi1.plot(column='CODIGOINE', categorical=True)\n",
    "\n",
    "\n",
    "\n",
    "factors = combi1.NAMEUNIT_x.drop_duplicates()\n",
    "ndim=len(factors)\n",
    "\n",
    "# combi1=combi1[['NAMEUNIT_x', 'FACTURACION_MENSUAL', 'geometry']].groupby(['NAMEUNIT_x'])\\\n",
    "#     .agg('sum').reset_index().head()\n",
    "combi1 = gpd.GeoDataFrame( combi1, geometry=combi1['geometry'])\n",
    "\n",
    "print(type(gdf_cmedico), type(muni_df), type(combi1) )\n",
    "\n",
    "combi1=combi1[['NAMEUNIT_x', 'FACTURACION_MENSUAL', 'geometry']]\n",
    "combi1=combi1.dissolve(by='NAMEUNIT_x', aggfunc='sum').reset_index()\n",
    "combi1['tipo_geometria']=combi1.geometry.geom_type\n",
    "\n",
    "combi1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data_plot['ACTOS'].fillna(0, inplace=True)\n",
    "use_data_plot['AAT'].fillna(0, inplace=True)\n",
    "print(use_data_plot.columns)\n",
    "#use_data_plot.drop(['cluster_x', 'cluster_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combi1.plot(column='FACTURACION_MENSUAL', categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bqplot import *\n",
    "\n",
    "dat_hmap=use_data_plot[['PCMIUN','PCMEGD', 'AAT','FACTURACION_MENSUAL']] \\\n",
    "        .loc[use_data_plot['PCMRCD']==1].groupby(['PCMIUN','PCMEGD'])\\\n",
    "        .agg(\"sum\").reset_index()\n",
    "dat_hmap=dat_hmap.loc[dat_hmap['AAT'] > 0]\n",
    "ds_hmap=hv.Dataset(dat_hmap, kdims=['PCMIUN','PCMEGD'], vdims=['AAT','FACTURACION_MENSUAL'])\n",
    "hmap=hv.HeatMap(ds_hmap,vdims=['AAT','FACTURACION_MENSUAL'])\n",
    "hmap=hv.Scatter(ds_hmap,vdims=['AAT','FACTURACION_MENSUAL']).opts(width=800, height=500\n",
    "                                                      , tools=[\"hover\"])\n",
    "ds_hmap.to(hv.Bars,kdims=['PCMIUN'], vdims=['FACTURACION_MENSUAL'])\n",
    "hv.Bars(ds_hmap,vdims=['AAT','FACTURACION_MENSUAL'])\n",
    "#ds_hmap.to(hv.Table)\n",
    "\n",
    "dat_hmap2=use_data_plot[['PCMIUN', 'PCMEGD','PCMEDS','FACTURACION_MENSUAL', 'AAT']] \\\n",
    "        .loc[use_data_plot['PCMRCD']==1].groupby(['PCMEGD', 'PCMEDS'])\\\n",
    "        .agg(\"sum\").reset_index()\n",
    "dat2=hv.Dataset(dat_hmap2, kdims=['PCMIUN' ], vdims=['FACTURACION_MENSUAL', 'PCMEDS', 'PCMEGD'])\n",
    "barras=dat2.to(hv.Bars,  'FACTURACION_MENSUAL', 'FACTURACION_MENSUAL', [ 'PCMIUN', 'PCMEDS', 'PCMEGD']).opts(width=600, height=400, tools=[\"hover\"]) \n",
    "#help(hv.Bars)\n",
    "print(dir(barras))\n",
    "barras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pn.extension(comms='ipywidgets')\n",
    "dat_hmap3=use_data_plot[[ 'PCMEGD','FACTURACION_MENSUAL', 'AAT', 'PCMIUN', 'PCMNFC', 'longitud', 'latitud']] \\\n",
    "        .loc[use_data_plot['PCMRCD']==1].groupby(['PCMEGD', 'PCMIUN', 'PCMNFC', 'longitud', 'latitud'])\\\n",
    "        .agg(\"sum\").reset_index()\n",
    "dshmap3=hv.Dataset(dat_hmap3)\n",
    "dat_hmap3.head()\n",
    "hv.Scatter( dat_hmap3, ['FACTURACION_MENSUAL', 'AAT']  ,vdims=['PCMEGD', 'PCMIUN', 'PCMNFC'])\\\n",
    "            .opts(width=600, height=500,size=6,tools=[\"hover\"], colorbar=True, cmap='fire')\n",
    "hv.HeatMap( dat_hmap3, ['FACTURACION_MENSUAL', 'AAT']  ,vdims=['longitud', 'latitud','PCMEGD', 'PCMIUN', 'PCMNFC'])\\\n",
    "            .opts(width=600, height=500,tools=[\"hover\"], colorbar=True, cmap='fire')\n",
    "\n",
    "hm=dshmap3.to(hv.HeatMap,  ['FACTURACION_MENSUAL', 'AAT']\n",
    "              , 'longitud'\n",
    "             #, [ 'PCMEGD', 'PCMIUN', 'PCMNFC'] \n",
    "           \n",
    "             , [ 'PCMNFC']\n",
    "             ).opts(width=400, height=250,tools=[\"hover\"], colorbar=True, cmap='fire_r') \n",
    "\n",
    "hv.output(hm, max_frames=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(datashade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bokeh.models import HoverTool\n",
    "\n",
    "\n",
    "dat_hmap3=use_data_plot[[ 'PCMEGD','FACTURACION_MENSUAL', 'longitud', 'latitud']] \\\n",
    "        .loc[use_data_plot['PCMRCD']==1].groupby(['PCMEGD', 'longitud', 'latitud'])\\\n",
    "        .agg(\"sum\").reset_index()\n",
    "dat_hmap3=dat_hmap3.set_index(['PCMEGD', 'longitud', 'latitud'])\n",
    "gridded_arr=dat_hmap3.to_xarray()\n",
    "gridded_arr\n",
    "xr_dataset = gv.Dataset(gridded_arr, kdims=['PCMEGD', 'longitud', 'latitud']\n",
    "                        , vdims=[('FACTURACION_MENSUAL', 'Factu.     mes')], crs=crs.Mercator())\n",
    "#dshmap3=hv.Dataset(dat_hmap3, kdims=['PCMEGD', 'longitud', 'latitud', 'PCMNFC'], vdims='FACTURACION_MENSUAL')\n",
    "\n",
    "type(xr_dataset)\n",
    "\n",
    "geo_dims = ['longitud', 'latitud']\n",
    "imagen=xr_dataset.to(hv.QuadMesh, geo_dims ) .opts(tools=[\"hover\"], width=600)\n",
    "#pn.panel(imagen, widget_location='bottom')\n",
    "imagen*gv.tile_sources.ESRI.opts(alpha=0.5)\n",
    "\n",
    "dynamic_hover = (spread(datashade(hv.Points( xr_dataset , kdims=['longitud', 'latitud']\n",
    "                            , vdims=[('FACTURACION_MENSUAL', 'Factu mes'), ( 'PCMEGD', 'Agrup. acti')]  )\n",
    "                            ,normalization='eq_hist', aggregator=ds.sum('FACTURACION_MENSUAL') , width=400, height=400)) * \n",
    "                 hv.util.Dynamic(rasterize(hv.Points( xr_dataset, kdims=['longitud', 'latitud']\n",
    "                , vdims=[('FACTURACION_MENSUAL', 'Factu mes'), ( 'PCMEGD', 'Agrup. acti')] ) \n",
    "                               , aggregator=ds.sum('FACTURACION_MENSUAL') \n",
    "                                           , width=20, height=20, streams=[RangeXY]), operation=hv.QuadMesh))\n",
    "\n",
    "hover = HoverTool(tooltips=[(\"Facturación\", \"@FACTURACION_MENSUAL{int}\")])\n",
    "( dynamic_hover ).opts(opts.QuadMesh(tools=[hover], alpha=0, hover_alpha=0.3)) *gv.tile_sources.ESRI.opts(alpha=0.3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = gv.Points([(-74.01, 40.71, 'New York'), (0.13, 51.51, 'London'), (116.40, 39.9, 'Beijing')], vdims='City')\n",
    "ds_cities = gv.Dataset([(-74.01, 40.71, 'New York'), (0.13, 51.51, 'London'), (116.40, 39.9, 'Beijing')], vdims='City')\n",
    "projected = gv.operation.project(cities, projection=crs.GOOGLE_MERCATOR)\n",
    "projected2= gv.operation.project(ds_cities, projection=crs.GOOGLE_MERCATOR)\n",
    "print(projected.crs)\n",
    "print(type(projected))\n",
    "print(type(ds_cities))\n",
    "projected.dframe()\n",
    "projected2.dframe() #como se puede ver no se puede proyectar un cambio de crs a un dataset si a Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_clientes2 = gpd.GeoDataFrame( info_clientes, geometry=info_clientes['geometry'])\n",
    "geo_clientes2.head()\n",
    "#ds4=gv.Dataset(geo_clientes2, kdims=['longitud', 'latitutd'] , crs=crs.GOOGLE_MERCATOR )\n",
    "ds4p=gv.Points(geo_clientes2, kdims=['longitud', 'latitutd'] )\n",
    "ds4rp= gv.operation.project(ds4p, projection=crs.GOOGLE_MERCATOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds4rp.dframe()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "use_color2=fire[::-5]\n",
    "spread(datashade(ds4rp, cmap= use_color2,  width=600, height=450)) \\\n",
    "* ( dynamic_hover ).opts(opts.QuadMesh(tools=[hover], alpha=0, hover_alpha=0.7)) \\\n",
    "    * gv.tile_sources.ESRI.opts(alpha=0.3, global_extent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(xr_dataset)\n",
    "# hv.extension('bokeh')\n",
    "# pn.extension()\n",
    "# pn.extension('plotly')\n",
    "# hv.extension('matplotlib')\n",
    "# xr_dataset.to(hv.HeatMap, kdims=['longitud', 'latitud'], vdims=['FACTURACION_MENSUAL'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_hmap3=dat_hmap3.reset_index()\n",
    "dat_hmap3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies, edges = np.histogram(dat_hmap3[['FACTURACION_MENSUAL', 'FACTURACION_MENSUAL']].values, 10)\n",
    "frequencies\n",
    "edges\n",
    "hv.Histogram(frequencies, edges).opts(tools=[\"hover\"],width=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pane = pn.panel('<marquee>Here is some custom HTML</marquee>')\n",
    "pn.extension(comms='ipywidgets')\n",
    "print(dir(pn))\n",
    "pane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "barras.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(barras.params('sort') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim1=barras.get_param_values('PCMEDS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(dim1))\n",
    "dim1.insert(0, 'Todos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(barras.kdims))\n",
    "barras.kdims.clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_countries = {\n",
    "    'Africa': ['Ghana', 'Togo', 'South Africa'],\n",
    "    'Asia'  : ['China', 'Thailand', 'Japan'],\n",
    "    'Europe': ['Austria', 'Bulgaria', 'Greece']\n",
    "}\n",
    "\n",
    "continent = pn.widgets.Select(\n",
    "    value='Asia', \n",
    "    options=['Africa', 'Asia', 'Europe']\n",
    ")\n",
    "\n",
    "country = pn.widgets.Select(\n",
    "    value=_countries[continent.value][0], \n",
    "    options=_countries[continent.value]\n",
    ")\n",
    "\n",
    "@pn.depends(continent.param.value, watch=True)\n",
    "def _update_countries(continent):\n",
    "    countries = _countries[continent]\n",
    "    country.options = countries\n",
    "    country.value = countries[0]\n",
    "\n",
    "pn.Row(continent, country)\n",
    "\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.layouts import row\n",
    "\n",
    "renderer = hv.renderer('bokeh').instance(mode='server')\n",
    "\n",
    "dmap1 = hv.DynamicMap(lambda x: hv.Curve(np.random.rand(10)), kdims='x').redim.range(x=(0,5))\n",
    "dmap2 = hv.DynamicMap(lambda y: hv.Scatter(np.random.rand(10)), kdims='y').redim.range(y=(0,5))\n",
    "\n",
    "widget1 = renderer.get_widget(dmap1, None, position='above').state\n",
    "widget2 = renderer.get_widget(dmap2, None, position='above').state\n",
    "\n",
    "\n",
    "r = row(widget1, widget2)\n",
    "\n",
    "# doc = curdoc()\n",
    "# doc.add_root(r)\n",
    "\n",
    "pn.Row( r)\n",
    "#NO ADQUIERE LA FUNCIONALIDAD DEL DYNAMIC MAP CUANDO CAMBIA EL WIDGET SI LO HACEMOS ASI\n",
    "#OBTENIENDO EL WIDGET DESDE EL RENDERER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn = pyodbc.connect(\"dsn=PRODUCCION\",UID=\"JAVIERBS\",PWD=\"ANASERJBS123456\")\n",
    "\n",
    "today=datetime.today().strftime(\"%Y/%m/%d\")\n",
    "file_anioanterior=str(int(today[:4])-1)[2:]\n",
    "file_anioanterior='ACUCHEQ'+ file_anioanterior\n",
    "file_anioanterior\n",
    "\n",
    "SQL_moni_activ=\"\"\"SELECT * FROM (SELECT DATE(ACQFCA CONCAT '-' CONCAT ACQFCM CONCAT '-' CONCAT ACQFCD) as fecha, ACQESP, PPSIUN AS COD_PROVEEDOR \n",
    "                    , count(ACQKEY) AS cta_actividad  \n",
    "                    FROM QS36F.ACUCHEQAC T1\n",
    "                    INNER JOIN PROVEEDOR.PRVPTOSER T3 ON T1.ACQNFA=T3.PPSFAC AND T1.ACQDSR=T3.PPSCEN \n",
    "                    AND T1.ACQCSR=T3.PPSCIA AND T1.ACQSUC=T3.PPSSUC\n",
    "                    WHERE ACQSUC=50 AND DATE(ACQFCA CONCAT '-' CONCAT ACQFCM CONCAT '-' CONCAT ACQFCD ) < CURRENT_DATE - 3 MONTHS\n",
    "                    GROUP BY DATE(ACQFCA CONCAT '-' CONCAT ACQFCM CONCAT '-' CONCAT ACQFCD) , ACQESP  , PPSIUN\n",
    "                UNION \n",
    "                    SELECT DATE(ACQFCA CONCAT '-' CONCAT ACQFCM CONCAT '-' CONCAT ACQFCD) as fecha, ACQESP, PPSIUN AS COD_PROVEEDOR \n",
    "                    , count(ACQKEY) AS cta_actividad  \n",
    "                    FROM QS36F.\"\"\" + file_anioanterior + \"\"\" T1\n",
    "                    INNER JOIN PROVEEDOR.PRVPTOSER T3 ON T1.ACQNFA=T3.PPSFAC AND T1.ACQDSR=T3.PPSCEN \n",
    "                    AND T1.ACQCSR=T3.PPSCIA AND T1.ACQSUC=T3.PPSSUC\n",
    "                    WHERE ACQSUC=50 AND DATE(ACQFCA CONCAT '-' CONCAT ACQFCM CONCAT '-' CONCAT ACQFCD ) < CURRENT_DATE - 3 MONTHS\n",
    "                    GROUP BY DATE(ACQFCA CONCAT '-' CONCAT ACQFCM CONCAT '-' CONCAT ACQFCD) , ACQESP  , PPSIUN\n",
    "                           \n",
    "                             ) STROS \"\"\"\n",
    "\n",
    "datos_moni= pd.read_sql(SQL_moni_activ,cnxn)\n",
    "#datos_moni.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Añadimos los datos de ackey's x día para preparar un datashade que se muestre la actividad de los proveedores tipo firemap donde se vea claramente quienes son los más visitados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_moni.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_moni_acti=use_data_plot.merge(datos_moni, how=\"left\",  left_on=['PCMECD', 'PCMIUN'],\n",
    "                                 right_on=['ACQESP', 'COD_PROVEEDOR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_moni_acti['CTA_ACTIVIDAD'].fillna(0, inplace=True)\n",
    "datos_moni_acti.loc[:, 'lng_mercator'], datos_moni_acti.loc[:, 'lat_mercator'] = ds.utils.lnglat_to_meters(datos_moni_acti['lng']\n",
    "                                                                                                ,datos_moni_acti['lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dask_moni_activ = dd.from_pandas(datos_moni_acti, npartitions=mp.cpu_count()).persist()\n",
    "dask_moni_activ.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_moni_acti.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_acti_agg=datos_moni_acti[['PCMIUN', 'PCMNFC', 'AAT', 'FACTURACION_MENSUAL', 'CTA_ACTIVIDAD','lng_mercator', 'lat_mercator']]\n",
    "dat_acti_agg.columns\n",
    "\n",
    "dat_acti_agg=dat_acti_agg.groupby(['PCMIUN', 'PCMNFC', 'AAT', 'FACTURACION_MENSUAL','lng_mercator', 'lat_mercator']).agg({\"CTA_ACTIVIDAD\": 'sum'})\n",
    "dat_acti_agg=dat_acti_agg.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_acti_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heatmap = hv.HeatMap((np.random.randint(0, 10, 100), np.random.randint(0, 10, 100),\n",
    "                      np.random.randn(100), np.random.randn(100)), vdims=[ 'z0','z1']).redim.range(z=(-2, 2))\n",
    "\n",
    "heatmap.opts(opts.HeatMap(tools=['hover'], colorbar=True, width=325, toolbar='above'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datpba= [(chr(65+i), chr(97+j),  i*j, i**j) for i in range(5) for j in range(5) if i!=j]\n",
    "datpba\n",
    "hv.HeatMap(datpba, vdims=[ 'z0','z1']).opts(opts.HeatMap(tools=['hover'], colorbar=True, width=325, toolbar='above')).sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#css para elementos del dashboard.\n",
    "css_personalizado = '''\n",
    ".bk-root{\n",
    "    \n",
    "    zoom:100%;\n",
    "}\n",
    "\n",
    ".widget-box {\n",
    "  background: #f0f0f0;\n",
    "  border-radius: 3px;\n",
    "  border: 1px black solid;\n",
    "  padding:0px;\n",
    "\n",
    "}\n",
    "\n",
    "table.greenTable {\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "  border-collapse: collapse;\n",
    "}\n",
    "table.greenTable td, table.greenTable th {\n",
    "  border: 1px solid #AAAAAA;\n",
    "  padding: 0.1em 0.5em !important;\n",
    "  line-height: normal;\n",
    " \n",
    "}\n",
    "\n",
    "table.greenTable tbody td {\n",
    "  font-size: 11px;\n",
    "}\n",
    "table.greenTable tr:nth-child(even) {\n",
    "  background: #D0E4F5;\n",
    "}\n",
    "table.greenTable thead {\n",
    "  background: #12A424;\n",
    "  background: -moz-linear-gradient(top, #4dbb5b 0%, #29ad3a 66%, #12A424 100%);\n",
    "  background: -webkit-linear-gradient(top, #4dbb5b 0%, #29ad3a 66%, #12A424 100%);\n",
    "  background: linear-gradient(to bottom, #4dbb5b 0%, #29ad3a 66%, #12A424 100%);\n",
    "  border-bottom: 2px solid #074412;\n",
    "}\n",
    "table.greenTable thead th {\n",
    "  font-size: 14px;\n",
    "  font-weight: bold;\n",
    "  color: #FFFFFF;\n",
    "  text-align: left;\n",
    "}\n",
    "table.greenTable tfoot {\n",
    "  font-size: 12px;\n",
    "  font-weight: bold;\n",
    "  color: #FFFFFF;\n",
    "  background: #D0E4F5;\n",
    "  background: -moz-linear-gradient(top, #dcebf7 0%, #d4e6f6 66%, #D0E4F5 100%);\n",
    "  background: -webkit-linear-gradient(top, #dcebf7 0%, #d4e6f6 66%, #D0E4F5 100%);\n",
    "  background: linear-gradient(to bottom, #dcebf7 0%, #d4e6f6 66%, #D0E4F5 100%);\n",
    "  border-top: 2px solid #444444;\n",
    "}\n",
    "table.greenTable tfoot td {\n",
    "  font-size: 14px;\n",
    "}\n",
    "table.greenTable tfoot .links {\n",
    "  text-align: right;\n",
    "}\n",
    "table.greenTable tfoot .links a{\n",
    "  display: inline-block;\n",
    "  background: #1C6EA4;\n",
    "  color: #FFFFFF;\n",
    "  padding: 2px 8px;\n",
    "  border-radius: 5px;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result.columns\n",
    "total_result.iloc[:20, :8] #PCMNFF: nif facturador, PCMNFP: nif profesional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString\n",
    "use_data_plot[['PCMECD', 'PCMEDS']].head(2)\n",
    "p1=geo_clientes['wkt'].apply(lambda x: wkt.loads(x)).iloc[0]\n",
    "p2=geo_clientes['wkt'].apply(lambda x: wkt.loads(x)).iloc[1]\n",
    "line=LineString([p1, p2])\n",
    "line\n",
    "#************************************************************************************************************\n",
    "#+ info en scipy 2018 youtubee.es: Introduction to Geospatial Data Analysis with Python | SciPy 2018 Tutorial\n",
    "#************************************************************************************************************\n",
    "#se puede obtener squeeze para devolver una geometry\n",
    "#plantilla:\n",
    "# variable= dataset.serie.loc[ matching, column_geometry].squeeze()\n",
    "geo_clientes.columns\n",
    "\n",
    "#geo_clientes['geometry']=geo_clientes['wkt'].apply(lambda x: wkt.loads(x))\n",
    "#geo_clientes.geometry.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#abrimos nuestro predictor de posibles bajas ante la eliminación del servicio\n",
    "pkl_filename = \"pickle_model_baja_x_reduccion_cm.pkl\"\n",
    "# Load from file\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    pickle_model = pickle.load(file)\n",
    "    \n",
    "# Calcula el score y hace una predicción.\n",
    "\n",
    "#Ypredict = pickle_model.predict(D_pro)\n",
    "#Ypredict\n",
    "df_forpredict=use_data_plot[['PCMECD', 'ACTOS', 'AAT']].copy()\n",
    "df_forpredict['ACTOS']=df_forpredict['ACTOS'].apply(lambda x: 0 if x < 0 else x)\n",
    "df_forpredict['AAT']=df_forpredict['AAT'].apply(lambda x: 0 if x < 0 else x)\n",
    "df_forpredict['ACTOS'].fillna(0, inplace=True)\n",
    "df_forpredict['AAT'].fillna(0, inplace=True)\n",
    "df_forpredict['ACTOS']=df_forpredict['ACTOS'].apply(lambda x: 0.1 if x<1 else x)\n",
    "df_forpredict['AAT']=df_forpredict['AAT'].apply(lambda x: 1 if x<1 else x)\n",
    "df_forpredict=df_forpredict.rename(columns={\"PCMECD\": \"ACQESP\", \"ACTOS\": \"ACTOS_TOTAL\", \"AAT\": \"AAT_TOTAL\"})\n",
    "df_forpredict.loc[pd.isnull(df_forpredict['ACQESP'])].head(5)\n",
    "Prediccion=pickle_model['svr'].predict(pickle_model['preprocessor'] \\\n",
    "                                       .transform(df_forpredict[['ACQESP', 'ACTOS_TOTAL', 'AAT_TOTAL']]))\n",
    "Prediccion\n",
    "# df_forpredict['ACQESP'].describe()\n",
    "# df_forpredict['ACTOS_TOTAL'].describe()\n",
    "\n",
    "use_data_plot['PROB_BAJAS']=Prediccion\n",
    "use_data_plot['PROB_BAJAS']=use_data_plot.apply(lambda x: 0 if x['AAT']==0 else x['PROB_BAJAS'], axis=1 )\n",
    "\n",
    "all_profs=use_data_plot['PCMNFP'].unique()\n",
    "# use_data_plot['Prof_Factu']use_data_plot.apply(lambda row: 1 if  row['PCMNFF'] in row['PCMNFP'] else 0 , axis=1)\n",
    "use_data_plot['Prof_Factu']=use_data_plot.apply(lambda row: 1 if  row['PCMNFF'] in all_profs else 0 , axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtenemos los datos de la actividad.\n",
    "datos_moni_acti=use_data_plot.merge(datos_moni, how=\"left\",  left_on=['PCMECD', 'PCMIUN'],\n",
    "                                 right_on=['ACQESP', 'COD_PROVEEDOR'])\n",
    "\n",
    "datos_moni_acti['CTA_ACTIVIDAD'].fillna(0, inplace=True)\n",
    "datos_moni_acti.loc[:, 'lng_mercator'], datos_moni_acti.loc[:, 'lat_mercator'] = ds.utils.lnglat_to_meters(datos_moni_acti['lng']\n",
    "                                                                                                ,datos_moni_acti['lat'])\n",
    "\n",
    "dask_moni_activ = dd.from_pandas(datos_moni_acti, npartitions=mp.cpu_count()).persist()\n",
    "dask_moni_activ.head(2)\n",
    "\n",
    "dat_acti_agg=datos_moni_acti[['PCMIUN', 'PCMNFC', 'AAT', 'FACTURACION_MENSUAL', 'CTA_ACTIVIDAD','lng_mercator', 'lat_mercator']]\n",
    "dat_acti_agg.columns\n",
    "\n",
    "dat_acti_agg=dat_acti_agg.groupby(['PCMIUN', 'PCMNFC', 'AAT', 'FACTURACION_MENSUAL','lng_mercator', 'lat_mercator']).agg({\"CTA_ACTIVIDAD\": 'sum'})\n",
    "dat_acti_agg=dat_acti_agg.reset_index()\n",
    "\n",
    "dat_acti_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_moni_activ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#posicionarlo en otro sitio no tien PROD_BAJAS, reasignar ubicación de celdas.\n",
    "from holoviews.operation.datashader import aggregate\n",
    "\n",
    "hv.extension('bokeh')\n",
    "dat_acti_agg['AAT2']=dat_acti_agg['AAT']\n",
    "\n",
    "datos_moni=hv.Dataset(dask_moni_activ[['lng_mercator', 'lat_mercator', 'Shape__Are','Texto', 'Cod_CCAA', 'dircompleta'\n",
    "                              ,'PCMECD', 'PCMLNP', 'PCMNFC', 'PCMNPR','n_clientes_a_radio','total_primas','PCMIUN',\n",
    "                             'POB18','C_MUN_PRO', 'PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD', 'PROB_BAJAS', 'ACQESP'\n",
    "                              , 'FACTURACION_MENSUAL', 'cluster', 'Prof_Factu', 'AAT', 'PRESP', 'CTA_ACTIVIDAD', 'FECHA']]\n",
    "                 , kdims=['lng_mercator', 'lat_mercator']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMLNP', 'PCMNFC', 'PCMNPR', 'PRESP' \n",
    "                          ,'n_clientes_a_radio', 'cluster' ,'POB18','C_MUN_PRO', 'PROB_BAJAS', 'ACQESP'\n",
    "                         ,'PCMIUN','PCMECD','PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD', 'AAT', 'FECHA'\n",
    "                          ,'total_primas','FACTURACION_MENSUAL', 'Prof_Factu', 'CTA_ACTIVIDAD'])\n",
    "puntos_moni=hv.Points(datos_moni, kdims=['lng_mercator', 'lat_mercator']\n",
    "             , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMLNP', 'PCMNFC', 'PCMNPR' ,'n_clientes_a_radio', 'cluster'\n",
    "                     ,'PCMIUN','PCMECD', 'PCMEDS','PCMNPS','PCMNAT','PCMRDS', 'Prof_Factu', 'PROB_BAJAS'\n",
    "                      ,'POB18','C_MUN_PRO','PCMEGD','total_primas', 'FACTURACION_MENSUAL', 'AAT', 'PRESP', 'CTA_ACTIVIDAD'])\n",
    "\n",
    "puntos_base_moni=hv.Points(datos_moni, kdims=['lng_mercator', 'lat_mercator']\n",
    "             , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMLNP', 'PCMNFC', 'PCMNPR' ,'n_clientes_a_radio', 'cluster'\n",
    "                     ,'PCMIUN','PCMECD','PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD'\n",
    "                      , 'Prof_Factu', 'PROB_BAJAS', 'PRESP', 'CTA_ACTIVIDAD'\n",
    "                      ,'POB18','C_MUN_PRO','total_primas', 'FACTURACION_MENSUAL', 'AAT']).opts(alpha=0.1, axiswise=True)\n",
    "base_forselect=datashade( puntos_base_moni ,streams=[RangeXY(transient=True)]\n",
    "                           , cmap=cm_n['bgy']\n",
    "                           , normalization='eq_hist' \n",
    "                           , x_sampling=0.01, y_sampling=0.01\n",
    "                     ).opts(alpha=0.1, axiswise=True)\n",
    "spreaded_forselect   = dynspread(base_forselect, threshold=0.6\n",
    "                                     , max_px=1, how='over'\n",
    "                                    , streams=[RangeXY(transient=True)]).opts( alpha=0.9, axiswise=True\n",
    "                                                                              ,bgcolor='black'\n",
    "                                                                              , width=600, height=400)\n",
    "\n",
    "# hv.output(spreaded_forselect)\n",
    "\n",
    "\n",
    "\n",
    "ht=hv.HexTiles( hv.Points(\n",
    "            #datos_moni,\n",
    "    dask_moni_activ,\n",
    "            kdims=['lng_mercator', 'lat_mercator'],\n",
    "            cdims=dict({ \"AAT\":'AAT', \"FACTU\":'PCMNFC'}),\n",
    "            vdims=['CTA_ACTIVIDAD' ]    )\n",
    "              )#.redim.range(CTA_ACTIVIDAD=(0,100000))\n",
    "               \n",
    "htptos=hv.Points(dat_acti_agg, kdims=['lng_mercator', 'lat_mercator'],)\n",
    "overlay = ht * htptos\n",
    "\n",
    "\n",
    "overlay.opts(opts.HexTiles(min_width=700, min_height=550, tools=['hover']\n",
    "                    , aggregator=np.sum, min_count=10, alpha=0.3, colorbar=True\n",
    "                      # , xaxis=None, yaxis=None\n",
    "                       , responsive=True)\n",
    "               , opts.Points(size=1, color='black')\n",
    "               )\n",
    "\n",
    "\n",
    "overlay*gv.tile_sources.ESRI\n",
    "\n",
    "scatter = hv.Scatter(datos_moni, vdims=['lng_mercator', 'lat_mercator', 'CTA_ACTIVIDAD'])\n",
    "scatter = scatter.opts(color='lat_mercator', size=dim('CTA_ACTIVIDAD')/20)\n",
    "\n",
    "                                         \n",
    "#help(hv.Raster)\n",
    "heatmap = hv.HeatMap(datos_moni.aggregate(kdims=['AAT', 'FACTURACION_MENSUAL']\n",
    "                                          , vdims=['CTA_ACTIVIDAD'], function=np.mean),\n",
    "                     label='Heatmap actividad')#.select(Year=(1928, 2002))\n",
    "heatmap\n",
    "len(datos_moni.aggregate(kdims=['AAT', 'FACTURACION_MENSUAL']\n",
    "                                          , vdims=['CTA_ACTIVIDAD'], function=np.mean) )\n",
    "\n",
    "datos_moni.aggregate(kdims=['PPSIUN']\n",
    "                                          , vdims=['CTA_ACTIVIDAD'], function=np.mean) .to(hv.Points) \\\n",
    ".opts(min_width=500, min_height=300, responsive=True) * gv.tile_sources.ESRI\n",
    "\n",
    "overlay=datos_moni.aggregate(kdims=['PPSIUN'] , vdims=['CTA_ACTIVIDAD'], function=np.sum) .to(hv.Points) \n",
    "overlay.opts( opts.Points(size=3, color='black'\n",
    "                          , min_width=500, min_height=300\n",
    "                          , responsive=True)\n",
    "               )\n",
    "overlay * gv.tile_sources.ESRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_line(s):\n",
    "    '''Rendering odd and even rows with different color'''\n",
    "    return ['background-color: #D4E6F1' if i%2!=0 else 'background-color: #85C1E9' for i in range(len(s))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### %%opts Image {+framewise}\n",
    "# from holoviews import opts\n",
    "# from holoviews import streams\n",
    "from holoviews.streams import  Buffer\n",
    "from holoviews.operation.datashader import regrid\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from holoviews.plotting.links import DataLink\n",
    "from holoviews.core import Collator, HoloMap, NdOverlay, Overlay, GridSpace\n",
    "import requests\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "pn.extension(raw_css=[css_personalizado])\n",
    "conf_width=600\n",
    "conf_height=600\n",
    "#min_height=600, min_width=600, responsive=True\n",
    "opts1=dict( min_width=conf_width, min_height=conf_height, responsive=True,xaxis=None, yaxis=None,bgcolor=\"black\", sizing_mode='scale_width'\n",
    "          ,tools=['box_select', 'lasso_select'])\n",
    "opts1_t=dict(min_width=conf_width, min_height=conf_height,global_extent=False, responsive=True, xaxis=None, yaxis=None,bgcolor=\"black\")\n",
    "\n",
    "opts2=dict(x_sampling=0.00001, y_sampling=0.00001)\n",
    "gopts  = hv.opts.WMTS(xaxis=None, yaxis=None, bgcolor='black', show_grid=False, responsive=True,min_width=conf_width, min_height=conf_height)\n",
    "\n",
    "url = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{Z}/{Y}/{X}.jpg'\n",
    "map_tiles=gv.WMTS(url, crs=crs.GOOGLE_MERCATOR)\n",
    "datos=use_data_plot.copy()\n",
    "\n",
    "#PCMDLC, cambiada x PCMLNP es más correcta la descripción. Tengo que cambiar en todo el codigo pq hay seleccion\n",
    "#dentro de la clase\n",
    "lst_muni=datos['PCMLNP'].unique()\n",
    "lst_muni=list(lst_muni)\n",
    "lst_muni.sort()\n",
    "lst_muni.insert(0,'Todas')\n",
    "\n",
    "cmaps  = dict([(n, cm_n[n]) for n in cm_n.keys() ])\n",
    "\n",
    "#**********************************************************************************************************\n",
    "#                                           NOTAS TECNICAS:\n",
    "#**********************************************************************************************************\n",
    "#Hay varias formas de notificar los cambios en el panel, aquí vamos a utilizar la 2 y 3 ya que siendo las\n",
    "#más complejas, son las más útiles en cuanto a rendimiento:\n",
    "#1.- dependencias signifcadas con el decorador @pn.depends(...), siempre que cambie alguno de los\n",
    "#parametros significados asi, cambiará el proceso y se ejecutará todo de nuevo\n",
    "#2.-Dependencia de un método para DynamicMap: decoraremos igualmente con @pn.dependes(...), lo que cambia\n",
    "#aqui es que al utilizar DynamicMap, el metodo solo se re-ejecutara cuando cambie algun parametro que\n",
    "#este afectado en este DynamicMap\n",
    "#3.-Argumento instancia-objeto de parametro: proporcionaremos una instancia del objeto param en lugar del\n",
    "#valor asociado a ese parametro, así las dependencias se infieren solo cuando se pasa el objeto completo\n",
    "#y sólo cambiarán o se actualizará cuando el valor cambie.\n",
    "#(*): Los enfoques 2 y 3 se basan en una caracteristica de HoloViews llamada streaming, que admiten muchos\n",
    "#tipos de comportamiento dinámico, además de responder a widgets. Por ejemplo la rasterize operación \n",
    "#adjunta una RangeXY streaming que vuelve a agregar los datos cada vez que cambia la ventana gráfica, lo \n",
    "#mismo ocurre en nuesro ejemplo en la operación de datashade.\n",
    "#**********************************************************************************************************\n",
    "#ver:\n",
    "#https://panel.pyviz.org/reference/panes/Ace.html#gallery-ace\n",
    "#implementacion widget con selección multiple:\n",
    "#https://github.com/pyviz/panel/issues/392\n",
    "\n",
    "ds_orig=use_data_plot.copy()\n",
    "ds_orig['lng_mercator']=0.0\n",
    "ds_orig['lat_mercator']=0.0\n",
    "ds_orig.loc[:, 'lng_mercator'], ds_orig.loc[:, 'lat_mercator'] = ds.utils.lnglat_to_meters(ds_orig['lng'],ds_orig['lat'])\n",
    "dask_df = dd.from_pandas(ds_orig, npartitions=mp.cpu_count())\n",
    "#dask_df=gdf_cmedico_spk\n",
    "min_cli_radio=0\n",
    "max_cli_radio=dask_df['n_clientes_a_radio'].max().compute()\n",
    "\n",
    "#compruebo que va bien el calculo de aat, asi que ya no muestro el selector de si/no y dejo x defecto\n",
    "#la opcion de calcular. Antes estaba asi:\n",
    "# bCalculo=pn.widgets.RadioButtonGroup(value=\"No\", options=[\"Sí\", \"No\"], name=\"Calcular AAT\", width=120)\n",
    "bCalculo=pn.widgets.RadioButtonGroup(value=\"Sí\", options=[\"Sí\", \"No\"], name=\"Calcular AAT\", width=120)\n",
    "\n",
    "class ExploraCMedico(param.Parameterized):\n",
    "#class ExploraCMedico(hv.streams.Stream):\n",
    "    ctl_calcular=bCalculo\n",
    "    bCalculate_aat=False#param.Boolean(False, doc=\"Calcular aat?\")\n",
    "    Calcula_aat=param.Selector(default=\"No\", objects=[\"Sí\", \"No\", \"Si\"], precedence=-1)#lo uso para link con widget radiobutton\n",
    "    Calcular=param.String( default='No', label='Calcular aat?', precedence=-1)#param.Boolean(False, doc=\"Calcular aat?\", precedence=-1)#inisibble\n",
    "    alpha=param.Magnitude(default=0.5, doc=\"Opacidad mapa\")\n",
    "    #colormap=param.ObjectSelector(default=\"fire\", objects=list(cm_n.keys()))\n",
    "    colormap=param.Selector(cmaps)\n",
    "    localidades=param.ObjectSelector(default=\"Todas\", objects=lst_muni )\n",
    "    set_datos=use_data_plot.copy()\n",
    "    spreading     = param.Integer(3, bounds=(0, 5))\n",
    "    muestra_nombres   = param.Boolean(True)\n",
    "    map_tiles=gv.WMTS(url, crs=crs.GOOGLE_MERCATOR)\n",
    "    parte_direccion=param.String( default='', label='parte direccion')\n",
    "    sel_rgo_cli=param.Range(default=(0, max_cli_radio), bounds=(0, max_cli_radio))\n",
    "\n",
    "    #lst_agrup_servicio\n",
    "    #lst_red\n",
    "    #lst_natups\n",
    "    #lst_factu\n",
    "    facturadores=param.ObjectSelector(default=\"Todos\", objects=lst_factu )\n",
    "    agrup_servicios= param.ObjectSelector(default=\"Todos\", objects=lst_agrup_servicio ) \n",
    "    especialidad=param.ObjectSelector(default=\"Todas\", objects=lst_espec ) \n",
    "    natups= param.ObjectSelector(default=\"Todas\", objects=lst_natups )    \n",
    "    red= param.ObjectSelector(default=\"Todas\", objects=lst_red )   \n",
    "    clusters=param.ObjectSelector(default=999, objects=lst_clusters )\n",
    "    \n",
    "#     btn_exportar_toxls = param.Action(lambda x: x.param.trigger('btn_exportar_toxls'), label='Exporta datos a excel')\n",
    "#     Nota_export= param.Parameter(default=\" \", constant=True)\n",
    "    \n",
    "    ds_pd=ds_orig.copy()\n",
    "    dask_df = dd.from_pandas(ds_pd, npartitions=mp.cpu_count())\n",
    "    se_datos=dask_df.copy()\n",
    "    dask_moni_activ = dd.from_pandas(datos_moni_acti, npartitions=mp.cpu_count()).persist()\n",
    "    dat_acti_agg=dat_acti_agg.groupby(['PCMIUN', 'PCMNFC', 'AAT', 'FACTURACION_MENSUAL'\n",
    "                                       ,'lng_mercator', 'lat_mercator']).agg({\"CTA_ACTIVIDAD\": 'sum'})\n",
    "\n",
    "    datos=hv.Dataset(dask_df[['lng_mercator', 'lat_mercator', 'Shape__Are','Texto', 'Cod_CCAA', 'dircompleta'\n",
    "                              ,'PCMECD', 'PCMLNP', 'PCMNFC', 'PCMNPR','n_clientes_a_radio','total_primas','PCMIUN',\n",
    "                             'POB18','C_MUN_PRO', 'PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD', 'PROB_BAJAS'\n",
    "                              , 'FACTURACION_MENSUAL', 'cluster', 'Prof_Factu', 'AAT', 'PRESP']]\n",
    "                 , kdims=['lng_mercator', 'lat_mercator']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMLNP', 'PCMNFC', 'PCMNPR', 'PRESP' \n",
    "                          ,'n_clientes_a_radio', 'cluster' ,'POB18','C_MUN_PRO', 'PROB_BAJAS'\n",
    "                         ,'PCMIUN','PCMECD','PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD', 'AAT'\n",
    "                          ,'total_primas','FACTURACION_MENSUAL', 'Prof_Factu'])\n",
    "    puntos=hv.Points(datos, kdims=['lng_mercator', 'lat_mercator']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMLNP', 'PCMNFC', 'PCMNPR' ,'n_clientes_a_radio', 'cluster'\n",
    "                         ,'PCMIUN','PCMECD', 'PCMEDS','PCMNPS','PCMNAT','PCMRDS', 'Prof_Factu', 'PROB_BAJAS'\n",
    "                          ,'POB18','C_MUN_PRO','PCMEGD','total_primas', 'FACTURACION_MENSUAL', 'AAT', 'PRESP'])\n",
    "    \n",
    "    puntos_base=hv.Points(datos, kdims=['lng_mercator', 'lat_mercator']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMLNP', 'PCMNFC', 'PCMNPR' ,'n_clientes_a_radio', 'cluster'\n",
    "                         ,'PCMIUN','PCMECD','PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD'\n",
    "                          , 'Prof_Factu', 'PROB_BAJAS', 'PRESP'\n",
    "                          ,'POB18','C_MUN_PRO','total_primas', 'FACTURACION_MENSUAL', 'AAT']).opts(alpha=0.1, axiswise=True)\n",
    "    base_forselect=datashade( puntos_base ,streams=[RangeXY(transient=True)]\n",
    "                               , cmap=cmaps['fire']\n",
    "                               , normalization='eq_hist' \n",
    "                               , x_sampling=0.00001, y_sampling=0.00001\n",
    "                         ).opts(alpha=0.1, axiswise=True)\n",
    "    spreaded_forselect   = dynspread(base_forselect, threshold=0.4\n",
    "                                         , max_px=1, how='over'\n",
    "                                        , streams=[RangeXY(transient=True)]).opts( alpha=0.1, axiswise=True)\n",
    "    #points=hv.Points(datos, ['Longitude', 'Latitude'])\n",
    "    #puntos=hv.Points(datos, ['Longitude', 'Latitude']).opts(framewise=True, axiswise=True)\n",
    "    #mapa_fondo=map_tiles.opts(gopts).opts(alpha=0.5, **opts1)\n",
    "    # selection that gives the current x_range/y_range of the map\n",
    "    box = hv.streams.RangeXY(transient=True)\n",
    "    ventana_actual={\"x_range_min\": None, \"x_range_max\": None, \"y_range_min\": None, \"y_range_max\": None}\n",
    "    \n",
    "    tabla=None\n",
    "    seleccion= None #hv.streams.Selection1D(source=puntos)\n",
    "    sel_fortabla=hv.streams.RangeXY(source=spreaded_forselect)\n",
    "    \n",
    "    plot_shaded     = datashade( puntos ,streams=[RangeXY(transient=True)]  , normalization='eq_hist' )\n",
    "    plot_spreaded   = dynspread(plot_shaded, threshold=0.9, how='over' )\n",
    "   \n",
    "    \n",
    "    def __ini__(self):\n",
    "        print(\"estmao en ini\")\n",
    "        self.btn_export_xls = param.Action(self.exportar_tbl_a_excel, 'Exportar tabla datos')\n",
    "        print(\"en toria ha añadido boton\")\n",
    "        super(ExploraCMedico, self).__init__()\n",
    "\n",
    "#     @param.depends('localidades' , 'sel_rgo_cli', 'facturadores', 'agrup_servicios'\n",
    "#                    ,'natups', 'red', 'parte_direccion', 'clusters', 'especialidad', watch=True)\n",
    "    def update_params(self, *events):\n",
    "        print(\"events es: \", events) \n",
    "        for event in events:\n",
    "            print(\"name event: \" , event.name)\n",
    "#             if event.name == 'options':\n",
    "#                 print('Possible options: %s' % ', '.join(event.new) , event )\n",
    "#             elif event.name == 'value':\n",
    "#                print( 'Selected: %s' % ','.join(event.new), event )\n",
    "            \n",
    "        \n",
    "        \n",
    "        #************************************************************\n",
    "        #actualizamos los parametros conforme a la seleccion actual:\n",
    "        #************************************************************\n",
    "        #_localidades update:\n",
    "        #-------------------------------------------------\n",
    "        _locs=self.puntos.data.compute().PCMLNP.unique()\n",
    "#         _locs=np.array(_locs)\n",
    "#         _locs_old=np.array(self.param.localidades.objects)\n",
    "#         idx=np.isin(_locs_old, _locs)\n",
    "#         locs_new=_locs_old[idx]\n",
    "#         locs_new=list(locs_new)\n",
    "        locs_new=list(_locs)\n",
    "        locs_new.sort()\n",
    "        locs_new.insert(0, 'Todas')\n",
    "#         if self.localidades=='Todas': \n",
    "#             value_sel= 'Todas' \n",
    "#         else: \n",
    "#             value_sel=locs_new[0]\n",
    "        value_sel=self.localidades\n",
    "        #si el param que hemos cambiado es este no cambio su objects, solo el resto\n",
    "        #[a if a else 2 for a in [0,1,0,3]]\n",
    "        getdatev=[(ev.old, ev.new) if ev.name=='localidades' else ('x','x') for ev in events  ]\n",
    "        print(\"getdatev: \", getdatev)\n",
    "        old,new=getdatev[0]\n",
    "        if (old == new ) | (new in ['Todos', 'Todas']):\n",
    "            self.param.localidades.objects=locs_new\n",
    "            self.localidades=value_sel #no reasignar valor sino vuelve a recupear info\n",
    "        #print(\"update localidades: \", _locs, locs_new, value_sel)\n",
    "        \n",
    "        #agrup servicios update:\n",
    "        #-------------------------------------------------\n",
    "        _agrupserv=self.puntos.data.compute().PCMEGD.unique()\n",
    "        _agrupserv_new=list(_agrupserv)\n",
    "        _agrupserv_new.sort()\n",
    "        _agrupserv_new.insert(0, 'Todos')\n",
    "        value_sel=self.agrup_servicios\n",
    "        getdatev=[(ev.old, ev.new) if ev.name=='agrup_servicios' else ('x','x') for ev in events  ]\n",
    "        print(\"getdatev: \", getdatev)\n",
    "        old,new=getdatev[0]\n",
    "        if (old == new ) | (new in ['Todos', 'Todas']):\n",
    "            self.param.agrup_servicios.objects=_agrupserv_new\n",
    "            self.agrup_servicios=value_sel  #no reasignar valor sino vuelve a recupear info\n",
    "        #print(\"update agrup_servicios: \", _agrupserv, _agrupserv_new, value_sel)\n",
    "        \n",
    "        #facturadores update:\n",
    "        #-------------------------------------------------\n",
    "        _factus=self.puntos.data.compute().PCMNFC.unique()\n",
    "        _factus_new=list(_factus)\n",
    "        _factus_new.sort()\n",
    "        _factus_new.insert(0, 'Todos')\n",
    "        value_sel=self.facturadores\n",
    "        getdatev=[(ev.old, ev.new) if ev.name=='facturadores' else ('x','x') for ev in events  ]\n",
    "        print(\"getdatev: \", getdatev)\n",
    "        old,new=getdatev[0]\n",
    "        if (old == new ) | (new in ['Todos', 'Todas']):\n",
    "            self.param.facturadores.objects=_factus_new\n",
    "            self.facturadores=value_sel  #no reasignar valor sino vuelve a recupear info\n",
    "        #print(\"update facturadores: \", _factus, _factus_new, value_sel)\n",
    "        \n",
    "        #natups update:\n",
    "        #-------------------------------------------------\n",
    "        _natups=self.puntos.data.compute().PCMNAT.unique()\n",
    "        _natups_new=np.array(_natups)\n",
    "        _natups_new=list(_natups_new) # x[~numpy.isnan(x)]\n",
    "        _natups_new.sort()\n",
    "        _natups_new.insert(0, 'Todas')\n",
    "        value_sel=self.natups\n",
    "        getdatev=[(ev.old, ev.new) if ev.name=='natups' else ('x','x') for ev in events  ]\n",
    "        print(\"getdatev: \", getdatev)\n",
    "        old,new=getdatev[0]\n",
    "        if (old == new ) | (new in ['Todos', 'Todas']):\n",
    "            self.param.natups.objects=_natups_new\n",
    "            self.natups=value_sel  #no reasignar valor sino vuelve a recupear info\n",
    "        \n",
    "        #red update:\n",
    "        #-------------------------------------------------\n",
    "        _red=self.puntos.data.compute().PCMRDS.unique()\n",
    "        _red_new=np.array(_red)\n",
    "        _red_new=list(_red_new) # x[~numpy.isnan(x)]\n",
    "        _red_new.sort()\n",
    "        _red_new.insert(0, 'Todas')\n",
    "        value_sel=self.red\n",
    "        getdatev=[(ev.old, ev.new) if ev.name=='red' else ('x','x') for ev in events  ]\n",
    "        print(\"getdatev: \", getdatev)\n",
    "        old,new=getdatev[0]\n",
    "        if (old == new ) | (new in ['Todos', 'Todas']):\n",
    "            self.param.red.objects=_red_new\n",
    "            self.red=value_sel  #no reasignar valor sino vuelve a recupear info\n",
    "        \n",
    "        #especialidad update:\n",
    "        #-------------------------------------------------\n",
    "        _especialidad=self.puntos.data.compute().PCMEDS.unique()\n",
    "        _especialidad_new=np.array(_especialidad)\n",
    "        _especialidad_new=list(_especialidad_new) # x[~numpy.isnan(x)]\n",
    "        _especialidad_new.sort()\n",
    "        _especialidad_new.insert(0, 'Todas')\n",
    "        value_sel=self.especialidad\n",
    "        getdatev=[(ev.old, ev.new) if ev.name=='especialidad' else ('x','x') for ev in events  ]\n",
    "        print(\"getdatev: \", getdatev)\n",
    "        old,new=getdatev[0]\n",
    "        if (old == new ) | (new in ['Todos', 'Todas']):\n",
    "            self.param.especialidad.objects=_especialidad_new\n",
    "            self.especialidad=value_sel  #no reasignar valor sino vuelve a recupear info\n",
    "            \n",
    "        #clusters update:\n",
    "        #-------------------------------------------------\n",
    "        _clusters=self.puntos.data.compute().loc[(~pd.isnull(self.puntos.data.compute().cluster) ) ].cluster.unique()\n",
    "        all_clusters=lst_clusters\n",
    "        _clusters_dict= dict([ (k,v) for k,v in all_clusters.items() if v in _clusters])\n",
    "        _clusters_new={}\n",
    "        _clusters_new[\"Todos\"] =999\n",
    "        for k in _clusters_dict.keys():\n",
    "            _clusters_new[k]=_clusters_dict[k]\n",
    "        \n",
    "        clusters_only_value=list( _clusters )\n",
    "        clusters_only_value.insert(0, 999)\n",
    "        value_sel=self.clusters\n",
    "        getdatev=[(ev.old, ev.new) if ev.name=='clusters' else ('x','x') for ev in events  ]\n",
    "        print(\"getdatev: \", getdatev)\n",
    "        old,new=getdatev[0]\n",
    "        if (old == new ) | (new in ['Todos', 'Todas', 999]):\n",
    "            self.param.clusters.objects= clusters_only_value\n",
    "            print(\"objects in clusters: \" , self.param.clusters.objects)\n",
    "            self.clusters=value_sel  #no reasignar valor sino vuelve a recupear info\n",
    "            print(\"update clusters: \", self.clusters, _clusters_new, type( _clusters_new))\n",
    "        \n",
    "    def make_base(self, x_range=None, y_range=None):\n",
    "        print(\"Ha pasado x base_map. info ventana: \", self.ventana_actual, \"streams: \", x_range, y_range)\n",
    "        puntos_base=hv.Points(self.datos, kdims=['lng_mercator', 'lat_mercator']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMLNP', 'PCMNFC', 'PCMNPR' ,'n_clientes_a_radio', 'cluster'\n",
    "                         ,'PCMIUN','PCMECD','PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD', 'Prof_Factu', 'PROB_BAJAS'\n",
    "                          ,'POB18','C_MUN_PRO','total_primas', 'FACTURACION_MENSUAL', 'AAT', 'PRESP'])\\\n",
    "                    .opts(alpha=0.1, framewise=True)\n",
    "        \n",
    "#         self.puntos=self.puntos.select(lng_mercator=(self.ventana_actual['x_range_min'] , \n",
    "#                                                     self.ventana_actual['x_range_max']) , \n",
    "#                                        lat_mercator=(self.ventana_actual['y_range_min'] , \n",
    "#                                                     self.ventana_actual['y_range_max']) ) \n",
    "        if x_range is not None:\n",
    "            self.puntos=self.puntos.select(lng_mercator=x_range , lat_mercator=y_range ) \n",
    "    \n",
    "        base_forselect=datashade( puntos_base ,streams=[RangeXY(transient=True)]\n",
    "                         , cmap=cmaps['fire']\n",
    "                         , normalization='eq_hist' \n",
    "                         , x_sampling=0.00001, y_sampling=0.00001\n",
    "                         ).opts(alpha=0.1, framewise=True)\n",
    "        spreaded_forselect   = dynspread(base_forselect, threshold=0.4\n",
    "                        , max_px=1, how='over'\n",
    "                        , streams=[RangeXY(transient=True)]).opts( alpha=0.1, framewise=True)\n",
    "        \n",
    "        return spreaded_forselect\n",
    "    \n",
    "    def make_btn_exportar(self):\n",
    "        btn_exportar_toxls = param.Action(lambda x: x.param.trigger('btn_exportar_toxls'), label='Exporta datos a excel')\n",
    "        return btn_exportar_toxls \n",
    "    \n",
    "    def make_link_download(self):\n",
    "        descarga=hv.Div(\"\"\"<a href=Exploracion_proveedores.xlsx download=\"Exploracion_proveedores.xlsx\">Download file</a>\"\"\")\n",
    "        return descarga\n",
    "    \n",
    "    #@param.depends('btn_exportar_toxls', watch=True)#esto era cuando lo hacia desde la clase ahora lo hago\n",
    "    #desde fuera con watch y no necesito el depends, asi puedo quitar el boton del .paam y ponerolo arriba\n",
    "    def exportar_tbl_a_excel(self, tipo_evento=None):\n",
    "        #print(\"forma datos en tabla: \" , len(self.tabla.data) ,type(self.tabla.data ) , type (self.param.Nota_export))\n",
    "        #print( dir (self.param.Nota_export))\n",
    "        \n",
    "        tmp_df=self.tabla.data.compute()\n",
    "        tmp_df.to_excel( 'Exploracion_proveedores.xlsx')\n",
    "        #pendiente codigo html para informar que ya se ha exportado\n",
    "        #pn.pane.HTML(iframe, height=400)\n",
    "        self.message(\"Datos exportados...\")\n",
    "        \n",
    "       \n",
    "        show_html=hv.Div(\"\"\"<head>\n",
    "        <body>\n",
    "                    <h3>Datos exportados a file Exploracion_proveedores.xlsx</h3></head>\n",
    "                    <iframe src='about:blank'>\n",
    "                    <script type=\"text/javascript\">\n",
    "                        function init() {\n",
    "                            // preparar codigo aqui\n",
    "                            alert(\"datos exportados...\")\n",
    "                        }\n",
    "                        window.onload = init;\n",
    "                    </script>\n",
    "                    </iframe>\n",
    "        </body>\n",
    "                    \n",
    "                    \"\"\")\n",
    "#         outp=urllib.parse.quote(outp)\n",
    "#         base_click=\"\"\"<h4>Datos de Facturación</h4><iframe width=480px height=200px src=data:text/html,\"\"\" + outp \\\n",
    "#                     +\"\"\" scrolling=\"no\" style=\"border-width: 0px\"></iframe>\"\"\"\n",
    "#         self.param.Nota_export.constant=False\n",
    "#         self.Nota_export=\"Datos exportados a file Exploracion_proveedores.xlsx\"\n",
    "#         self.param.Nota_export.constant=True\n",
    "#         self.param.Nota_export.label=\"Nota export:\"\n",
    "        \n",
    "        return show_html\n",
    "        #return pn.pane.HTML( \"\"\"<html><script>alert('Datos exportados a file Exploracion_proveedores.xlsx');\n",
    "        #            </script>\n",
    "        #            </html>\"\"\", height=100)\n",
    "        \n",
    "    @param.depends ('sel_rgo_cli', watch=True)\n",
    "    def filtro_sel_rgo_cli(self):\n",
    "        self.datos=self.datos.select(n_clientes_a_radio=self.sel_rgo_cli )\n",
    "    \n",
    "   \n",
    "    \n",
    "    @param.depends('localidades' , 'sel_rgo_cli', 'facturadores', 'agrup_servicios'\n",
    "                   ,'natups', 'red', 'parte_direccion', 'clusters', 'especialidad', watch=True)\n",
    "    def SeleccionaDatos(self, x_range=None, y_range=None, *events, **kwargs):\n",
    "        print(\"estamos en seleccionDatos\", self.params.args, x_range, y_range, self.parte_direccion)\n",
    "        \n",
    "        #print(dir( self.param.localidades) )\n",
    "        #print(self.param.localidades.__getstate__(), self.param.localidades.watchers)\n",
    "             \n",
    "       \n",
    "\n",
    "        self.set_datos=self.ds_pd.copy()\n",
    "        \n",
    "        #si filtro los datos tngo problemas al utilizar datashade con el calculo de l density\n",
    "        #da error division x cero, por lo tanto no puedo filtrar solo seleccionar\n",
    "#         if self.localidades=='Todas':\n",
    "#             idx_filtros=[True  for m in  range (self.set_datos.shape[0])   ]\n",
    "#             self.set_datos = self.set_datos[idx_filtros]\n",
    "#         else:\n",
    "            \n",
    "#             idx_filtros=[m  for m in ( self.set_datos['PCMLNP'] == self.localidades) ]\n",
    "#             self.set_datos = self.set_datos[idx_filtros]\n",
    "        idx_filtro_dir=self.set_datos['dircompleta'].loc[self.set_datos['dircompleta'].str.contains(self.parte_direccion\n",
    "                                                                                        , regex=False)].index\n",
    "        self.set_datos=self.set_datos.iloc[idx_filtro_dir]\n",
    "        self.set_datos= dd.from_pandas(self.set_datos, npartitions=mp.cpu_count())\n",
    "        \n",
    "        idx_filtro_dir=np.asarray(idx_filtro_dir).flatten()\n",
    "        print(self.set_datos['lng_mercator'].min().compute(),self.set_datos['lat_mercator'].min().compute() )\n",
    "                \n",
    "        datos=hv.Dataset(self.set_datos[['lng_mercator', 'lat_mercator', 'Shape__Are','Texto', 'Cod_CCAA', 'dircompleta'\n",
    "                                              , 'PCMLNP', 'PCMNFC', 'PCMNPR','n_clientes_a_radio','total_primas', 'cluster'\n",
    "                                        ,'PCMIUN','PCMECD','PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD', 'Prof_Factu', 'PROB_BAJAS'\n",
    "                                         ,'POB18','C_MUN_PRO', 'FACTURACION_MENSUAL', 'AAT', 'PRESP']]\n",
    "                 , kdims=['lng_mercator', 'lat_mercator']\n",
    "                 , vdims=['Texto', 'Shape__Are', 'Cod_CCAA', 'dircompleta', 'PCMLNP', 'PCMNFC'\n",
    "                          ,'POB18','C_MUN_PRO', 'PCMNPR' ,'FACTURACION_MENSUAL', 'Prof_Factu', 'PROB_BAJAS', 'AAT'\n",
    "                          ,'PCMIUN','n_clientes_a_radio','PCMEDS','PCMNPS','PCMNAT','PCMRDS'\n",
    "                          ,'PCMEGD','total_primas', 'cluster' , 'PRESP'])\n",
    "        \n",
    "        #este filtro tengo que hacerlo el primero pq sino puede q alguno de los indices q pasamos sean filtrados x otro criterio\n",
    "        #y obtendriamos error\n",
    "        print(\"checking cluster type: \", type(self.clusters), self.param.clusters.objects)\n",
    "        datos=datos.select(n_clientes_a_radio=self.sel_rgo_cli)\n",
    "        if self.red != 'Todas':\n",
    "            print(\"opc red: \", self.red)\n",
    "            datos=datos.select(PCMRDS=self.red)\n",
    "        if self.facturadores != 'Todos':\n",
    "            print(\"facturadores: \", self.facturadores)\n",
    "            datos=datos.select(PCMNFC=self.facturadores)\n",
    "        if self.natups != 'Todas':\n",
    "            print(\"natups: \", self.natups)\n",
    "            datos=datos.select(PCMNAT=self.natups)\n",
    "        if self.agrup_servicios != 'Todos':\n",
    "            print(\"agrup servicios: \", self.agrup_servicios)\n",
    "            datos=datos.select(PCMEGD=self.agrup_servicios)\n",
    "        if self.clusters != 999 :\n",
    "            datos=datos.select(cluster=self.clusters)\n",
    "        if self.especialidad != 'Todas':\n",
    "            datos=datos.select(PCMEDS=self.especialidad)\n",
    "            \n",
    "        \n",
    "        \n",
    "        datos=datos.select(lng_mercator=(self.ventana_actual['x_range_min'], self.ventana_actual['x_range_max']), \n",
    "                    lat_mercator=(self.ventana_actual['y_range_min'], self.ventana_actual['y_range_max']) )\n",
    "        if self.seleccion is not None:\n",
    "            print(\"valor de self.seleccion=\", self.seleccion)\n",
    "#             selxrange, selyrange=zip(*self.seleccion)\n",
    "#             datos.select(lng_mercator=selxrange, \n",
    "#                     lat_mercator=selyrange)\n",
    "        \n",
    "        \n",
    "        self.datos=datos\n",
    "        print(\"forma de gedf set_datos en selecciondatos: \", self.set_datos.shape)\n",
    "        print(\"forma de hv dataset datos en selecciondatos: \", len(datos.data))\n",
    "        print(\"forma de hv dataset self.datos en selecciondatos: \", len(self.datos.data))\n",
    "        \n",
    "        self.puntos=hv.Points(datos, ['lng_mercator', 'lat_mercator']\n",
    "                     , ['Texto', 'Shape__Are', 'Cod_CCAA', 'dircompleta' , 'PCMLNP', 'PCMNFC', 'PCMNPR' \n",
    "                        ,'POB18','C_MUN_PRO','FACTURACION_MENSUAL', 'PROB_BAJAS'\n",
    "                        ,'PCMIUN','PCMECD','n_clientes_a_radio','PCMEDS','PCMNPS','PCMNAT','PCMRDS'\n",
    "                        ,'PCMEGD','total_primas', 'cluster', 'AAT' , 'PRESP'])\n",
    "                    \n",
    "        \n",
    "        if self.localidades != 'Todas':\n",
    "            sel_datos=self.ds_pd.loc[self.ds_pd['PCMLNP']==self.localidades].copy()\n",
    "        else:\n",
    "            sel_datos=self.ds_pd.copy()\n",
    "        \n",
    "        #**********************************************************************************************************\n",
    "        #   La seleccion de datos x localidad no la hago en el recordset, sino por la seleccion de coordenadas\n",
    "        #**********************************************************************************************************\n",
    "        x_range_min = sel_datos['lng_mercator'].quantile(0.01)\n",
    "        x_range_max = sel_datos['lng_mercator'].quantile(0.99)\n",
    "        y_range_min = sel_datos['lat_mercator'].quantile(0.01)\n",
    "        y_range_max = sel_datos['lat_mercator'].quantile(0.99)\n",
    "        \n",
    "        #shape_are se expresa en hectareas -.> 1 hectarea son 10.000 m cuadrados\n",
    "        if x_range_min == x_range_max:\n",
    "            x_range_max=x_range_min + sel_datos['Shape__Are'].max()*(10000/0.75)\n",
    "            x_range_min=x_range_min - sel_datos['Shape__Are'].max()*(10000/0.75)\n",
    "        else:\n",
    "            if  (x_range_max - x_range_min) < 5000:\n",
    "                x_range_max+=2500\n",
    "                x_range_min-=2500\n",
    "\n",
    "        if y_range_min == y_range_max:\n",
    "            y_range_max=y_range_min  + sel_datos['Shape__Are'].max()*(10000/0.75) \n",
    "            y_range_min=y_range_min  - sel_datos['Shape__Are'].max()*(10000/0.75) \n",
    "        else:\n",
    "            if  (y_range_max - y_range_min) < 5000:\n",
    "\n",
    "                y_range_max+=2500\n",
    "                y_range_min-=2500\n",
    "        \n",
    "            \n",
    "        print(\"rango canvas: \", x_range_min, x_range_max, y_range_min, y_range_max )\n",
    "        #ventana_actual={\"x_range_min\": None, \"x_range_max\": None, \"y_range_min\": None, \"y_range_max\": None}\n",
    "        self.ventana_actual['x_range_min']=x_range_min\n",
    "        self.ventana_actual['x_range_max']=x_range_max\n",
    "        self.ventana_actual['y_range_min']=y_range_min\n",
    "        self.ventana_actual['y_range_max']=y_range_max\n",
    "        print(\"ventana_actual: \" ,self.ventana_actual )\n",
    "        \n",
    "        self.puntos=self.puntos \\\n",
    "                        .redim.values(lng_mercator=(x_range_min, x_range_max),\n",
    "                        lat_mercator=(y_range_min, y_range_max) ).opts(framewise=True)\n",
    "                  \n",
    "        self.puntos=self.puntos.select(lng_mercator=(x_range_min , x_range_max) , lat_mercator=(y_range_min , y_range_max) )\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if self.localidades=='Todas':\n",
    "#             set_data=self.datos\n",
    "#         else:\n",
    "#             set_data=self.datos.select(PCMLNP=self.localidades)\n",
    "        \n",
    "#         if x_range is None:\n",
    "#             puntos=hv.Points(set_data, ['Longitude', 'Latitude']\n",
    "#                     , ['Texto', 'Cod_CCAA', 'dircompleta' , 'PCMLNP', 'PCMNFC', 'PCMNPR' ])\n",
    "#         else:\n",
    "#             puntos=hv.Points(set_data, ['Longitude', 'Latitude']\n",
    "#                     , ['Texto', 'Cod_CCAA', 'dircompleta' , 'PCMLNP', 'PCMNFC', 'PCMNPR' ])\\\n",
    "#                         .select( longitude= x_range, latitude=y_range )\n",
    "              \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return self.puntos\n",
    "        \n",
    "        #return self.datos\n",
    "    \n",
    "    \n",
    "    \n",
    "    @param.depends('alpha' , watch=True)\n",
    "    def tiles(self):\n",
    "        #self.mapa_fondo=map_tiles.opts(gopts).opts(alpha=self.alpha, **opts1)\n",
    "        #return self.mapa_fondo\n",
    "        #return map_tiles.opts(gopts).opts(alpha=self.alpha, framewise=True, **opts1_t)\n",
    "        #return  gv.tile_sources.CartoDark (alpha=self.alpha, framewise=True, **opts1_t)\n",
    "        return self.map_tiles.opts(gopts).opts(alpha=self.alpha, **opts1_t)\n",
    "     \n",
    "    @param.depends('muestra_nombres')\n",
    "    def labels(self):\n",
    "        return gts.StamenLabels.options(level='annotation', alpha=1 if self.muestra_nombres else 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    @param.depends('localidades' , 'sel_rgo_cli', 'facturadores', 'agrup_servicios'\n",
    "                   ,'natups', 'red', 'parte_direccion', 'clusters', 'especialidad', watch=True)\n",
    "    def selected_info(self, x_range=None, y_range=None):\n",
    "        #si estuviesemos trabajando conuna seleccion 1d sobre puntos que no va a ser el caso\n",
    "        #recogeriamos la matriz de puntos seleccionada, de la siguiente forma:\n",
    "#         arr = self.puntos.array()[index]\n",
    "#         if len(arr)==0:\n",
    "#             tabla=hv.Table(self.puntos)\n",
    "#         else:\n",
    "#             tabla=hv.Table( self.puntos.clone(arr) )\n",
    "\n",
    "#         print(\"array en selected_info es: \" , arr)\n",
    "\n",
    "        \n",
    "        print(\"seleccion en selected_info: \" , x_range, y_range)\n",
    "        clon_puntos=self.puntos\n",
    "        print(\"datos dentro de clon puntos: \", clon_puntos.data.compute().shape[0] )\n",
    "        clon_puntos=clon_puntos.select(lng_mercator=x_range , lat_mercator=y_range)\n",
    "        \n",
    "        \n",
    "        print(\"dir clon_puntos: \", dir(clon_puntos) )\n",
    "        print(\"forma de clon_puntos despues selecionar\", type(clon_puntos.dframe().shape))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.tabla=hv.Table(clon_puntos, kdims=[], vdims=[('PCMNFC','Facturador')\n",
    "                                                     , ('PCMNPR', 'Profesional')\n",
    "                                                     ,('dircompleta', 'dirección')\n",
    "                                                     ,('PCMLNP','Localidad')\n",
    "                                                     , ('PCMEDS', 'Especialidad')\n",
    "                                                     , ('FACTURACION_MENSUAL', 'factu mes')\n",
    "                                                     , ('n_clientes_a_radio', 'n. clientes -radio-')\n",
    "                                                     , ('total_primas', 'Primas -radio-') \n",
    "                                                     , ('AAT', 'aseg. aten')\n",
    "                                                     , ('PROB_BAJAS', 'Prob. bajas')\n",
    "                                                     , ('PRESP', 'Nota opinión')\n",
    "                                                     , ('Prof_Factu', 'ProfFactu')\n",
    "                                                         ]).opts(height=250)\n",
    "        \n",
    "        df_box=clon_puntos.data[['n_clientes_a_radio', 'PCMLNP', 'PCMEDS']].compute()\n",
    "        \n",
    "        \n",
    "        boxwhisker = hv.BoxWhisker((df_box['PCMLNP'], df_box['PCMEDS'], df_box['n_clientes_a_radio']  ),\n",
    "              ['Localidad', 'Especialidad'], 'Value').sort()\n",
    "        boxwhisker.opts(height=300)\n",
    "        \n",
    "        css = ['https://cdn.datatables.net/1.10.19/css/jquery.dataTables.min.css']\n",
    "        js = {\n",
    "            '$': 'https://code.jquery.com/jquery-3.4.1.slim.min.js',\n",
    "            'DataTable': 'https://cdn.datatables.net/1.10.19/js/jquery.dataTables.min.js'\n",
    "        }\n",
    "        \n",
    "        script = \"\"\"\n",
    "           \n",
    "            <script type=\"text/javascript\" src='https://code.jquery.com/jquery-3.4.1.slim.min.js'></script> \n",
    "            <script type=\"text/javascript\" src='https://cdn.datatables.net/1.10.19/js/jquery.dataTables.min.js'></script>\n",
    "            \n",
    "            <script type='text/javascript' src=  'https://cdn.datatables.net/t/dt/dt-1.10.11,fc-3.2.1,fh-3.1.1,r-2.0.2,se-1.1.2/datatables.min.js'></script>\n",
    "            <script src='https://cdn.datatables.net/buttons/1.0.3/js/dataTables.buttons.min.js'></script>\n",
    "            <script type='text/javascript' language='javascript' src='//cdn.datatables.net/buttons/1.1.2/js/buttons.flash.min.js'></script>\n",
    "            <script type='text/javascript' language='javascript' src='//cdnjs.cloudflare.com/ajax/libs/jszip/2.5.0/jszip.min.js'></script>\n",
    "            <script type='text/javascript' language='javascript' src='//cdn.rawgit.com/bpampuch/pdfmake/0.1.18/build/pdfmake.min.js'></script>\n",
    "            <script type='text/javascript' language='javascript' src='//cdn.rawgit.com/bpampuch/pdfmake/0.1.18/build/vfs_fonts.js'></script>\n",
    "            <script type='text/javascript' language='javascript' src='//cdn.datatables.net/buttons/1.1.2/js/buttons.html5.min.js'></script>\n",
    "            <script type='text/javascript' language='javascript' src='//cdn.datatables.net/buttons/1.1.2/js/buttons.print.min.js'></script>\n",
    "            <script type='text/javascript' src='static/js/bokeh.min.js?v=547e7d2591695b654def5914bdd697fa'></script>\n",
    "            <script type='text/javascript' src='static/js/bokeh-widgets.min.js?v=423bf6bb32b8def8b6c9df74817506e4'></script>\n",
    "            <script type='text/javascript' src='static/js/bokeh-tables.min.js?v=5f778b8a005d8538b5b13998ec45fc16'></script>\n",
    "            <script type='text/javascript' src='static/js/bokeh-gl.min.js?v=be19384f76795da42f51580e7b5fd473'></script>\n",
    "            <script>\n",
    "            \n",
    "            if (document.readyState === \"complete\") {\n",
    "            \n",
    "              $('.bk-data-table').dataTable({\n",
    "                            scrollY: 300,\n",
    "                            paging: false\n",
    "                        } );\n",
    "            } else {\n",
    "              $(document).ready(function () {\n",
    "                $('.bk-data-table').dataTable({\n",
    "                            scrollY: 300,\n",
    "                            paging: false\n",
    "                        } );\n",
    "              })\n",
    "            }\n",
    "            </script>\n",
    "            \"\"\"\n",
    "\n",
    "        html_tbl = self.tabla.dframe().to_html(classes=['example', 'panel-df', 'bk-data-table'])\n",
    "        render_datatable= pn.pane.HTML(html_tbl+script).object\n",
    "        \n",
    "        render_datatable=\"\"\"<head><meta charset=\"utf-8\"><link rel=\"stylesheet\" type=\"text/css\" \\\n",
    "        href=\"https://cdn.datatables.net/1.10.19/css/jquery.dataTables.min.css\"/> \\\n",
    "        <link rel=\"stylesheet\" type=\"text/css\" \\\n",
    "        href=\"https://cdn.datatables.net/responsive/2.2.3/css/responsive.dataTables.min.css\"/> \\\n",
    "        <link rel=\"stylesheet\" type=\"text/css\" \\ \n",
    "        href=\"https://cdn.datatables.net/t/dt/dt-1.10.11,fc-3.2.1,fh-3.1.1,r-2.0.2,se-1.1.2/datatables.min.css\"/> \\\n",
    "        <link rel=\"stylesheet\" type=\"text/css\" \\\n",
    "        href=\"https://cdn.datatables.net/1.10.11/css/jquery.dataTables.min.css\"> \\\n",
    "        <link rel=\"stylesheet\" type=\"text/css\" \\\n",
    "        href=\"https://cdn.datatables.net/buttons/1.1.2/css/buttons.dataTables.min.css\"> \\\n",
    "        </head>\"\"\" + render_datatable\n",
    "        \n",
    "        render_datatable=urllib.parse.quote(render_datatable)\n",
    "        base_html=\"\"\"<head>\n",
    "                    \n",
    "                    </head>\n",
    "                    <iframe width=800px height=300px src=data:text/html,\"\"\" + render_datatable \\\n",
    "                    +\"\"\" scrolling=\"no\" style=\"border-width: 0px\"></iframe>\"\"\"\n",
    "        \n",
    "        #return hv.Div(base_html) #esto lo tengo que trabajar mas.\n",
    "#         if index:\n",
    "#             label = 'Mean x, y: %.3f, %.3f' % tuple(arr.mean(axis=0))\n",
    "#         else:\n",
    "#             label = 'No selection'\n",
    "        #return points.clone(arr, label=label).opts(style=dict(color='red'))\n",
    "        return self.tabla\n",
    "    \n",
    "    @param.depends('localidades' , 'sel_rgo_cli', 'facturadores', 'agrup_servicios', 'alpha'\n",
    "                   ,'natups', 'red', 'parte_direccion','clusters', 'especialidad', watch=True)\n",
    "    def selected_info_activ(self, x_range=None, y_range=None):\n",
    "        \n",
    "        \n",
    "        clon_puntos=self.puntos\n",
    "        clon_acti=self.dask_moni_activ\n",
    "\n",
    "        if x_range is not None:\n",
    "            clon_puntos=clon_puntos.select(lng_mercator=x_range , lat_mercator=y_range)\n",
    "            #clon_acti_grup= clon_acti_grup.select(lng_mercator=x_range , lat_mercator=y_range)\n",
    "            #clon_acti=clon_acti.select(lng_mercator=x_range , lat_mercator=y_range)\n",
    "            \n",
    "        clon_acti_grup=self.dat_acti_agg.groupby(['PCMIUN', 'PCMNFC', 'AAT', 'FACTURACION_MENSUAL'\n",
    "                                            ,'lng_mercator', 'lat_mercator']).agg({\"CTA_ACTIVIDAD\": 'sum'})\n",
    "        \n",
    "        print(\"formas en activ: \", clon_acti_grup.shape, clon_acti.compute().shape)\n",
    "        #df_box=clon_puntos.data[['n_clientes_a_radio', 'PCMLNP', 'PCMEDS']].compute()\n",
    "        df_box=clon_acti_grup[['CTA_ACTIVIDAD']]\n",
    "        acti_min=df_box['CTA_ACTIVIDAD'].quantile(0.01)\n",
    "        acti_max=df_box['CTA_ACTIVIDAD'].quantile(0.99)\n",
    "        \n",
    "#         ht=hv.HexTiles( hv.Points(\n",
    "#             #datos_moni,\n",
    "#             clon_acti_grup,\n",
    "#             kdims=['lng_mercator', 'lat_mercator'],\n",
    "#             #cdims=dict({ \"AAT\":'AAT', \"FACTU\":'PCMNFC'}),\n",
    "#             vdims=['CTA_ACTIVIDAD' ]    ), \n",
    "#             kdims=['lng_mercator', 'lat_mercator'],\n",
    "#             #cdims=dict({ \"AAT\":'AAT', \"FACTU\":'PCMNFC'}),\n",
    "#             vdims=['CTA_ACTIVIDAD' ]    \n",
    "#               )#.redim.range(CTA_ACTIVIDAD=(0,100000))\n",
    "               \n",
    "        \n",
    "#         htptos=hv.Points(clon_acti_grup, kdims=['lng_mercator', 'lat_mercator'])\n",
    "#         overlay = ht * htptos\n",
    "        overlay=self.datos.aggregate(kdims=['PPSIUN'] , vdims=['clientes_a_radio', 'AAT','FACTURACION_MENSUAL']\n",
    "                                     , function=np.sum) .to(hv.Points).redim.values(FACTURACION_MENSUAL=(0,10000)) \\\n",
    "                                    .opts(colorbar=True)\n",
    "        return   overlay.opts( opts.Points(size=5, color='black'\n",
    "                          , min_width=500, min_height=300\n",
    "                          , responsive=True, colorbar=True)\n",
    "               ) * self.map_tiles\n",
    "\n",
    "        \n",
    "        return overlay.opts(opts.HexTiles(\n",
    "                    min_width=700, min_height=550,\n",
    "                    tools=['hover']\n",
    "                    , aggregator=np.sum, min_count=10, alpha=self.alpha\n",
    "                    ,cmap='fire' , colorbar=True\n",
    "                    , xaxis=None, yaxis=None\n",
    "                    , responsive=True\n",
    "                                         )\n",
    "             , opts.Points(size=1, color='black')\n",
    "               )\n",
    "    \n",
    "    @param.depends('localidades' , 'sel_rgo_cli', 'facturadores', 'agrup_servicios'\n",
    "                   ,'natups', 'red', 'parte_direccion','clusters', 'especialidad', watch=True)\n",
    "    def selected_info_scatter(self, x_range=None, y_range=None):\n",
    "        \n",
    "        print(\"seleccion en selected_info: \" , x_range, y_range)\n",
    "        clon_puntos=self.puntos\n",
    "        print(\"datos dentro de clon puntos: \", clon_puntos.data.compute().shape[0] )\n",
    "        if x_range is not None:\n",
    "            clon_puntos=clon_puntos.select(lng_mercator=x_range , lat_mercator=y_range)\n",
    "        print(\"forma de clon_puntos despues selecionar\", len(clon_puntos))\n",
    "        \n",
    "        \n",
    "        #df_box=clon_puntos.data[['n_clientes_a_radio', 'PCMLNP', 'PCMEDS']].compute()\n",
    "        df_box=clon_puntos.data[['n_clientes_a_radio', 'Shape__Are' , 'FACTURACION_MENSUAL']].compute()\n",
    "        fac_min=df_box['FACTURACION_MENSUAL'].quantile(0.01)\n",
    "        fac_max=df_box['FACTURACION_MENSUAL'].quantile(0.99)\n",
    "        print(\"rango clientes: \", fac_min, fac_max)\n",
    "        \n",
    "        sct=hv.Scatter( df_box,kdims=[('Shape__Are', 'Area Localidad'),\n",
    "                                       ('n_clientes_a_radio', 'clientes') ]\n",
    "                            , vdims=[ ('FACTURACION_MENSUAL', 'Facturación')]\n",
    "                                       ).redim.range(FACTURACION_MENSUAL=(fac_min, fac_max)).opts(framewise=True)\n",
    "        \n",
    "        sct = hv.HexTiles(df_box, kdims=[('Shape__Are', 'Area Localidad'),\n",
    "                                       ('n_clientes_a_radio', 'clientes') ], vdims=['FACTURACION_MENSUAL'])\\\n",
    "                                .opts(framewise=True)\n",
    "        obj_desc=self.datos.data.compute()\n",
    "        obj_desc=obj_desc[['FACTURACION_MENSUAL', 'n_clientes_a_radio']].describe().to_html()\n",
    "        sct=hv.Div(\"\"\"\n",
    "            <h1>Datos de interés</h1>\n",
    "            <h3>Realice sus selecciones y visualize cuantos servicios existen en la zona\n",
    "            y cuantos clientes están a un radio de 1500m.\n",
    "            Si pulsa en el botón exportar a excel, obtendrá un documento con las selección de datos</h2>\n",
    "            <div align='right'>\"\"\"+ obj_desc+\"\"\"</div>\"\"\")\n",
    "        sct=hv.Div(\"\"\"\n",
    "            <h1>Datos de interés</h1>\n",
    "            <h3>Realice sus selecciones y visualize cuantos servicios existen en la zona\n",
    "            y cuantos clientes están a un radio de 1500m.</h3>\n",
    "            <marquee>\n",
    "            <h5>Si pulsa en el botón exportar a excel, obtendrá un documento con las selección de datos</h5>\n",
    "            </marquee>\n",
    "            <iframe src='http://172.16.241.232/ibi_apps/run.bip?BIP_REQUEST_TYPE=BIP_RUN&BIP_folder=IBFS%253A%252FWFC%252FRepository%252FGaleno%252FInformes_Galeno%252FActividadMP&BIP_item=grafico_for_caso_uso_cmedico.fex&PR1SUC=50' \n",
    "            title=\"Datos facturación\"\n",
    "            width=\"800\"\n",
    "            height=\"210\">\n",
    "            </iframe>\n",
    "            \n",
    "           \"\"\")\n",
    "        conjunto_ppsiun=clon_puntos.data.PCMIUN.unique().compute()\n",
    "        if len(conjunto_ppsiun)==0: conjunto_ppsiun=[-1]\n",
    "        filtro_ppsiun_wf= ' OR '.join([str(id).replace('.0', '') for id in conjunto_ppsiun])\n",
    "        print(\"conjunto PPSIUN: \" , conjunto_ppsiun[0:2] , len(conjunto_ppsiun)  )\n",
    "        conjunto_espec=clon_puntos.data.PCMECD.unique().compute()\n",
    "        if len(conjunto_espec)==0: conjunto_espec=[-1]\n",
    "        filtro_espec_wf= ' OR '.join([str(id).replace('.0', '') for id in conjunto_espec])\n",
    "        \n",
    "        if self.facturadores != 'Todos':\n",
    "            S=self.facturadores\n",
    "            poscoma=S.find(\",\")\n",
    "            if poscoma==-1:\n",
    "                proveedor=self.facturadores\n",
    "                case_proveedor=\"&PROVEEDOR=\" + proveedor \n",
    "            else:\n",
    "                ini=poscoma+2\n",
    "                end=len(S)\n",
    "                poscoma\n",
    "                end\n",
    "                nombre=S[ini: end]\n",
    "                apellidos=S[0:poscoma]\n",
    "                apellidos\n",
    "                proveedor=nombre +', ' + apellidos\n",
    "                proveedor\n",
    "                case_proveedor=\"&PROVEEDOR=\" + proveedor \n",
    "            \n",
    "        else:\n",
    "            case_proveedor=\"&PROVEEDOR=_FOC_NULL\"\n",
    "        \n",
    "#         case_ppsiun='&PPSIUN='+filtro_ppsiun_wf\n",
    "#         filtros={ \"SUC\":50, \"PPSIUN\": filtro_ppsiun_wf }  \n",
    "#         filtros={ \"SUC\":50 }  \n",
    "#         #filtros = json.dumps(filtros)\n",
    "#         # Convert to String\n",
    "#         filtros = str(filtros)\n",
    "#         # Convert string to byte\n",
    "#         filtros = filtros.encode('utf-8')\n",
    "#         #filtros =urllib.parse.urlencode(filtros)\n",
    "#         url_post=\"http://172.16.241.232/ibi_apps/run.bip?BIP_REQUEST_TYPE=BIP_RUN&IBIMR_domain=Galeno&IBIMR_action=MR_RUN_FEX\" \\\n",
    "#         + \"&IBIMR_fex=/WFC/Repository/Galeno/Informes_Galeno/ActividadMP/grafico_for_caso_uso_cmedico.fex\" \\\n",
    "#         + \"&BIP_folder=/WFC/Repository/Galeno/Informes_Galeno/ActividadMP\" \\\n",
    "#         + \"&BIP_item=grafico_for_caso_uso_cmedico.fex\"\n",
    "#         print(\"urlpost: \" , url_post)\n",
    "#         #data_post = urllib.parse.urlencode(filtros).encode()\n",
    "#         print(\"data_post: \", filtros)\n",
    "#         #req =  urllib.request.Request(url_post, data=filtros) # this will make the method \"POST\"\n",
    "#         #la anterior no funciona, con el modulo request funciona mejor\n",
    "#         r = requests.post(url_post  )\n",
    "#         help(requests.post)\n",
    "#         print( r.status_code )\n",
    "#         print( r )\n",
    "#         #resp = urllib.request.urlopen(req)\n",
    "#         #print(resp)\n",
    "        \n",
    "#         base_url=composicion_csta=\"'http://172.16.241.232/ibi_apps/run.bip?BIP_REQUEST_TYPE=BIP_RUN\" \\\n",
    "#         +\"&BIP_folder=IBFS%253A%252FWFC%252FRepository%252FGaleno%252FInformes_Galeno%252FActividadMP\" \\\n",
    "#         +\"&BIP_item=grafico_for_caso_uso_cmedico.fex&SUC=50'\"\n",
    "#         print(\"base_url: \", base_url)\n",
    "#         composicion_csta=\"'http://172.16.241.232/ibi_apps/run.bip?BIP_REQUEST_TYPE=BIP_RUN\" \\\n",
    "#         +\"&BIP_folder=IBFS%253A%252FWFC%252FRepository%252FGaleno%252FInformes_Galeno%252FActividadMP\" \\\n",
    "#         +\"&BIP_item=grafico_for_caso_uso_cmedico.fex&SUC=50\"\\\n",
    "#         + case_proveedor+ \"'\"\n",
    "        \n",
    "#         print(composicion_csta, case_proveedor)\n",
    "        print(\"filtro ppsiun: \", filtro_ppsiun_wf)\n",
    "        args=[(\"BIP_REQUEST_TYPE\", \"BIP_RUN\" ),\n",
    "                (\"BIP_folder\", \"/WFC/Repository/Galeno/Informes_Galeno/ActividadMP\") ,\n",
    "                (\"BIP_item\", \"grafico_for_caso_uso_cmedico.fex\"),\n",
    "                (\"SUC\", \"50\"),\n",
    "                (\"PPSIUN\", filtro_ppsiun_wf),\n",
    "                (\"ESPECIALIDAD\", filtro_espec_wf)\n",
    "                     ]\n",
    "        \n",
    "        headers = {'content-type': 'application/x-www-form-urlencoded'}\n",
    "        base_url=  \"http://172.16.241.232/ibi_apps/run.bip?BIP_REQUEST_TYPE=BIP_RUN\" \\\n",
    "                     +\"&BIP_folder=IBFS%253A%252FWFC%252FRepository%252FGaleno%252FInformes_Galeno%252FActividadMP\" \\\n",
    "                     +\"&BIP_item=grafico_for_caso_uso_cmedico.fex\"\n",
    "        base2_url=  \"http://172.16.241.232/ibi_apps/run.bip?BIP_REQUEST_TYPE=BIP_RUN\" \\\n",
    "                     +\"&BIP_folder=IBFS%253A%252FWFC%252FRepository%252FGaleno%252FInformes_Galeno%252FActividadMP\" \\\n",
    "                     +\"&BIP_item=src_get_aat.fex\"\n",
    "        args=[\n",
    "        (\"SUC\", 50),\n",
    "        (\"PPSIUN\", filtro_ppsiun_wf),\n",
    "        (\"ESPECIALIDAD\", filtro_espec_wf)\n",
    "             ]\n",
    "        #r = requests.post(api_url, data = {\"var 1\":\"value\", \"var 2\":\"value\"}, verify=True)\n",
    "        s = requests.Session()\n",
    "        response=s.post(base_url, data=args,  timeout=15 , auth=HttpNegotiateAuth())\n",
    "        #response2=s.post(base2_url, data=args,  timeout=15 , auth=HttpNegotiateAuth())\n",
    "        #print(\"json naat: \", response2.text)\n",
    "        \n",
    "        #print(\"tipo json_aat: \",type( response2.text), type(json.dumps(response2.text)), type(json.loads( response2.text))   )\n",
    "       # json_aat=dict(response.text)\n",
    "        #print(\"tipo json_aat: \" , type(json_aat))\n",
    "        #print(\"response wf es: \" , response.text)\n",
    "#         sct=hv.Div(\"\"\"\n",
    "#             <h3>Datos de Facturación</h3>\n",
    "#             <iframe src=\"\"\"+ composicion_csta +\"\"\"\n",
    "#             title=\"Datos facturación\"\n",
    "#             frameborder=\"0\"\n",
    "#             width=\"400\"\n",
    "#             height=\"210\">\n",
    "#             </iframe>\n",
    "            \n",
    "#            \"\"\")\n",
    "\n",
    "        if( response.status_code in [200, 201]):\n",
    "            outp= response.text \n",
    "            #sustituyo la referencia del script por la ip de galeno sino considera que esta en el\n",
    "            #servidor local\n",
    "            outp=outp.replace(\"/ibi_apps/tdg/jschart/distribution/tdgchart-min.js\"\\\n",
    "                             ,\"http://172.16.241.232/ibi_apps/tdg/jschart/distribution/tdgchart-min.js\")\n",
    "            #outp=outp.replace(\"<!DOCTYPE html>\", \"\")\n",
    "            outp=urllib.parse.quote(outp)\n",
    "            base_html=\"\"\"<h4>Datos de Facturación</h4><iframe width=550px height=200px src=data:text/html,\"\"\" + outp \\\n",
    "                    +\"\"\" scrolling=\"no\" style=\"border-width: 0px\"></iframe>\"\"\"\n",
    "           \n",
    "            #base_html=base_html.replace(\"about:blank\", outp)\n",
    "            outp=base_html\n",
    "        else:\n",
    "            outp=\"<h4>esperando al servidor (Galeno)...<h4>\"\n",
    "            \n",
    "        sct=hv.Div(base_html)\n",
    "            \n",
    "        #sct = sct.opts(color='FACTURACION_MENSUAL', size=dim('FACTURACION_MENSUAL')/10 )\n",
    "        #distri=hv.Distribution(df_box)\n",
    "#         boxwhisker = hv.BoxWhisker((df_box['PCMLNP'], df_box['PCMEDS'], df_box['n_clientes_a_radio']  ),\n",
    "#               ['Localidad', 'Especialidad'], 'Value').sort()\n",
    "#         boxwhisker.opts(height=300)\n",
    "        \n",
    "        \n",
    "#         if index:\n",
    "#             label = 'Mean x, y: %.3f, %.3f' % tuple(arr.mean(axis=0))\n",
    "#         else:\n",
    "#             label = 'No selection'\n",
    "        #return points.clone(arr, label=label).opts(style=dict(color='red'))\n",
    "        return sct #boxwhisker\n",
    "    @param.depends('localidades' , 'sel_rgo_cli', 'facturadores', 'agrup_servicios'\n",
    "                   ,'natups', 'red', 'parte_direccion', 'clusters', 'especialidad', watch=True)\n",
    "    def selected_info_box(self, x_range=None, y_range=None):\n",
    "        #si estuviesemos trabajando conuna seleccion 1d sobre puntos que no va a ser el caso\n",
    "        #recogeriamos la matriz de puntos seleccionada, de la siguiente forma:\n",
    "#         arr = self.puntos.array()[index]\n",
    "#         if len(arr)==0:\n",
    "#             tabla=hv.Table(self.puntos)\n",
    "#         else:\n",
    "#             tabla=hv.Table( self.puntos.clone(arr) )\n",
    "\n",
    "#         print(\"array en selected_info es: \" , arr)\n",
    "\n",
    "        \n",
    "        print(\"seleccion en selected_info: \" , x_range, y_range)\n",
    "        clon_puntos=self.puntos\n",
    "        print(\"datos dentro de clon puntos: \", clon_puntos.data.compute().shape[0] )\n",
    "        if x_range is not None:\n",
    "            clon_puntos=clon_puntos.select(lng_mercator=x_range , lat_mercator=y_range)\n",
    "        print(\"forma de clon_puntos despues selecionar\", len(clon_puntos))\n",
    "        \n",
    "        \n",
    "        #df_box=clon_puntos.data[['n_clientes_a_radio', 'PCMLNP', 'PCMEDS']].compute()\n",
    "        df_box=clon_puntos.data[['n_clientes_a_radio']].compute()\n",
    "        cli_min=df_box['n_clientes_a_radio'].quantile(0.01)\n",
    "        cli_max=df_box['n_clientes_a_radio'].quantile(0.99)\n",
    "        print(\"rango clientes: \", cli_min, cli_max)\n",
    "        distri=hv.Distribution(df_box).redim.range(n_clientes_a_radio=(cli_min, cli_max)).opts(framewise=True)\n",
    "        div=hv.Div(\"\"\"\n",
    "            <h1>Datos de interés</h1>\n",
    "            <h3>Realice sus selecciones y visualize cuantos servicios existen en la zona\n",
    "            y cuantos clientes están a un radio de 1500m.</h3>\n",
    "            <marquee>\n",
    "            <h5>Si pulsa en el botón exportar a excel, obtendrá un documento con las selección de datos</h5>\n",
    "            </marquee>\n",
    "            <iframe src='http://172.16.241.232/ibi_apps/run.bip?BIP_REQUEST_TYPE=BIP_RUN&BIP_folder=IBFS%253A%252FWFC%252FRepository%252FGaleno%252FInformes_Galeno%252FActividadMP&BIP_item=grafico_for_caso_uso_cmedico.fex&PR1SUC=50' \n",
    "            title=\"Datos facturación\"\n",
    "            width=\"400\"\n",
    "            height=\"210\">\n",
    "            </iframe>\n",
    "            \n",
    "           \"\"\")\n",
    "        #distri=hv.Distribution(df_box)\n",
    "#         boxwhisker = hv.BoxWhisker((df_box['PCMLNP'], df_box['PCMEDS'], df_box['n_clientes_a_radio']  ),\n",
    "#               ['Localidad', 'Especialidad'], 'Value').sort()\n",
    "#         boxwhisker.opts(height=300)\n",
    "        \n",
    "        \n",
    "#         if index:\n",
    "#             label = 'Mean x, y: %.3f, %.3f' % tuple(arr.mean(axis=0))\n",
    "#         else:\n",
    "#             label = 'No selection'\n",
    "        #return points.clone(arr, label=label).opts(style=dict(color='red'))\n",
    "        return distri #boxwhisker\n",
    "   \n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "    @param.depends('localidades' , 'sel_rgo_cli', 'facturadores', 'agrup_servicios'\n",
    "                   ,'natups', 'red', 'parte_direccion', 'Calcula_aat', 'clusters', 'especialidad', watch=True)\n",
    "    def selected_info_aat(self, x_range=None, y_range=None):\n",
    "        print(\"Estamos en selected_info_aat --> variable bCalculate_aat: \",self.bCalculate_aat, \"var ctl_calcular: \"\n",
    "              , self.ctl_calcular )\n",
    "        \n",
    "        if self.ctl_calcular.value ==\"No\" : \n",
    "            arg_nefasto=(\"SUC\", -1000)\n",
    "        else:\n",
    "            arg_nefasto=(\"SUC\", 50)\n",
    "        \n",
    "        print(\"arg_nefasto es: \", arg_nefasto)\n",
    "        #print(\"seleccion en selected_info: \" , x_range, y_range)\n",
    "        clon_puntos=self.puntos\n",
    "        #print(\"datos dentro de clon puntos: \", clon_puntos.data.compute().shape[0] )\n",
    "        if x_range is not None:\n",
    "            clon_puntos=clon_puntos.select(lng_mercator=x_range , lat_mercator=y_range)\n",
    "        print(\"forma de clon_puntos despues selecionar\", len(clon_puntos))\n",
    "        \n",
    "        \n",
    "        #df_box=clon_puntos.data[['n_clientes_a_radio', 'PCMLNP', 'PCMEDS']].compute()\n",
    "        df_box=clon_puntos.data[['n_clientes_a_radio', 'Shape__Are' , 'FACTURACION_MENSUAL']].compute()\n",
    "        fac_min=df_box['FACTURACION_MENSUAL'].quantile(0.01)\n",
    "        fac_max=df_box['FACTURACION_MENSUAL'].quantile(0.99)\n",
    "        print(\"rango clientes: \", fac_min, fac_max)\n",
    "        \n",
    "        obj_desc=self.datos.data.compute()\n",
    "        obj_desc=obj_desc[['FACTURACION_MENSUAL', 'n_clientes_a_radio']].describe().to_html()\n",
    "        \n",
    "        conjunto_ppsiun=clon_puntos.data.PCMIUN.unique().compute()\n",
    "        avg_cli_radio=clon_puntos.data.n_clientes_a_radio.mean().compute()\n",
    "        if avg_cli_radio==0: avg_cli_radio=1\n",
    "        if len(conjunto_ppsiun)==0: conjunto_ppsiun=[-1]\n",
    "        filtro_ppsiun_wf= ' OR '.join([str(id).replace('.0', '') for id in conjunto_ppsiun])\n",
    "        print(\"conjunto PPSIUN: \" , conjunto_ppsiun[0:2] , len(conjunto_ppsiun)  )\n",
    "        conjunto_espec=clon_puntos.data.PCMECD.unique().compute()\n",
    "        if len(conjunto_espec)==0: conjunto_espec=[-1]\n",
    "        filtro_espec_wf= ' OR '.join([str(id).replace('.0', '') for id in conjunto_espec])\n",
    "        \n",
    "        nProfs=len(clon_puntos.data.loc[clon_puntos.data.PCMNPR != 'sin profesional asignado'] \\\n",
    "                   .PCMNPR.unique().compute() )\n",
    "        nota_proveedores=clon_puntos.data.loc[clon_puntos.data.PRESP > -1 ] \\\n",
    "                   .PRESP.mean().compute() \n",
    "        tpobl=clon_puntos.data.compute()\n",
    "        tpobl.fillna(0, inplace=True)\n",
    "        tpobl=tpobl.groupby(['C_MUN_PRO'], as_index=False).agg({\n",
    "                                                         'POB18': [pd.Series.max]\n",
    "                                                          }).reset_index()\n",
    "        \n",
    "        #print(\"forma de tpobl: \", tpobl.shape, tpobl.head(7), tpobl.columns)\n",
    "        total_poblacion=tpobl['POB18'].values.sum()\n",
    "        tpobl=None\n",
    "        \n",
    "        if self.facturadores != 'Todos':\n",
    "            S=self.facturadores\n",
    "            poscoma=S.find(\",\")\n",
    "            if poscoma==-1:\n",
    "                proveedor=self.facturadores\n",
    "                case_proveedor=\"&PROVEEDOR=\" + proveedor \n",
    "            else:\n",
    "                ini=poscoma+2\n",
    "                end=len(S)\n",
    "                poscoma\n",
    "                end\n",
    "                nombre=S[ini: end]\n",
    "                apellidos=S[0:poscoma]\n",
    "                apellidos\n",
    "                proveedor=nombre +', ' + apellidos\n",
    "                proveedor\n",
    "                case_proveedor=\"&PROVEEDOR=\" + proveedor \n",
    "            \n",
    "        else:\n",
    "            case_proveedor=\"&PROVEEDOR=_FOC_NULL\"\n",
    "        \n",
    "        headers = {'content-type': 'application/x-www-form-urlencoded'}\n",
    "        \n",
    "        base_url=  \"http://172.16.241.232/ibi_apps/run.bip?BIP_REQUEST_TYPE=BIP_RUN\" \\\n",
    "                     +\"&BIP_folder=IBFS%253A%252FWFC%252FRepository%252FGaleno%252FInformes_Galeno%252FActividadMP\" \\\n",
    "                     +\"&BIP_item=src_get_aat.fex\"\n",
    "        args=[\n",
    "        arg_nefasto ,\n",
    "        (\"PPSIUN\", filtro_ppsiun_wf),\n",
    "        (\"ESPECIALIDAD\", filtro_espec_wf),\n",
    "        (\"CLIRADIO\", avg_cli_radio )\n",
    "             ]\n",
    "        s = requests.Session()\n",
    "        \n",
    "        response=s.post(base_url, data=args,  timeout=15 , auth=HttpNegotiateAuth())\n",
    "        \n",
    "        print(\"json naat: \", response.text)\n",
    "        print(\"tipo json_aat: \",type( response.text), type(json.dumps(response.text)), type(json.loads( response.text))   )\n",
    "        json_aat=json.loads( response.text)\n",
    "        print(\"return: \",json_aat)\n",
    "#         print(\"return: \", json_aat[\"AAT_TDKV\"][0][\"TAAT\"], int(json_aat[\"AAT_TDKV\"][0][\"TAAT\"].replace(\"0.00\",\"\") ) \\\n",
    "#              , json_aat[\"AAT_TDKV\"][1][\"TAAT\"], int(json_aat[\"AAT_TDKV\"][1][\"TAAT\"].replace(\"0.00\",\"\") ))\n",
    "\n",
    "        if( response.status_code in [200, 201]):\n",
    "            n_ppsiun=len(conjunto_ppsiun)\n",
    "#             tbl_jsn={\"AAT 2018\" : int(json_aat[\"AAT_TDKV\"][0][\"TAAT\"].replace(\".00\", \"\")) \\\n",
    "#                         ,\"AAT 2019\" : int(json_aat[\"AAT_TDKV\"][1][\"TAAT\"].replace(\".00\", \"\")) \\\n",
    "#                         , \"N. proveedores\": n_ppsiun\n",
    "#                         }\n",
    "            \n",
    "            tbl= pd.DataFrame(json_aat[\"AAT_TDKV\"], index=np.asarray(range( len(json_aat[\"AAT_TDKV\"] )   )))\n",
    "#             tbl=tbl.pivot_table(values='TAAT', columns='AÑO',\n",
    "#                    aggfunc=lambda x: x.dropna().sum())#.to_html(classes='table table-striped table-bordered table-hover table-condensed')\n",
    "           \n",
    "            tbl['TAAT']=tbl['TAAT'].astype('float32')\n",
    "            tbl['TAATVSRADIO']=tbl['TAATVSRADIO'].astype('float32')\n",
    "            \n",
    "            tbl=tbl.pivot_table(values=['TAAT','TAATVSRADIO'] , index=['AÑO'] \n",
    "                   ,aggfunc= { \"TAAT\" : np.sum , \"TAATVSRADIO\" : np.mean }, fill_value=0  )\n",
    "\n",
    "            #tbl.reset_index(inplace=True)\n",
    "            tbl=tbl.rename_axis(None)\n",
    "#             tbl=tbl.pivot_table(values=['TAAT', 'TAATVSRADIO'], columns='AÑO',\n",
    "#                    aggfunc=lambda x: x.sum())\n",
    "            print(\"columnas en tbl: \" , tbl.columns)\n",
    "            tbl[\"N.FACTUR\"]=n_ppsiun\n",
    "            tbl[\"N.PROFS\"]=nProfs\n",
    "            tbl[\"POBLACION\"]=total_poblacion\n",
    "            tbl[\"NOTA ENCUESTA\"]=nota_proveedores\n",
    "            tbl.columns=['AAT', 'AAT vs clientes radio', 'N.FACTUR', 'N.PROFS', 'POBLACION', 'NOTA ENCUESTA']\n",
    "            #tbl = pd.DataFrame(tbl_jsn, index=[0], columns=[\"AAT 2018\", \"AAT 2019\", \"N. proveedores\"])\n",
    "            tbl=tbl.style.apply(style_line).render()\n",
    "            \n",
    "            print(\"objeto tbl despues de render es de tipo: \", type(tbl))\n",
    "            print(tbl)\n",
    "            tbl=tbl.replace('table id=', 'table class=\"greenTable\" id=')\n",
    "            #json_aat=json.dumps(json_aat)\n",
    "#             outp=hv.Div(\"<h4>Recuento asegurados atendidos</h4><nav>AAT 2018: \" \\\n",
    "#                         + str(int(json_aat[\"AAT_TDKV\"][0][\"TAAT\"].replace(\".00\", \"\"))) + \"</br>\"\\\n",
    "#                   \"<nav>AAT 2019: \" + str( int(json_aat[\"AAT_TDKV\"][1][\"TAAT\"].replace(\".00\", \"\"))) )\n",
    "            outp=hv.Div(\"<div align = 'left'>\"+ tbl + \"</div>\" )\n",
    "            \n",
    "        else:\n",
    "            outp= hv.Div(\"esperando al servidor (Galeno)...\")\n",
    "            \n",
    "        sct=outp\n",
    "            \n",
    "        \n",
    "        return sct\n",
    "        \n",
    "    \n",
    "    def selected_info_dyn(self):\n",
    "        return hv.DynamicMap(self.selected_info, streams=[self.sel_fortabla]).options(\n",
    "        height=400,\n",
    "        width=990,\n",
    "        toolbar = None \n",
    "            )\n",
    "    def selected_info_box_dyn(self):\n",
    "        return hv.DynamicMap(self.selected_info_box, streams=[self.sel_fortabla]).options(\n",
    "        height=320,\n",
    "        #max_width=800,\n",
    "        toolbar = None \n",
    "        )\n",
    "    def selected_info_scatter_dyn(self):\n",
    "        return hv.DynamicMap(self.selected_info_scatter, streams=[self.sel_fortabla]).options(\n",
    "        height=320,\n",
    "        width=550,\n",
    "        toolbar = None \n",
    "        ) \n",
    "    def selected_info_aat_dyn(self):\n",
    "       \n",
    "        return hv.DynamicMap(self.selected_info_aat, streams=[self.sel_fortabla]).options(\n",
    "        height=40,\n",
    "        width=500,\n",
    "        toolbar = None \n",
    "        ) \n",
    "    def selected_info_activ_dyn(self):\n",
    "       \n",
    "        return hv.DynamicMap(self.selected_info_activ, streams=[self.sel_fortabla]).options(\n",
    "            min_width=300,\n",
    "            min_height=250\n",
    "        #height=600,\n",
    "        #width=800,\n",
    "        #toolbar = None \n",
    "        ) \n",
    "    #si queiero pasar determinados argumentos solo cuando cambien ellos mismos y no onsiderar cualquier\n",
    "    #cambio de cualquier parametro para ahorrar en rendimiento y no calcular todo todas las veces,\n",
    "    #no puedo repetir las dependencias en los procedimiento de cambio y aqui para pintarlo, yaque,\n",
    "    #lo que pasara es que se pintara con el parametro sincambiar antes de que se notifique el cambio\n",
    "    #en el procedimiento de cambio.\n",
    "    @param.depends('localidades', 'colormap', 'spreading', 'muestra_nombres' ,watch=True)\n",
    "    def prepara_grafico(self, **kwargs):\n",
    "        \n",
    "        \n",
    "        print( self.name, self.localidades)\n",
    "        #if (not self.set_datos.empty):\n",
    "\n",
    "\n",
    "#             sombreador=datashade(hv.DynamicMap(self.SeleccionaDatos), cmap=self.param.colormap\n",
    "#                                  ,   streams=[RangeXY()]\n",
    "#                                  , **opts2)\n",
    "\n",
    "        #*********************************************************************************\n",
    "        #En el caso típico de tener conjuntos de datos mucho mayor que la resolución trama, \n",
    "        #HoloViews operaciones que funcionan en el conjunto de datos completo \n",
    "        #Datashader-basa ( rasterize, aggregate, regrid) son computacionalmente caro; \n",
    "        #los otros no lo son ( shade, spread, dynspread, etc.)\n",
    "        #*********************************************************************************\n",
    "        #el precompute=True en este caso hace que las interacciones sean rápidas, sino\n",
    "        #cada vez que mueves el mapa son 25-40 segundos\n",
    "        #*********************************************************************************\n",
    "        #decido no hacer el rasterize, si lo hago piero el etalle de la distincion del color\n",
    "        #que si hace el datashade\n",
    "\n",
    "        if self.localidades != 'Todas':\n",
    "            sel_datos=self.ds_pd.loc[self.ds_pd['PCMLNP']==self.localidades].copy()\n",
    "        else:\n",
    "            sel_datos=self.ds_pd.copy()\n",
    "\n",
    "\n",
    "\n",
    "        x_range_min = sel_datos['lng_mercator'].quantile(0.01)\n",
    "        x_range_max = sel_datos['lng_mercator'].quantile(0.99)\n",
    "        y_range_min = sel_datos['lat_mercator'].quantile(0.01)\n",
    "        y_range_max = sel_datos['lat_mercator'].quantile(0.99)\n",
    "\n",
    "        #shape_are se expresa en hectareas -.> 1 hectarea son 10.000 m cuadrados\n",
    "        if x_range_min == x_range_max:\n",
    "            x_range_max=x_range_min + sel_datos['Shape__Are'].max()*(10000/0.75)\n",
    "            x_range_min=x_range_min - sel_datos['Shape__Are'].max()*(10000/0.75)\n",
    "        else:\n",
    "            if  (x_range_max - x_range_min) < 5000:\n",
    "                x_range_max+=2500\n",
    "                x_range_min-=2500\n",
    "\n",
    "        if y_range_min == y_range_max:\n",
    "            y_range_max=y_range_min  + sel_datos['Shape__Are'].max()*(10000/0.75) \n",
    "            y_range_min=y_range_min  - sel_datos['Shape__Are'].max()*(10000/0.75) \n",
    "        else:\n",
    "            if  (y_range_max - y_range_min) < 5000:\n",
    "\n",
    "                y_range_max+=2500\n",
    "                y_range_min-=2500\n",
    "\n",
    "        sw = (x_range_min,y_range_min)\n",
    "        ne = (x_range_max,y_range_max)\n",
    "        SF = zip(sw, ne)\n",
    "\n",
    "        print(\"canvas: \" ,y_range_min, y_range_max, x_range_min, x_range_max)\n",
    "        print(\"region seleccionada: \" , *SF)\n",
    "\n",
    "        self.ventana_actual['x_range_min']=x_range_min\n",
    "        self.ventana_actual['x_range_max']=x_range_max\n",
    "        self.ventana_actual['y_range_min']=y_range_min\n",
    "        self.ventana_actual['y_range_max']=y_range_max\n",
    "        \n",
    "        \n",
    "        self.seleccion=self.sel_fortabla\n",
    "            \n",
    "        \n",
    "        \n",
    "       \n",
    "        print(\"streaming in prepara_grafico x sel_fortalba: \", self.sel_fortabla)\n",
    "#             pts=hv.DynamicMap(self.SeleccionaDatos, streams=[RangeXY(transient=True)]) \\\n",
    "#                     .opts( norm=dict(framewise=True))\n",
    "\n",
    "        pts=hv.DynamicMap(self.SeleccionaDatos, streams=[hv.streams.RangeXY(source=self.spreaded_forselect)] ).opts(axiswise=True)\n",
    "          \n",
    "\n",
    "        \n",
    "        #seleccion rango de clientes a radio\n",
    "        #pts.select(n_clientes_a_radio = self.param.sel_rgo_cli)\n",
    "        \n",
    "        shaded     = datashade( pts ,streams=[RangeXY(transient=True)]\n",
    "                               , cmap=self.param['colormap'] \n",
    "                               , normalization='eq_hist' \n",
    "                               ,x_range=(x_range_min, x_range_max) , y_range=(y_range_min, y_range_max) \n",
    "                               ,x_sampling=10, y_sampling=10\n",
    "                         ).opts(axiswise=True)\n",
    "        #spreaded   = spread(shaded, px=4, how=\"add\")#esta opcion sin rasterize previo da error.\n",
    "        #spreaded   = dynspread(shaded, threshold=0.8, max_px=self.param.spreading, how='over' ).opts(axiswise=True)\n",
    "        spreaded   = dynspread(shaded, threshold=0.8, max_px=1, how='over' ).opts(axiswise=True)\n",
    "#         #esta base_forselect no puede ser un dinamicmap, la creo preciesamente x eso para que sea\n",
    "#         #la base para seleccionar con el stream un rango de puntos, asi podemos filtrar la tabla\n",
    "#         #con la seleccion realizada, pongo el alpha muy bajo para que no se vea.\n",
    "        \n",
    "#         base_forselect=datashade( self.puntos ,streams=[RangeXY(transient=True)]\n",
    "#                                , cmap=self.param['colormap'] \n",
    "#                                , normalization='eq_hist' \n",
    "#                                ,x_range=(x_range_min, x_range_max) , y_range=(y_range_min, y_range_max) \n",
    "#                                  , x_sampling=0.00001, y_sampling=0.00001\n",
    "#                          ).opts(alpha=0.1)\n",
    "#         spreaded_forselect   = dynspread(base_forselect, threshold=0.4\n",
    "#                                          , max_px=self.param.spreading, how='over'\n",
    "#                                         , streams=[RangeXY(transient=True)]).opts( alpha=0.1)\n",
    "        \n",
    "       \n",
    "        renderer = hv.renderer('bokeh')\n",
    "\n",
    "#             plot_ptos = renderer.get_plot(pts[0])\n",
    "#             print(\"Info plot_ptos: \", type(plot_ptos),dir(plot_ptos), plot_ptos.streams, plot_ptos.xlim, plot_ptos.ylim)\n",
    "\n",
    "\n",
    "        #spreaded=spreaded.select(lng_mercator=(x_range_min , x_range_max) , lat_mercator=(y_range_min , y_range_max) )\n",
    "        dataplot   = spreaded#.apply.opts(**opts1)\n",
    "        \n",
    "        dataplot= dynspread( datashade(hv.DynamicMap(self.SeleccionaDatos, streams=[RangeXY(transient=True)])\n",
    "                                   , normalization='eq_hist'\n",
    "                                , cmap=self.param['colormap'] \n",
    "                                   , width=conf_width , height=conf_height\n",
    "                                    ,x_range=(x_range_min, x_range_max) , y_range=(y_range_min, y_range_max) \n",
    "                                   ,x_sampling=5, y_sampling=5\n",
    "                                   \n",
    "                                  ) , threshold=0.75, max_px=1, how=\"add\") \n",
    "        \n",
    "        self.plot_shaded=self.plot_shaded.clone(shaded)\n",
    "        self.plot_spreaded=self.plot_spreaded.clone(spreaded)\n",
    "\n",
    "        if self.localidades=='Todas':\n",
    "            #mas_info=hv.Empty()\n",
    "            print(\"min n clientes radio: \", self.set_datos['n_clientes_a_radio'].min() )\n",
    "            valores_sel=self.set_datos['n_clientes_a_radio']\n",
    "            data_uno=self.datos.select(n_clientes_a_radio=10000 )\n",
    "            print(\"registros en data_uno: \", len(data_uno))\n",
    "            mas_info=hv.Points(data_uno, kdims=['lng_mercator', 'lat_mercator'] \n",
    "             , vdims=['PCMNFC', 'PCMNPR', 'dircompleta', 'PCMLNP' ,'n_clientes_a_radio','total_primas', 'cluster'\n",
    "                     ,'PCMIUN','PCMECD','PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD', 'PROB_BAJAS'])\n",
    "\n",
    "        else:\n",
    "            mas_info=hv.Points(self.datos, kdims=['lng_mercator', 'lat_mercator'] \n",
    "             , vdims=['PCMNFC', 'PCMNPR', 'dircompleta', 'PCMLNP' ,'n_clientes_a_radio', 'total_primas', 'cluster'\n",
    "                     ,'PCMIUN','PCMECD','PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD', 'PROB_BAJAS'])\\\n",
    "                .opts(tools=[\"hover\"])\n",
    "\n",
    "#             capa_Quadmesh=(hv.util.Dynamic(hd.aggregate(spreaded, streams=[self.box]), operation=hv.QuadMesh ))\\\n",
    "#                                         .opts(tools=[\"hover\",\"save\", \"undo\", \"redo\"]\n",
    "#                                                , alpha=0  , hover_alpha=0.2, hover_color=\"white\"\n",
    "#                                                , show_legend=False )\n",
    "        self.spreaded_forselect=self.spreaded_forselect.select(lng_mercator=(x_range_min, x_range_max) \n",
    "                                          , lat_mercator=(y_range_min, y_range_max)  )\n",
    "\n",
    "        final=(dataplot.opts(tools=[ \"box_select\", \"lasso_select\", \"redo\", \"undo\", \"save\" ], axiswise=True )  * hv.DynamicMap(self.tiles) \\\n",
    "            * hv.DynamicMap(self.labels) * self.spreaded_forselect )\n",
    "\n",
    "            #\\\n",
    "                #* capa_Quadmesh\n",
    "                \n",
    "        \n",
    "\n",
    "        final=self.spreaded_forselect \\\n",
    "        * dynspread( datashade(hv.DynamicMap(self.SeleccionaDatos, streams=[RangeXY(transient=True)]) \n",
    "                                   , normalization='eq_hist'\n",
    "                                , cmap=self.param['colormap'] \n",
    "                                   , width=conf_width , height=conf_height\n",
    "                                    ,x_range=(x_range_min, x_range_max) , y_range=(y_range_min, y_range_max) \n",
    "                                   ,x_sampling=5, y_sampling=5\n",
    "                                   \n",
    "                                  ) , threshold=0.75, max_px=self.param.spreading, how=\"add\")\\\n",
    "                            .opts(tools=[ \"redo\", \"undo\", \"save\" ], axiswise=True )  \\\n",
    "         * hv.DynamicMap(self.labels)\n",
    "       \n",
    "        return final * hv.DynamicMap(self.tiles )\n",
    "    \n",
    "        return  (( final * hv.DynamicMap(self.tiles )) \\\n",
    "                 +  hv.DynamicMap(self.selected_info, streams=[self.sel_fortabla]).options(\n",
    "        height=400,\n",
    "        width=800,\n",
    "        toolbar = None \n",
    "            )).opts(merge_tools=False).cols(2)\n",
    "    \n",
    "        \n",
    "        return  (( final * hv.DynamicMap(self.tiles )) \\\n",
    "                 +  hv.DynamicMap(self.selected_info, streams=[self.sel_fortabla]).options(\n",
    "        height=600,\n",
    "        width=800,\n",
    "        toolbar = None \n",
    "            ) +  (  hv.DynamicMap(self.selected_info_box, streams=[self.sel_fortabla]).options(\n",
    "        height=200,\n",
    "        #max_width=800,\n",
    "        toolbar = None \n",
    "    ) + hv.DynamicMap(self.selected_info_scatter, streams=[self.sel_fortabla]).options(\n",
    "        height=200,\n",
    "        width=500,\n",
    "        toolbar = None \n",
    "    ) )).opts(merge_tools=False).cols(2)\n",
    "#             #rtlink = RangeToolLink(source, target)\n",
    "        #tabla=hv.Table(self.tabla)\n",
    "#             #rtlink = DataLink( dataplot, tabla)\n",
    "#             rtlink =DataLink( dataplot, tabla)\n",
    "\n",
    "        #lo proximo es embed un div (con algun boton de js para exportar datos a excel)\n",
    "        #ver: http://holoviews.org/reference/elements/bokeh/Div.html\n",
    "        #return  pts.opts(tools=[\"box_select\"]) \n",
    "\n",
    "        #obj_puntos=hv.renderer('bokeh').get_plot(final)\n",
    "        #self.seleccion=hv.streams.Selection1D(source=obj_puntos)\n",
    "        print(\"final : \" , type(final ) )\n",
    "        \n",
    "        return ( final.options( axiswise=True,\n",
    "        tools=[ \"box_select\", \"lasso_select\", \"redo\", \"undo\" ],\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        toolbar='above',\n",
    "\n",
    "        #height=600,\n",
    "        #width=600\n",
    "    ) + hv.DynamicMap(self.selected_info, streams=[self.sel_fortabla]).options(\n",
    "        height=600,\n",
    "        width=800,\n",
    "        toolbar = None \n",
    "    )  + hv.DynamicMap(self.selected_info_box, streams=[self.sel_fortabla]).options(\n",
    "        height=200,\n",
    "        max_width=800,\n",
    "        toolbar = None \n",
    "    ) + hv.DynamicMap(self.selected_info_scatter, streams=[self.sel_fortabla]).options(\n",
    "        height=200,\n",
    "        width=800,\n",
    "        toolbar = None \n",
    "    )).opts(merge_tools=False).cols(2)\n",
    "\n",
    "    \n",
    "    \n",
    "        return ( final.options( axiswise=True,\n",
    "        tools=[ \"box_select\", \"lasso_select\", \"redo\", \"undo\" ],\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        toolbar='above',\n",
    "\n",
    "        #height=600,\n",
    "        #width=600\n",
    "    ) + hv.DynamicMap(self.selected_info, streams=[self.sel_fortabla]).options(\n",
    "        height=600,\n",
    "        width=800,\n",
    "        toolbar = None \n",
    "    )).opts(merge_tools=False).cols(2)\n",
    "\n",
    "\n",
    "\n",
    "        return ( final.options(\n",
    "        tools=[ \"box_select\", \"lasso_select\", \"redo\", \"undo\" ],\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        toolbar='above',\n",
    "\n",
    "        #height=600,\n",
    "        #width=600\n",
    "    ) + hv.DynamicMap(self.selected_info, streams=[ hv.streams.Selection1D(source=final)]).options(\n",
    "        height=600,\n",
    "        width=800,\n",
    "        toolbar = None \n",
    "    )).opts(merge_tools=False)\n",
    "\n",
    "        #return (dataplot * hv.DynamicMap(self.tiles) ) * hv.DynamicMap(self.labels) #\\\n",
    "                   ##* capa_Quadmesh\n",
    "           \n",
    "    \n",
    "\n",
    "#explorador=ExploraCMedico(name=\"Situación c.medico Privado y Muface\")\n",
    "explorador=ExploraCMedico(name=\"\")\n",
    "\n",
    "# Filtros=pn.Param(explorador.param, widgets={\n",
    "#     'red': pn.widgets.MultiSelect(value=list([\"Todas\"]), options= list(lst_red))\n",
    "#     #,'select_number': pn.widgets.DiscretePlayer\n",
    "#     }, expand_button=False\n",
    "# )\n",
    "#explorador.param._BATCH_PARAM=False\n",
    "#explorador.param.batch_param=True\n",
    "explorador.transient=False #creo que es más rápido no se detiene tanto en diferenciar los eventos.\n",
    "\n",
    "\n",
    "#el truco para que solo coja los cambios del DynamicMap y de self.param... cuando los objetos\n",
    "#cambien, es llamar a la funcion con los parentesis, es decir explorador.prepara_grafico() y no\n",
    "\n",
    "#print(explorador.name, explorador.transient)\n",
    "\n",
    "# dashboard=pn.Row(pn.Param(explorador.param, expand_button=False), explorador.prepara_grafico() )\n",
    "title       = '<div style=\"font-size:28px\" title=\"Seleccione con los selectores o directamente sobre el mapa.<br> \\\n",
    "              El sistema le indicará los clientes que tiene a un rango de 1.500m y la facturación de los  \\\n",
    "              proveedores seleccionados\">Exploración Cuadro Médico Zaragoza</div>'\n",
    "# instruction = 'Seleccione con los selectores o directamente sobre el mapa.<br>' + \\\n",
    "#               'Puede descargar los datos aqui: <a href=Exploracion_proveedores.xlsx download=\"Exploracion_proveedores.xlsx\">Download file</a>'\n",
    "# instruction = 'Seleccione con los selectores o directamente sobre el mapa.<br>' + \\\n",
    "#               'El sistema le indicará los clientes que tiene a un rango de 1.500m y la facturación de los proveedores seleccionados'\n",
    "instruction=''\n",
    "oggm_logo   = '<img src=\"http://172.16.241.232/ibi_apps/approot/galeno/img/img_hospital.png\" width=110 height=55></img>'\n",
    "btnexport = pn.widgets.Button(name='Exporta tabla a excel', width=200)\n",
    "btnexport.param.watch(explorador.exportar_tbl_a_excel , parameter_names='clicks')\n",
    "\n",
    "#todavia en desarrollo, desactivo\n",
    "btnexport.jscallback(clicks='alert(\"Datos exportados...\")')\n",
    "#aqui jslink con argumentos:\n",
    "#a.jscallback(clicks='alert(slider1.value+slider2.value)', args={'slider1': slider1, 'slider2': slider2})\n",
    "#datatable=explorador.selected_info_dyn() \n",
    "#datatable.jscallback(load='alert(\"tabla cargada\")')#DynamicMap' object has no attribute 'jscallback'\n",
    "\n",
    "#bCalculo.link=explorador.Calcular\n",
    "#bCalculo.param.watch(explorador.set_toogle_aat() , parameter_names='value' )\n",
    "def callback_calaat(target, event):\n",
    "    print(\"cambio valor: \", event.new)\n",
    "    target.default=event.new #bCalculo.options\n",
    "     #event.new.upper() + '!!!'\n",
    "    #no puede enlazar los valores correctamente pero puedo lanzar el trigger asi la funcion reconoce el cambio\n",
    "    #y se puede ejecutar selected_info_aat cuando cambio el valor del radiobutton.\n",
    "    explorador.param.trigger('Calcula_aat')\n",
    "    \n",
    "\n",
    "bCalculo.link(explorador.param.Calcula_aat, callbacks={'value':callback_calaat })\n",
    "\n",
    "\n",
    "\n",
    "#no muestro bCalculo lo sustituyo por un espaciador\n",
    "bCalculo=pn.layout.Spacer(width=10)\n",
    "header = pn.Row( pn.layout.Spacer(width=55), pn.Pane(oggm_logo),  pn.layout.Spacer(width=130), \n",
    "                pn.Column( pn.Row( pn.Pane(title, width=550) ), pn.Row(pn.Pane(instruction,height=0, width=550) ) )\n",
    "                , pn.Column(pn.Row( bCalculo  , pn.Pane(explorador.selected_info_aat_dyn(), width=500)))\n",
    "                , pn.Column(pn.Row(pn.layout.Spacer(height=30)) , pn.Row(pn.layout.Spacer(width=250), btnexport) ))\n",
    "dashboard=pn.Column(header, pn.Row( pn.Param(explorador.param, expand_button=False , css_classes=['widget-box', 'bk-root'])\n",
    "                           ,pn.Column( explorador.prepara_grafico()) \n",
    "                           ,pn.Column( explorador.selected_info_dyn()  \n",
    "                           ,pn.Row(explorador.selected_info_box_dyn() \n",
    "                           ,pn.layout.Spacer(width=80) , explorador.selected_info_scatter_dyn()\n",
    "                                   , css_classes=['greenTable']  ) )\n",
    "                            ) \n",
    "                   )\n",
    "\n",
    "\n",
    "dashboard.margin=0\n",
    "dash_cli=pn.Column(oggm_logo ,pn.Row( explorador.param , pn.Column( explorador.selected_info_activ_dyn()\n",
    "                                                                   , width=1000 ))) \n",
    "                  \n",
    "\n",
    "                                     \n",
    "#tabs=pn.Tabs(('Cuadro Médico', dashboard), tabs_location='left')\n",
    "tabs=pn.Tabs(('Cuadro Médico', dashboard), (\"Asegurados\", dash_cli))\n",
    "\n",
    "#me valgo de este watch para cambiar los objects en los parametros de filtros, de acuerdo a las\n",
    "#opciones disponibles que van quedando según las selecciones del usuario.\n",
    "explorador.param.watch(fn=explorador.update_params \\\n",
    "                       , parameter_names=['agrup_servicios', 'localidades', 'facturadores' \\\n",
    "                                          , 'clusters','natups', 'red', 'especialidad'] \\\n",
    "                      , what='value', onlychanged=True)\n",
    "#***********************************************************************************************\n",
    "#para utilizar la variable Filtros y asi permitir la selección múltiple tengo que cambiar\n",
    "#el código para que acepte valores como lista y aplicar las selecciones con un \"OR\", o bien\n",
    "#con el select del Dataset pero cambiando antes a todos los valores, sino la selección no\n",
    "#podrá seleccion una cosa y la otra\n",
    "#***********************************************************************************************\n",
    "#dashboard=pn.Row(Filtros, explorador.prepara_grafico() )\n",
    "#***********************************************************************************************\n",
    "#explorador.event()\n",
    "\n",
    "#la unica forma que he encontrado para recuperar los streams en llamando explorador.evento() post\n",
    "#generacion de la variable dashboar con la llamada a prepara_grafico, si llamo a evento\n",
    "#desde la generacion de la variable dashboard no pinta mas que los parametros el plot no.\n",
    "#dashboard.show(websocket_origin='*')    #con esto conseguimos que pueda compartirse desde mi ip, sustituyendo\n",
    "#dashboard\n",
    "tabs.show(websocket_origin='*')\n",
    "\n",
    "#se puede usar , 'stretch_width' para configurar el redimensionamiento en cada column / Row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos_tipfac3=datos_tipfac.pivot_table(values='TOTAL', index='PPSIUN', columns='setagrup', \n",
    "#                          aggfunc=lambda x: len(x.dropna().unique())   )\n",
    "datos_tipfac.head(3)\n",
    "np.random.seed(0)\n",
    "df = pd.DataFrame({'state': ['CA', 'WA', 'CO', 'AZ'] * 3,\n",
    "                   'office_id': list(range(1, 7)) * 2,\n",
    "                   'sales': [np.random.randint(100000, 999999)\n",
    "                             for _ in range(12)]})\n",
    "state_office = df.groupby(['state', 'office_id']).agg({'sales': 'sum'})\n",
    "# Change: groupby state_office and divide by sum\n",
    "# state_pcts = state_office.groupby(level=0).apply(lambda x:\n",
    "#                                                  100 * x / float(x.sum()))\n",
    "state_office.head(2)\n",
    "state_pcts = state_office.groupby(level=0).apply(lambda x:\n",
    "                                                  100 * x / float(x.sum()))\n",
    "state_pcts\n",
    "\n",
    "datos_tipfac_totxagrup = datos_tipfac.groupby(['PPSIUN', 'setagrup']).agg({'TOTAL': 'sum'})\n",
    "datos_tipfac_pct = datos_tipfac_totxagrup.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))\n",
    "datos_tipfac_pct.reset_index(inplace=True)\n",
    "datos_tipfac_pct.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[('x', 'x')]\n",
    "b,c=a[0]\n",
    "c\n",
    "explorador.puntos.data.compute().columns\n",
    "#explorador.puntos.data.compute().PCMRDS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(explorador.param.watch)\n",
    "explorador.param.watch(fn=explorador.SeleccionaDatos \\\n",
    "                       , parameter_names=['agrup_servicios', 'localidades', 'facturadores'] \\\n",
    "                      , what='value', onlychanged=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(dir(explorador.param))\n",
    "explorador.state_pop\n",
    "explorador.state_push\n",
    "\n",
    "#print(w1)\n",
    "# w1[\"objects\"][0][5] #param que ha cambiado.\n",
    "# w1[\"objects\"][1][5]\n",
    "# w1[\"precedence\"][1][5]\n",
    "\n",
    "\n",
    "# explorador.param.watch_values(explorador.SeleccionaDatos(), ['facturadores', 'agrup_servicios'])\n",
    "explorador.param.watch(explorador.SeleccionaDatos, ['facturadores', 'agrup_servicios'])\n",
    "dir(w1)\n",
    "w1.parameter_names\n",
    "w1.count('agrup_servicios')\n",
    "\n",
    "#print(explorador.param.agrup_servicios.__getstate__(), explorador.param.agrup_servicios.watchers)\n",
    "print(explorador.param.agrup_servicios.__getstate__() )\n",
    "explorador.param.agrup_servicios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pandas-docs.github.io/pandas-docs-travis/user_guide/groupby.html\n",
    "#help (explorador.param.set_param)\n",
    "explorador.param.localidades.objects=['Todas',\n",
    " 'Alagón                             ']\n",
    "dir(explorador.puntos._Dataset__params)\n",
    "#pn.param.Pane(explorador.puntos._Dataset__params.values() )\n",
    "#print(dir(explorador.puntos))\n",
    "print(explorador.puntos.get_param_values() ) #info del contendedor\n",
    "dimloc=explorador.puntos.get_dimension('PCMLNP')\n",
    "print(dir(dimloc) )\n",
    "dimloc.__sizeof__()\n",
    "trauma=explorador.puntos.select(PCMECD=40000)\n",
    "len(trauma)\n",
    "len(explorador.puntos)\n",
    "trauma.data.compute().PCMLNP.unique()\n",
    "\n",
    "_natups=explorador.puntos.data.compute().loc[~pd.isnull(explorador.puntos.data.compute().PCMNAT)].PCMNAT.unique()\n",
    "_natups\n",
    "\n",
    "_clusters=explorador.puntos.data.compute().loc[(~pd.isnull(explorador.puntos.data.compute().cluster) ) ].cluster.unique()\n",
    "all_clusters=lst_clusters\n",
    "all_clusters\n",
    "#f_clusters_new=dict([ k, v in all_clusters  if  ( _clusters in all_clusters.values ) ] )\n",
    "\n",
    "f_clusters_new = dict([ (k,v) for k,v in all_clusters.items() if v in _clusters])\n",
    "f_clusters_new[\"Todos\"]=999\n",
    "f_clusters_new.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ (k,v) for k,v in all_clusters.items() if v for v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "busprof_factu=use_data_plot.copy()\n",
    "print(busprof_factu.columns)\n",
    "busprof_factu['ProfEsFactu']=busprof_factu.apply(lambda row: 1 if  row['PCMNFF'] in row['PCMNFP'] else 0 , axis=1)\n",
    "busprof_factu[['PCMNFF', 'PCMNFP', 'PCMNFC', 'PCMNPR','ProfEsFactu']].head(10)\n",
    "\n",
    "help(hv.DynamicMap.event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(hv.Dataset)\n",
    "hvset=hv.Dataset(busprof_factu[['PCMNFF', 'PCMNFP', 'PCMNFC', 'PCMNPR','ProfEsFactu']])\n",
    "valores_dim=hvset.dframe().apply(lambda row: 1 if  row['PCMNFF'] in row['PCMNFP'] else 0 , axis=1)\n",
    "print(hvset)\n",
    "help(hvset.add_dimension)\n",
    "hvset=hvset.add_dimension('xxx', 5, valores_dim)\n",
    "hvset.dframe()\n",
    "len(hvset.dimensions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info_clientes.columns)\n",
    "#clientes_for_scan=info_clientes[['CODPER', ]]\n",
    "print(use_data_plot.columns)\n",
    "use_data_plot[['PCMNFF','PCMNFC', 'FACTURACION_MENSUAL', 'AAT']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pn.extension()\n",
    "a = pn.widgets.Button(name='Add')\n",
    "slider1 = pn.widgets.IntSlider()\n",
    "slider2 = pn.widgets.IntSlider()\n",
    "p=hv.Points([0,1])\n",
    "def call_click():\n",
    "    print(\"pasa x call_click\")\n",
    "    return hv.Div(\"\"\"\n",
    "        <script> alert(\"callback funciona correctamente\"); </scipt>\n",
    "        <div> </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    \n",
    "#esto esta en nuevas versiones, ver si puedo actualizarlo, pero puede ser que esta nueva version sea\n",
    "#incompatible con pandas o pyspark, veremos...\n",
    "a.jscallback(clicks='alert(slider1.value+slider2.value)', args={'slider1': slider1, 'slider2': slider2})\n",
    "#pn.jscallback(clicks='alert(slider1.value+slider2.value)', args={'slider1': slider1, 'slider2': slider2})\n",
    "#a.on_click=call_click()\n",
    "print(type(a))\n",
    "das=pn.Row(a, slider1, slider2, p)\n",
    "#help(a.on_click)\n",
    "das"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension()\n",
    "cd_code =\"\"\"\n",
    "if (!target.remaining_time){\n",
    "    target.margin = [5, 10]\n",
    "    target.width = 200\n",
    "    target.remaining_time = 1000*10 //10s\n",
    "    target.text = ((target.remaining_time)/1000.).toString() + ' s remaining'\n",
    "var x = setInterval(() => {   \n",
    "    if(target.remaining_time > 1000) {\n",
    "        target.remaining_time = target.remaining_time - 1000\n",
    "        target.text = ((target.remaining_time)/1000.).toString() + ' s remaining'\n",
    "    } else {\n",
    "        target.text = ''\n",
    "        target.margin = [0, 0, 0, 0]\n",
    "        target.width = 0\n",
    "        target.remaining_time = 0\n",
    "        clearInterval(x)\n",
    "    }\n",
    "  \n",
    "}, 1000);\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "b = pn.widgets.Button(name='Click me')\n",
    "t = pn.widgets.StaticText(value='', width=0, width_policy='fixed', margin=0)\n",
    "b.jslink(t,code={'clicks':cd_code})\n",
    "pn.Row(b, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dir(urllib.request.URLopener.open_local_file(\"clusters_cm_Zaragoza.xlsx\")))\n",
    "#help(urllib.request.URLopener.open_local_file)\n",
    "#archivo: // host / ruta\n",
    "ruta=urllib.parse.urlencode('C:\\\\Users\\\\javierb\\\\Desktop\\\\PYTHON\\\\Aprendizaje Supervisado\\\\clusters_cm_Zaragoza.xlsx')\n",
    "#urllib.request.URLopener.open_local_file(ruta)\n",
    "ruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(explorador))\n",
    "explorador.message(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = { 'Year': [2019,2019,2019,2018,2018],\n",
    "        'Week': [1,2,3,1,2],\n",
    "        'Part': ['A','A','A','B','B'],\n",
    "        'Static': [20,20,20,40,40],\n",
    "        'Value': [np.nan,10,50,30,np.nan]\n",
    "   }\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "#df.Value = df.groupby('Part')[['Static', 'Value']].ffill().ffill(axis=1).Value\n",
    "df=df.set_index(['Year','Week', 'Part', 'Static']).unstack([0,1]).reset_index().fillna(method='ffill', axis=1)\n",
    "#df=df.set_index(['Year','Week', 'Part', 'Static']).unstack([0,1]).reset_index().fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_naat=  {'AAT_TDKV': [{'AÑO': ' 2018', 'TAAT': '  10244.00', 'TAATVSRADIO': '        7.41'}\n",
    "                          , {'AÑO': ' 2019', 'TAAT': '   9763.00', 'TAATVSRADIO': '        7.07'}]}\n",
    "print(\"n keys: \" , len(json_naat[\"AAT_TDKV\"] ) )\n",
    "tbl= pd.DataFrame(json_naat[\"AAT_TDKV\"], index=np.asarray(range( len(json_naat[\"AAT_TDKV\"]  )   )))\n",
    "#tbl=tbl.set_index([\"AÑO\"]).reset_index().fillna(method='ffill', axis=1)\n",
    "tbl.head()\n",
    "\n",
    "#aggfunc = { \"Cantidad\" : len , \"Precio\" : np . sum }, fill_value = 0 \n",
    "tbl['TAAT']=tbl['TAAT'].astype('float32')\n",
    "tbl['TAATVSRADIO']=tbl['TAATVSRADIO'].astype('float32')\n",
    "\n",
    "tbl=tbl.pivot_table(values=['TAAT','TAATVSRADIO'] , index=['AÑO'] \n",
    "                   ,aggfunc= { \"TAAT\" : np.sum , \"TAATVSRADIO\" : np.mean }, fill_value=0  )\n",
    "# tbl_json=tbl.to_json()\n",
    "# print(tbl.columns)\n",
    "# print(tbl_json)\n",
    "# tbl2= pd.DataFrame(json_naat[\"AAT_TDKV\"], index=np.asarray(range( len(json_naat.keys()  )+1   )))\n",
    "# tbl2.head()\n",
    "#tbl.reset_index()\n",
    "tbl.head()\n",
    "print(tbl.columns)\n",
    "#tbl.reset_index(inplace=True)\n",
    "tbl=tbl.rename_axis(None)\n",
    "tbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(-5, 5, 0.25)\n",
    "Y = np.arange(-5, 5, 0.25)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "R = np.sqrt(X**2 + Y**2)\n",
    "Z = np.sin(R)\n",
    "img = hv.Image(Z)\n",
    "\n",
    "# Render matplotlib surface plot to HTML\n",
    "surface = hv.Surface(img)\n",
    "# surface_html = hv.renderer('matplotlib').html(surface)\n",
    "# surface_div = hv.Div(surface_html)\n",
    "\n",
    "# Generate HTML summary table from pandas dataframe\n",
    "df_html = img.dframe()[['z']].describe().to_html()\n",
    "df_div = hv.Div(\"<div align='right'>\"+df_html+\"<div>\")\n",
    "\n",
    "img  + df_div.opts(width=200)\n",
    "\n",
    "tbl_jsn={\"AAT 2018\" :1000 \\\n",
    "                        ,\"AAT 2019\" : 670 \\\n",
    "                        , \"N. proveedores\": 149\n",
    "                        }\n",
    "tbl=pd.DataFrame(tbl_jsn, index=[0])\n",
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(dir(dashboard))\n",
    "#dashboard.objects\n",
    "dashboard.background='black'\n",
    "dashboard.margin=0\n",
    "dir (dashboard.css_classes)\n",
    "#help(dashboard.aspect_ratio)\n",
    "app=dashboard.get_root()\n",
    "dir(app)\n",
    "tbl_jsn={\"AAT 2018\" : 34000 \\\n",
    "                        ,\"AAT 2019\" : 32000\\\n",
    "                        , \"N. proveedores\": 2000\n",
    "                        }\n",
    "tbl=pd.DataFrame(tbl_jsn, index=[0])\n",
    "tbl=tbl.to_html()\n",
    "hv.Div(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_naat= { \"AAT_TDKV\" : [\n",
    "#{\"AÑO\": \" 2018\",\"TAAT\":\"      5.00\"}  ,        \n",
    "    {\"AÑO\": \" 2019\",\"TAAT\":\"      50.00\"}          \n",
    "]}\n",
    "df=pd.DataFrame(json_naat[\"AAT_TDKV\"], index=[0])\n",
    "df.head()\n",
    "tbl=hv.Table(df)\n",
    "p=pn.pane.HTML(tbl.dframe())\n",
    "dir(p.object)\n",
    "print(p.object.to_html())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash_panel = dashboard.get_root()\n",
    "dash_panel=dash_panel.layout(side='left', plot=dashboard)\n",
    "\n",
    "# Define the dashboard\n",
    "template = \"\"\"\n",
    "{% extends base %}\n",
    "\n",
    "{% block preamble %}\n",
    "<style>\n",
    "div#dashboard {\n",
    "    width: 80%;\n",
    "    margin: 0 auto;\n",
    "}\n",
    "</style>\n",
    "{% endblock preamble %}\n",
    "\n",
    "{% block contents %}\n",
    "<div id=\"dashboard\">\n",
    "  <h1>My dashboard</h1>\n",
    "  {{ embed(roots.dash1) }}\n",
    "</div>\n",
    "{% endblock contents %}\n",
    "\"\"\"\n",
    "tmpl = pn.Template(template)\n",
    "tmpl.add_panel('dash1', dash_panel)\n",
    "tmpl.servable(title=\"My page title\")\n",
    "\n",
    "# Uncomment to preview dashboard in jupyter notebook\n",
    "#dash_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_naat=dict(   { \"AAT_TDKV\" : [\n",
    "{\"AÑO\": \" 2018\",\"TAAT\": \" 0.00\" }   ,{\"AÑO\": \" 2019\",\"TAAT\":\" 0.00\"}\n",
    "]})\n",
    "json_naat\n",
    "json_naat[\"AAT_TDKV\"][1][\"TAAT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pn.pane.Markdown(\"\")\n",
    "t = pn.widgets.TextInput()\n",
    "st=param.String(default=\"Hey\")\n",
    "ls=param.Selector(default=1, objects=[1,2,3])\n",
    "bCal=pn.widgets.RadioButtonGroup(value=\"No\", options=[\"Sí\", \"No\"], name=\"Calcular AAT\", width=150)\n",
    "\n",
    "def callback(target, event):\n",
    "    print(dir(target))\n",
    "    print(event)\n",
    "    #print(target.value)\n",
    "    target.objects =event.new #event.new.upper() + '!!!'\n",
    "\n",
    "#bCal.link(explorador.param.Calcular , callbacks={'value': callback})\n",
    "bCal.link(ls , callbacks={'value': callback})\n",
    "# t.link(m, callbacks={'value': callback})\n",
    "# t.value=\"Some text\"\n",
    "explorador.param.Calcular.precedence=0\n",
    "pn.Row(st, ls,  explorador.param.Calcular, bCal)\n",
    "#dir(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(explorador.param.Calcular)\n",
    "explorador.bCalculate_aat=True\n",
    "explorador.bCalculate_aat\n",
    "#explorador.param.trigger('Calcular')\n",
    "pn.Row(explorador.param.cls)\n",
    "pn.Row(explorador.ctl_calcular)\n",
    "explorador.ctl_calcular.value=True\n",
    "#pn.panel(self.param, parameters=['button'])\n",
    "explorador.param.trigger('Calcular')\n",
    "pn.Row(explorador.ctl_calcular)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# json_aat=  { \"AAT_TDKV\" : [\n",
    "# {\"AÑO\": \" 2018\",\"TAAT\":\"  37307.00\"}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
    "# ,{\"AÑO\": \" 2019\",\"TAAT\":\"  36348.00\"}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
    "# ]}\n",
    "type(json_aat)\n",
    "json_aat=dict({ \"AAT_TDKV\" : [{\"AÑO\": \" 2018\",\"TAAT\":\" \"}   ,{\"AÑO\": \" 2019\",\"TAAT\":\" \"}]})\n",
    "\n",
    "json_aat[\"AAT_TDKV\"][0][\"AÑO\"]\n",
    "json_aat[\"AAT_TDKV\"][1][\"AÑO\"]\n",
    "json_aat[\"AAT_TDKV\"][0][\"TAAT\"]\n",
    "int(json_aat[\"AAT_TDKV\"][1][\"TAAT\"].replace(\".00\", \"\"))\n",
    "\n",
    "hv.Div(\"AAT 2018: \" + str(int(json_aat[\"AAT_TDKV\"][0][\"TAAT\"].replace(\".00\", \"\"))) + \"</br>\"\\\n",
    "      \"AAT 2019: \" + str( int(json_aat[\"AAT_TDKV\"][1][\"TAAT\"].replace(\".00\", \"\"))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_bool():\n",
    "    bCalculate_aat=param.Boolean(False, doc=\"Calcular aat?\")\n",
    "    return bCalculate_aat\n",
    "\n",
    "obj=explorador.set_toogle_aat() \n",
    "print(dir(obj))\n",
    "\n",
    "#print(dir(pn.Row(obj)))\n",
    "pn.Row(obj).params\n",
    "type(obj)\n",
    "\n",
    "\n",
    "obj2=ret_bool()\n",
    "type(obj2)\n",
    "dir(obj2)\n",
    "obj2.default\n",
    "#https://github.com/pyviz/panel/issues/240\n",
    "#pn.panel(explorador.param, parameters=[set_toogle_aat()] )\n",
    "#print(dir(explorador.param))\n",
    "print(dir(explorador.param.cls.bCalculate_aat))\n",
    "pn.Row(pn.widgets.Toggle(value=False, height=30, width=80, name=\"Calcular AAT: (Si/No)\"))\n",
    "#help(pn.widgets.Toggle)\n",
    "#help(pn.widgets.CheckButtonGroup)\n",
    "\n",
    "def on_cambio_Calculate(ctl):\n",
    "    print(ctl.value, explorador.bCalculate_aat)\n",
    "    \n",
    "#print(help(pn.widgets.CheckButtonGroup))\n",
    "bCalculo=pn.widgets.RadioButtonGroup(value=\"No\", options=[\"Sí\", \"No\"], name=\"Calcular AAT\")\n",
    "#bCalculo.labels=[\"Calcular AAT ?\"]\n",
    "bCalculo.link=explorador.bCalculate_aat\n",
    "\n",
    "bCalculo.param.watch(on_cambio_Calculate(bCalculo), parameter_names='options' )\n",
    "#help(bCalculo.param.watch)\n",
    "pn.Row(bCalculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dic1={\"SUC\": 50 }\n",
    "base_url=  'http://172.16.241.232/ibi_apps/run.bip?'\n",
    "url_get=\"http://172.16.241.232/ibi_apps/run.bip?BIP_REQUEST_TYPE=BIP_RUN&BIP_folder=IBFS%253A%252FWFC%252FRepository%252FGaleno%252FInformes_Galeno%252FActividadMP&BIP_item=grafico_for_caso_uso_cmedico.fex\"\n",
    "\n",
    "#base_url=\"http://172.16.241.232/ibi_apps/run.bip?BIP_REQUEST_TYPE=BIP_RUN&BIP_folder=IBFS%253A%252FWFC%252FRepository%252FGaleno%252FInformes_Galeno%252FActividadMP&BIP_item=grafico_for_caso_uso_cmedico.fex\"\n",
    "\n",
    "# r=requests.post(base_url, auth=('javierb', 'AnitaSergio_092019jbs'))\n",
    "# print(r.status_code)\n",
    "usr='admin'\n",
    "pwd='AnitaSergio_092019jbs'\n",
    "payload = \"username=%s&password=%s\" % (usr,pwd)\n",
    "args={\"BIP_REQUEST_TYPE\": \"BIP_RUN\" ,\n",
    "\"BIP_folder\": \"/WFC/Repository/Galeno/Informes_Galeno/ActividadMP/\" ,\n",
    "\"BIP_item\": \"grafico_for_caso_uso_cmedico.fex\"\n",
    "}\n",
    "# args=[(\"BIP_REQUEST_TYPE\", \"BIP_RUN\" ),\n",
    "# (\"BIP_folder\", \"/WFC/Repository/Galeno/Informes_Galeno/ActividadMP\") ,\n",
    "# (\"BIP_item\", \"grafico_for_caso_uso_cmedico.fex\"),\n",
    "# (\"BIMR_action\",\"MR_SIGNON\"),\n",
    "# (\"IBIMR_user\", \"REDCENTRAL\\javierb\"),\n",
    "# (\"IBIMR_pass\", \"AnitaSergio_092019jbs\")\n",
    "#      ]\n",
    "filtros=[(\"SUC\", \"50\")]\n",
    "args=[(\"BIP_REQUEST_TYPE\", \"BIP_RUN\" ),\n",
    "(\"BIP_folder\", \"/WFC/Repository/Galeno/Informes_Galeno/ActividadMP\") ,\n",
    "(\"BIP_item\", \"src_get_aat.fex\"),\n",
    "(\"SUC\", 50)\n",
    "     ]\n",
    "headers = {'content-type': 'application/x-www-form-urlencoded'}\n",
    "#r = requests.post(api_url, data = {\"var 1\":\"value\", \"var 2\":\"value\"}, verify=True)\n",
    "s = requests.Session()\n",
    "# # response = s.post(base_url, params=args, data=dic1, timeout=15, verify=True)\n",
    "# response = s.post(base_url,params=args, data=data, timeout=15, verify=True)\n",
    "#plantilla uso:\n",
    "#r = requests.get('https://iis.contoso.com', auth=HttpNegotiateAuth())\n",
    "response=s.post(base_url, params=args,  timeout=15 , auth=HttpNegotiateAuth())\n",
    "#response=s.get(url_get, timeout=15)\n",
    "#response=urllib.request.urlopen(url_get, timeout=15)\n",
    "#response=s.get(\"http://www.google.es\", timeout=15)\n",
    "#response = requests.request(\"POST\", base_url, data=args, verify=True)\n",
    "#print(response.text)\n",
    "#data = response.json()\n",
    "response.status_code\n",
    "#print(dir(response) )\n",
    "#response.history\n",
    "print(response.url)\n",
    "#response.apparent_encoding\n",
    "# dir(response.request)\n",
    "# help(response.request.prepare_auth)\n",
    "#print(dir(response.raw) )\n",
    "#response.raw.read()\n",
    "#print(base_url)\n",
    "dir(response)\n",
    "\n",
    "hv.Div(\"\"\"\n",
    "            <h1>Datos de interés</h1>\n",
    "            <h3>Realice sus selecciones y visualize cuantos servicios existen en la zona\n",
    "            y cuantos clientes están a un radio de 1500m.</h3>\n",
    "            <marquee>\n",
    "            <h5>Si pulsa en el botón exportar a excel, obtendrá un documento con las selección de datos</h5>\n",
    "            </marquee>\"\"\"+response.text)\n",
    "            \n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S=\"Adiego Sancho, Antonio\"\n",
    "poscoma=S.find(\":\")\n",
    "ini=poscoma+2\n",
    "end=len(S)\n",
    "poscoma\n",
    "end\n",
    "nombre=S[ini: end]\n",
    "apellidos=S[0:poscoma]\n",
    "apellidos\n",
    "proveedor=nombre +', ' + apellidos\n",
    "proveedor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%opts Image {+framewise}\n",
    "# from holoviews import opts\n",
    "# from holoviews import streams\n",
    "from holoviews.streams import  Buffer\n",
    "from holoviews.operation.datashader import regrid\n",
    "from holoviews.plotting.links import RangeToolLink\n",
    "from holoviews.plotting.links import DataLink\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "conf_width=600\n",
    "conf_height=600\n",
    "#min_height=600, min_width=600, responsive=True\n",
    "opts1=dict( min_width=conf_width, min_height=conf_height, responsive=True,xaxis=None, yaxis=None,bgcolor=\"black\", sizing_mode='scale_width'\n",
    "          ,tools=['box_select', 'lasso_select'])\n",
    "opts1_t=dict(min_width=conf_width, min_height=conf_height,global_extent=False, responsive=True, xaxis=None, yaxis=None,bgcolor=\"black\")\n",
    "\n",
    "opts2=dict(x_sampling=0.00001, y_sampling=0.00001)\n",
    "gopts  = hv.opts.WMTS(xaxis=None, yaxis=None, bgcolor='black', show_grid=False, responsive=True,min_width=conf_width, min_height=conf_height)\n",
    "\n",
    "url = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{Z}/{Y}/{X}.jpg'\n",
    "map_tiles=gv.WMTS(url, crs=crs.GOOGLE_MERCATOR)\n",
    "datos=use_data_plot.copy()\n",
    "\n",
    "#PCMDLC, cambiada x PCMLNP es más correcta la descripción. Tengo que cambiar en todo el codigo pq hay seleccion\n",
    "#dentro de la clase\n",
    "lst_muni=datos['PCMLNP'].unique()\n",
    "lst_muni=list(lst_muni)\n",
    "lst_muni.sort()\n",
    "lst_muni.insert(0,'Todas')\n",
    "\n",
    "cmaps  = dict([(n, cm_n[n]) for n in cm_n.keys() ])\n",
    "\n",
    "#**********************************************************************************************************\n",
    "#                                           NOTAS TECNICAS:\n",
    "#**********************************************************************************************************\n",
    "#Hay varias formas de notificar los cambios en el panel, aquí vamos a utilizar la 2 y 3 ya que siendo las\n",
    "#más complejas, son las más útiles en cuanto a rendimiento:\n",
    "#1.- dependencias signifcadas con el decorador @pn.depends(...), siempre que cambie alguno de los\n",
    "#parametros significados asi, cambiará el proceso y se ejecutará todo de nuevo\n",
    "#2.-Dependencia de un método para DynamicMap: decoraremos igualmente con @pn.dependes(...), lo que cambia\n",
    "#aqui es que al utilizar DynamicMap, el metodo solo se re-ejecutara cuando cambie algun parametro que\n",
    "#este afectado en este DynamicMap\n",
    "#3.-Argumento instancia-objeto de parametro: proporcionaremos una instancia del objeto param en lugar del\n",
    "#valor asociado a ese parametro, así las dependencias se infieren solo cuando se pasa el objeto completo\n",
    "#y sólo cambiarán o se actualizará cuando el valor cambie.\n",
    "#(*): Los enfoques 2 y 3 se basan en una caracteristica de HoloViews llamada streaming, que admiten muchos\n",
    "#tipos de comportamiento dinámico, además de responder a widgets. Por ejemplo la rasterize operación \n",
    "#adjunta una RangeXY streaming que vuelve a agregar los datos cada vez que cambia la ventana gráfica, lo \n",
    "#mismo ocurre en nuesro ejemplo en la operación de datashade.\n",
    "#**********************************************************************************************************\n",
    "\n",
    "ds_orig=use_data_plot.copy()\n",
    "ds_orig['lng_mercator']=0.0\n",
    "ds_orig['lat_mercator']=0.0\n",
    "ds_orig.loc[:, 'lng_mercator'], ds_orig.loc[:, 'lat_mercator'] = ds.utils.lnglat_to_meters(ds_orig['lng'],ds_orig['lat'])\n",
    "dask_df = dd.from_pandas(ds_orig, npartitions=mp.cpu_count())\n",
    "#dask_df=gdf_cmedico_spk\n",
    "min_cli_radio=0\n",
    "max_cli_radio=dask_df['n_clientes_a_radio'].max().compute()\n",
    "\n",
    "class ExploraCMedico(param.Parameterized):\n",
    "#class ExploraCMedico(hv.streams.Stream):\n",
    "\n",
    "    \n",
    "    alpha=param.Magnitude(default=0.5, doc=\"Opacidad mapa\")\n",
    "    #colormap=param.ObjectSelector(default=\"fire\", objects=list(cm_n.keys()))\n",
    "    colormap=param.Selector(cmaps)\n",
    "    localidades=param.ObjectSelector(default=\"Todas\", objects=lst_muni )\n",
    "    set_datos=use_data_plot.copy()\n",
    "    spreading     = param.Integer(3, bounds=(0, 5))\n",
    "    muestra_nombres   = param.Boolean(True)\n",
    "    \n",
    "    sel_rgo_cli=param.Range(default=(0, max_cli_radio), bounds=(0, max_cli_radio))\n",
    "\n",
    "    #lst_agrup_servicio\n",
    "    #lst_red\n",
    "    #lst_natups\n",
    "    #lst_factu\n",
    "    facturadores=param.ObjectSelector(default=\"Todos\", objects=lst_factu )\n",
    "    agrup_servicios= param.ObjectSelector(default=\"Todos\", objects=lst_agrup_servicio )   \n",
    "    natups= param.ObjectSelector(default=\"Todas\", objects=lst_natups )    \n",
    "    red= param.ObjectSelector(default=\"Todas\", objects=lst_red )   \n",
    "    btn_exportar_toxls = param.Action(lambda x: x.param.trigger('btn_exportar_toxls'), label='Exporta datos a excel')\n",
    "    Nota_export= param.Parameter(default=\" \", constant=True)\n",
    "    \n",
    "    ds_pd=ds_orig.copy()\n",
    "    dask_df = dd.from_pandas(ds_pd, npartitions=mp.cpu_count())\n",
    "    se_datos=dask_df.copy()\n",
    "    \n",
    "    datos=hv.Dataset(dask_df[['lng_mercator', 'lat_mercator', 'Shape__Are','Texto', 'Cod_CCAA', 'dircompleta'\n",
    "                              , 'PCMLNP', 'PCMNFC', 'PCMNPR','n_clientes_a_radio','total_primas',\n",
    "                             'PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD', 'FACTURACION_MENSUAL']]\n",
    "                 , kdims=['lng_mercator', 'lat_mercator']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMLNP', 'PCMNFC', 'PCMNPR' ,'n_clientes_a_radio' \n",
    "                         ,'PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD','total_primas','FACTURACION_MENSUAL'])\n",
    "    puntos=hv.Points(datos, kdims=['lng_mercator', 'lat_mercator']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMLNP', 'PCMNFC', 'PCMNPR' ,'n_clientes_a_radio'\n",
    "                         ,'PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD','total_primas', 'FACTURACION_MENSUAL'])\n",
    "    \n",
    "    puntos_base=hv.Points(datos, kdims=['lng_mercator', 'lat_mercator']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMLNP', 'PCMNFC', 'PCMNPR' ,'n_clientes_a_radio'\n",
    "                         ,'PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD','total_primas', 'FACTURACION_MENSUAL']).opts(alpha=0.1, axiswise=True)\n",
    "    base_forselect=datashade( puntos_base ,streams=[RangeXY(transient=True)]\n",
    "                               , cmap=cmaps['fire']\n",
    "                               , normalization='eq_hist' \n",
    "                               , x_sampling=0.00001, y_sampling=0.00001\n",
    "                         ).opts(alpha=0.1, axiswise=True)\n",
    "    spreaded_forselect   = dynspread(base_forselect, threshold=0.4\n",
    "                                         , max_px=1, how='over'\n",
    "                                        , streams=[RangeXY(transient=True)]).opts( alpha=0.1, axiswise=True)\n",
    "    #points=hv.Points(datos, ['Longitude', 'Latitude'])\n",
    "    #puntos=hv.Points(datos, ['Longitude', 'Latitude']).opts(framewise=True, axiswise=True)\n",
    "    #mapa_fondo=map_tiles.opts(gopts).opts(alpha=0.5, **opts1)\n",
    "    # selection that gives the current x_range/y_range of the map\n",
    "    box = hv.streams.RangeXY(transient=True)\n",
    "    ventana_actual={\"x_range_min\": None, \"x_range_max\": None, \"y_range_min\": None, \"y_range_max\": None}\n",
    "    \n",
    "    tabla=None\n",
    "    seleccion= hv.streams.Selection1D(source=puntos)\n",
    "    \n",
    "    plot_shaded     = datashade( puntos ,streams=[RangeXY(transient=True)]  , normalization='eq_hist' )\n",
    "    plot_spreaded   = dynspread(plot_shaded, threshold=0.9, how='over' )\n",
    "    \n",
    "    def __ini__(self):\n",
    "        print(\"estmao en ini\")\n",
    "        self.btn_export_xls = param.Action(self.exportar_tbl_a_excel, 'Exportar tabla datos')\n",
    "        print(\"en toria ha añadido boton\")\n",
    "        super(ExploraCMedico, self).__init__()\n",
    "\n",
    "       \n",
    "    def make_base(self):\n",
    "        puntos_base=hv.Points(self.datos, kdims=['lng_mercator', 'lat_mercator']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMLNP', 'PCMNFC', 'PCMNPR' ,'n_clientes_a_radio'\n",
    "                         ,'PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD','total_primas', 'FACTURACION_MENSUAL']).opts(alpha=0.1, framewise=True)\n",
    "        base_forselect=datashade( puntos_base ,streams=[RangeXY(transient=True)]\n",
    "                         , cmap=cmaps['fire']\n",
    "                         , normalization='eq_hist' \n",
    "                         , x_sampling=0.00001, y_sampling=0.00001\n",
    "                         ).opts(alpha=0.1, framewise=True)\n",
    "        spreaded_forselect   = dynspread(base_forselect, threshold=0.4\n",
    "                        , max_px=1, how='over'\n",
    "                        , streams=[RangeXY(transient=True)]).opts( alpha=0.1, framewise=True)\n",
    "        \n",
    "        return spreaded_forselect\n",
    "    \n",
    "    @param.depends('btn_exportar_toxls', watch=True)\n",
    "    def exportar_tbl_a_excel(self, **kwargs):\n",
    "        print(\"forma datos en tabla: \" , len(self.tabla.data) ,type(self.tabla.data ) , type (self.param.Nota_export))\n",
    "        print( dir (self.param.Nota_export))\n",
    "        \n",
    "        tmp_df=self.tabla.data.compute()\n",
    "        tmp_df.to_excel( 'Exploracion_proveedores.xlsx')\n",
    "        #pendiente codigo html para informar que ya se ha exportado\n",
    "        #pn.pane.HTML(iframe, height=400)\n",
    "        \n",
    "        show_html=hv.Div(\"\"\"\n",
    "                    <h3>Datos exportados a file Exploracion_proveedores.xlsx</h3>\n",
    "                    \"\"\")\n",
    "        \n",
    "        self.param.Nota_export.constant=False\n",
    "        self.Nota_export=\"Datos exportados a file Exploracion_proveedores.xlsx\"\n",
    "        self.param.Nota_export.constant=True\n",
    "        self.param.Nota_export.label=\"Nota export:\"\n",
    "        \n",
    "        return show_html\n",
    "        #return pn.pane.HTML( \"\"\"<html><script>alert('Datos exportados a file Exploracion_proveedores.xlsx');\n",
    "        #            </script>\n",
    "        #            </html>\"\"\", height=100)\n",
    "        \n",
    "    @param.depends ('sel_rgo_cli', watch=True)\n",
    "    def filtro_sel_rgo_cli(self):\n",
    "        self.datos=self.datos.select(n_clientes_a_radio=self.sel_rgo_cli )\n",
    "    \n",
    "   \n",
    "    \n",
    "    @param.depends('localidades' , 'sel_rgo_cli', 'facturadores', 'agrup_servicios'\n",
    "                   ,'natups', 'red', watch=True)\n",
    "    def SeleccionaDatos(self, x_range=None, y_range=None):\n",
    "        print(\"estamos en seleccionDatos\", self.params.args, x_range, y_range)\n",
    "        \n",
    "        #print(dir( self.param.localidades) )\n",
    "        #print(self.param.localidades.__getstate__(), self.param.localidades.watchers)\n",
    "             \n",
    "       \n",
    "\n",
    "        self.set_datos=self.ds_pd.copy()\n",
    "        \n",
    "        #si filtro los datos tngo problemas al utilizar datashade con el calculo de l density\n",
    "        #da error division x cero, por lo tanto no puedo filtrar solo seleccionar\n",
    "#         if self.localidades=='Todas':\n",
    "#             idx_filtros=[True  for m in  range (self.set_datos.shape[0])   ]\n",
    "#             self.set_datos = self.set_datos[idx_filtros]\n",
    "#         else:\n",
    "            \n",
    "#             idx_filtros=[m  for m in ( self.set_datos['PCMLNP'] == self.localidades) ]\n",
    "#             self.set_datos = self.set_datos[idx_filtros]\n",
    "            \n",
    "        self.set_datos= dd.from_pandas(self.set_datos, npartitions=mp.cpu_count())\n",
    "        print(self.set_datos['lng_mercator'].min().compute(),self.set_datos['lat_mercator'].min().compute() )\n",
    "                \n",
    "        datos=hv.Dataset(self.set_datos[['lng_mercator', 'lat_mercator', 'Shape__Are','Texto', 'Cod_CCAA', 'dircompleta'\n",
    "                                              , 'PCMLNP', 'PCMNFC', 'PCMNPR','n_clientes_a_radio','total_primas'\n",
    "                                        ,'PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD', 'FACTURACION_MENSUAL']]\n",
    "                 , kdims=['lng_mercator', 'lat_mercator']\n",
    "                 , vdims=['Texto', 'Shape__Are', 'Cod_CCAA', 'dircompleta', 'PCMLNP', 'PCMNFC', 'PCMNPR' ,'FACTURACION_MENSUAL'\n",
    "                          ,'n_clientes_a_radio','PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD','total_primas', ])\n",
    "        \n",
    "        datos=datos.select(n_clientes_a_radio=self.sel_rgo_cli)\n",
    "        if self.red != 'Todas':\n",
    "            print(\"opc red: \", self.red)\n",
    "            datos=datos.select(PCMRDS=self.red)\n",
    "        if self.facturadores != 'Todos':\n",
    "            print(\"facturadores: \", self.facturadores)\n",
    "            datos=datos.select(PCMNFC=self.facturadores)\n",
    "        if self.natups != 'Todas':\n",
    "            print(\"natups: \", self.natups)\n",
    "            datos=datos.select(PCMNAT=self.natups)\n",
    "        if self.agrup_servicios != 'Todos':\n",
    "            print(\"agrup servicios: \", self.agrup_servicios)\n",
    "            datos=datos.select(PCMEGD=self.agrup_servicios)\n",
    "        print(\"forma de gedf set_datos en selecciondatos: \", self.set_datos.shape)\n",
    "        print(\"forma de hv dataset datos en selecciondatos: \", len(datos.data))\n",
    "        \n",
    "        self.datos=datos\n",
    "        \n",
    "        self.puntos=hv.Points(datos, ['lng_mercator', 'lat_mercator']\n",
    "                     , ['Texto', 'Shape__Are', 'Cod_CCAA', 'dircompleta' , 'PCMLNP', 'PCMNFC', 'PCMNPR' ,'FACTURACION_MENSUAL'\n",
    "                        ,'n_clientes_a_radio','PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD','total_primas' ])\n",
    "                    \n",
    "        \n",
    "        if self.localidades != 'Todas':\n",
    "            sel_datos=self.ds_pd.loc[self.ds_pd['PCMLNP']==self.localidades].copy()\n",
    "        else:\n",
    "            sel_datos=self.ds_pd.copy()\n",
    "        \n",
    "        #**********************************************************************************************************\n",
    "        #   La seleccion de datos x localidad no la hago en el recordset, sino por la seleccion de coordenadas\n",
    "        #**********************************************************************************************************\n",
    "        x_range_min = sel_datos['lng_mercator'].quantile(0.01)\n",
    "        x_range_max = sel_datos['lng_mercator'].quantile(0.99)\n",
    "        y_range_min = sel_datos['lat_mercator'].quantile(0.01)\n",
    "        y_range_max = sel_datos['lat_mercator'].quantile(0.99)\n",
    "        \n",
    "        #shape_are se expresa en hectareas -.> 1 hectarea son 10.000 m cuadrados\n",
    "        if x_range_min == x_range_max:\n",
    "            x_range_max=x_range_min + sel_datos['Shape__Are'].max()*(10000/0.75)\n",
    "            x_range_min=x_range_min - sel_datos['Shape__Are'].max()*(10000/0.75)\n",
    "        else:\n",
    "            if  (x_range_max - x_range_min) < 5000:\n",
    "                x_range_max+=2500\n",
    "                x_range_min-=2500\n",
    "\n",
    "        if y_range_min == y_range_max:\n",
    "            y_range_max=y_range_min  + sel_datos['Shape__Are'].max()*(10000/0.75) \n",
    "            y_range_min=y_range_min  - sel_datos['Shape__Are'].max()*(10000/0.75) \n",
    "        else:\n",
    "            if  (y_range_max - y_range_min) < 5000:\n",
    "\n",
    "                y_range_max+=2500\n",
    "                y_range_min-=2500\n",
    "        \n",
    "            \n",
    "        print(\"rango canvas: \", x_range_min, x_range_max, y_range_min, y_range_max )\n",
    "        #ventana_actual={\"x_range_min\": None, \"x_range_max\": None, \"y_range_min\": None, \"y_range_max\": None}\n",
    "        self.ventana_actual['x_range_min']=x_range_min\n",
    "        self.ventana_actual['x_range_max']=x_range_max\n",
    "        self.ventana_actual['y_range_min']=y_range_min\n",
    "        self.ventana_actual['y_range_max']=y_range_max\n",
    "        print(\"ventana_actual: \" ,self.ventana_actual )\n",
    "        \n",
    "        self.puntos=self.puntos \\\n",
    "                        .redim.values(lng_mercator=(x_range_min, x_range_max),\n",
    "                        lat_mercator=(y_range_min, y_range_max) ).opts(framewise=True)\n",
    "                  \n",
    "        self.puntos=self.puntos.select(lng_mercator=(x_range_min , x_range_max) , lat_mercator=(y_range_min , y_range_max) )\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if self.localidades=='Todas':\n",
    "#             set_data=self.datos\n",
    "#         else:\n",
    "#             set_data=self.datos.select(PCMLNP=self.localidades)\n",
    "        \n",
    "#         if x_range is None:\n",
    "#             puntos=hv.Points(set_data, ['Longitude', 'Latitude']\n",
    "#                     , ['Texto', 'Cod_CCAA', 'dircompleta' , 'PCMLNP', 'PCMNFC', 'PCMNPR' ])\n",
    "#         else:\n",
    "#             puntos=hv.Points(set_data, ['Longitude', 'Latitude']\n",
    "#                     , ['Texto', 'Cod_CCAA', 'dircompleta' , 'PCMLNP', 'PCMNFC', 'PCMNPR' ])\\\n",
    "#                         .select( longitude= x_range, latitude=y_range )\n",
    "              \n",
    "       \n",
    "        return self.puntos\n",
    "        \n",
    "        #return self.datos\n",
    "    \n",
    "    \n",
    "    \n",
    "    @param.depends('alpha' , watch=True)\n",
    "    def tiles(self):\n",
    "        #self.mapa_fondo=map_tiles.opts(gopts).opts(alpha=self.alpha, **opts1)\n",
    "        #return self.mapa_fondo\n",
    "        return map_tiles.opts(gopts).opts(alpha=self.alpha, framewise=True, **opts1_t)\n",
    "        #return  gv.tile_sources.CartoDark (alpha=self.alpha, framewise=True, **opts1_t)\n",
    "     \n",
    "    @param.depends('muestra_nombres')\n",
    "    def labels(self):\n",
    "        return gts.StamenLabels.options(level='annotation', alpha=1 if self.muestra_nombres else 0)\n",
    "    \n",
    "    @param.depends('localidades' , 'sel_rgo_cli', 'facturadores', 'agrup_servicios'\n",
    "                   ,'natups', 'red', watch=True)\n",
    "    def selected_info(self, x_range=None, y_range=None):\n",
    "        #si estuviesemos trabajando conuna seleccion 1d sobre puntos que no va a ser el caso\n",
    "        #recogeriamos la matriz de puntos seleccionada, de la siguiente forma:\n",
    "#         arr = self.puntos.array()[index]\n",
    "#         if len(arr)==0:\n",
    "#             tabla=hv.Table(self.puntos)\n",
    "#         else:\n",
    "#             tabla=hv.Table( self.puntos.clone(arr) )\n",
    "\n",
    "#         print(\"array en selected_info es: \" , arr)\n",
    "\n",
    "        \n",
    "        print(\"seleccion en selected_info: \" , x_range, y_range)\n",
    "        clon_puntos=self.puntos\n",
    "        print(\"datos dentro de clon puntos: \", clon_puntos.data.compute().shape[0] )\n",
    "        clon_puntos=clon_puntos.select(lng_mercator=x_range , lat_mercator=y_range)\n",
    "        print(\"forma de clon_puntos despues selecionar\", len(clon_puntos))\n",
    "        self.tabla=hv.Table(clon_puntos, kdims=[], vdims=[('PCMNFC','Facturador')\n",
    "                                                     , ('PCMNPR', 'Profesional')\n",
    "                                                     ,('dircompleta', 'dirección')\n",
    "                                                     ,('PCMLNP','Localidad')\n",
    "                                                     , ('PCMEDS', 'Especialidad')\n",
    "                                                     , ('n_clientes_a_radio', 'n. clientes -radio-')\n",
    "                                                     , ('total_primas', 'Primas -radio-')   \n",
    "                                                         ]).opts(height=300)\n",
    "        \n",
    "        df_box=clon_puntos.data[['n_clientes_a_radio', 'PCMLNP', 'PCMEDS']].compute()\n",
    "        \n",
    "        \n",
    "        boxwhisker = hv.BoxWhisker((df_box['PCMLNP'], df_box['PCMEDS'], df_box['n_clientes_a_radio']  ),\n",
    "              ['Localidad', 'Especialidad'], 'Value').sort()\n",
    "        boxwhisker.opts(height=300)\n",
    "        \n",
    "        \n",
    "#         if index:\n",
    "#             label = 'Mean x, y: %.3f, %.3f' % tuple(arr.mean(axis=0))\n",
    "#         else:\n",
    "#             label = 'No selection'\n",
    "        #return points.clone(arr, label=label).opts(style=dict(color='red'))\n",
    "        return self.tabla\n",
    "    def selected_info_scatter(self, x_range=None, y_range=None):\n",
    "        \n",
    "        print(\"seleccion en selected_info: \" , x_range, y_range)\n",
    "        clon_puntos=self.puntos\n",
    "        print(\"datos dentro de clon puntos: \", clon_puntos.data.compute().shape[0] )\n",
    "        if x_range is not None:\n",
    "            clon_puntos=clon_puntos.select(lng_mercator=x_range , lat_mercator=y_range)\n",
    "        print(\"forma de clon_puntos despues selecionar\", len(clon_puntos))\n",
    "        \n",
    "        \n",
    "        #df_box=clon_puntos.data[['n_clientes_a_radio', 'PCMLNP', 'PCMEDS']].compute()\n",
    "        df_box=clon_puntos.data[['n_clientes_a_radio', 'Shape__Are' , 'FACTURACION_MENSUAL']].compute()\n",
    "        fac_min=df_box['FACTURACION_MENSUAL'].quantile(0.01)\n",
    "        fac_max=df_box['FACTURACION_MENSUAL'].quantile(0.99)\n",
    "        print(\"rango clientes: \", fac_min, fac_max)\n",
    "        \n",
    "        sct=hv.Scatter( df_box,kdims=[('Shape__Are', 'Area Localidad'),\n",
    "                                       ('n_clientes_a_radio', 'clientes') ]\n",
    "                            , vdims=[ ('FACTURACION_MENSUAL', 'Facturación')]\n",
    "                                       ).redim.range(FACTURACION_MENSUAL=(fac_min, fac_max)).opts(framewise=True)\n",
    "        \n",
    "        sct = hv.HexTiles(df_box, kdims=[('Shape__Are', 'Area Localidad'),\n",
    "                                       ('n_clientes_a_radio', 'clientes') ], vdims=['FACTURACION_MENSUAL'])\\\n",
    "                                .opts(framewise=True)\n",
    "        sct=hv.Div(\"\"\"\n",
    "            <h1>Datos de interés</h1>\n",
    "            <h3>Realice sus selecciones y visualize cuantos servicios existen en la zona\n",
    "            y cuantos clientes están a un radio de 1500m.\n",
    "            Si pulsa en el botón exportar a excel, obtendrá un documento con las selección de datos</h2>\n",
    "            \n",
    "            \"\"\")\n",
    "        #sct = sct.opts(color='FACTURACION_MENSUAL', size=dim('FACTURACION_MENSUAL')/10 )\n",
    "        #distri=hv.Distribution(df_box)\n",
    "#         boxwhisker = hv.BoxWhisker((df_box['PCMLNP'], df_box['PCMEDS'], df_box['n_clientes_a_radio']  ),\n",
    "#               ['Localidad', 'Especialidad'], 'Value').sort()\n",
    "#         boxwhisker.opts(height=300)\n",
    "        \n",
    "        \n",
    "#         if index:\n",
    "#             label = 'Mean x, y: %.3f, %.3f' % tuple(arr.mean(axis=0))\n",
    "#         else:\n",
    "#             label = 'No selection'\n",
    "        #return points.clone(arr, label=label).opts(style=dict(color='red'))\n",
    "        return sct #boxwhisker\n",
    "    def selected_info_box(self, x_range=None, y_range=None):\n",
    "        #si estuviesemos trabajando conuna seleccion 1d sobre puntos que no va a ser el caso\n",
    "        #recogeriamos la matriz de puntos seleccionada, de la siguiente forma:\n",
    "#         arr = self.puntos.array()[index]\n",
    "#         if len(arr)==0:\n",
    "#             tabla=hv.Table(self.puntos)\n",
    "#         else:\n",
    "#             tabla=hv.Table( self.puntos.clone(arr) )\n",
    "\n",
    "#         print(\"array en selected_info es: \" , arr)\n",
    "\n",
    "        \n",
    "        print(\"seleccion en selected_info: \" , x_range, y_range)\n",
    "        clon_puntos=self.puntos\n",
    "        print(\"datos dentro de clon puntos: \", clon_puntos.data.compute().shape[0] )\n",
    "        if x_range is not None:\n",
    "            clon_puntos=clon_puntos.select(lng_mercator=x_range , lat_mercator=y_range)\n",
    "        print(\"forma de clon_puntos despues selecionar\", len(clon_puntos))\n",
    "        \n",
    "        \n",
    "        #df_box=clon_puntos.data[['n_clientes_a_radio', 'PCMLNP', 'PCMEDS']].compute()\n",
    "        df_box=clon_puntos.data[['n_clientes_a_radio']].compute()\n",
    "        cli_min=df_box['n_clientes_a_radio'].quantile(0.01)\n",
    "        cli_max=df_box['n_clientes_a_radio'].quantile(0.99)\n",
    "        print(\"rango clientes: \", cli_min, cli_max)\n",
    "        distri=hv.Distribution(df_box).redim.range(n_clientes_a_radio=(cli_min, cli_max)).opts(framewise=True)\n",
    "        #distri=hv.Distribution(df_box)\n",
    "#         boxwhisker = hv.BoxWhisker((df_box['PCMLNP'], df_box['PCMEDS'], df_box['n_clientes_a_radio']  ),\n",
    "#               ['Localidad', 'Especialidad'], 'Value').sort()\n",
    "#         boxwhisker.opts(height=300)\n",
    "        \n",
    "        \n",
    "#         if index:\n",
    "#             label = 'Mean x, y: %.3f, %.3f' % tuple(arr.mean(axis=0))\n",
    "#         else:\n",
    "#             label = 'No selection'\n",
    "        #return points.clone(arr, label=label).opts(style=dict(color='red'))\n",
    "        return distri #boxwhisker\n",
    "\n",
    "\n",
    "    #si queiero pasar determinados argumentos solo cuando cambien ellos mismos y no onsiderar cualquier\n",
    "    #cambio de cualquier parametro para ahorrar en rendimiento y no calcular todo todas las veces,\n",
    "    #no puedo repetir las dependencias en los procedimiento de cambio y aqui para pintarlo, yaque,\n",
    "    #lo que pasara es que se pintara con el parametro sincambiar antes de que se notifique el cambio\n",
    "    #en el procedimiento de cambio.\n",
    "    #@param.depends('localidades' ,watch=True)\n",
    "    def prepara_grafico(self, **kwargs):\n",
    "        \n",
    "        print( self.name, self.localidades)\n",
    "        #if (not self.set_datos.empty):\n",
    "\n",
    "\n",
    "#             sombreador=datashade(hv.DynamicMap(self.SeleccionaDatos), cmap=self.param.colormap\n",
    "#                                  ,   streams=[RangeXY()]\n",
    "#                                  , **opts2)\n",
    "\n",
    "        #*********************************************************************************\n",
    "        #En el caso típico de tener conjuntos de datos mucho mayor que la resolución trama, \n",
    "        #HoloViews operaciones que funcionan en el conjunto de datos completo \n",
    "        #Datashader-basa ( rasterize, aggregate, regrid) son computacionalmente caro; \n",
    "        #los otros no lo son ( shade, spread, dynspread, etc.)\n",
    "        #*********************************************************************************\n",
    "        #el precompute=True en este caso hace que las interacciones sean rápidas, sino\n",
    "        #cada vez que mueves el mapa son 25-40 segundos\n",
    "        #*********************************************************************************\n",
    "        #decido no hacer el rasterize, si lo hago piero el etalle de la distincion del color\n",
    "        #que si hace el datashade\n",
    "\n",
    "        if self.localidades != 'Todas':\n",
    "            sel_datos=self.ds_pd.loc[self.ds_pd['PCMLNP']==self.localidades].copy()\n",
    "        else:\n",
    "            sel_datos=self.ds_pd.copy()\n",
    "\n",
    "\n",
    "\n",
    "        x_range_min = sel_datos['lng_mercator'].quantile(0.01)\n",
    "        x_range_max = sel_datos['lng_mercator'].quantile(0.99)\n",
    "        y_range_min = sel_datos['lat_mercator'].quantile(0.01)\n",
    "        y_range_max = sel_datos['lat_mercator'].quantile(0.99)\n",
    "\n",
    "        #shape_are se expresa en hectareas -.> 1 hectarea son 10.000 m cuadrados\n",
    "        if x_range_min == x_range_max:\n",
    "            x_range_max=x_range_min + sel_datos['Shape__Are'].max()*(10000/0.75)\n",
    "            x_range_min=x_range_min - sel_datos['Shape__Are'].max()*(10000/0.75)\n",
    "        else:\n",
    "            if  (x_range_max - x_range_min) < 5000:\n",
    "                x_range_max+=2500\n",
    "                x_range_min-=2500\n",
    "\n",
    "        if y_range_min == y_range_max:\n",
    "            y_range_max=y_range_min  + sel_datos['Shape__Are'].max()*(10000/0.75) \n",
    "            y_range_min=y_range_min  - sel_datos['Shape__Are'].max()*(10000/0.75) \n",
    "        else:\n",
    "            if  (y_range_max - y_range_min) < 5000:\n",
    "\n",
    "                y_range_max+=2500\n",
    "                y_range_min-=2500\n",
    "\n",
    "        sw = (x_range_min,y_range_min)\n",
    "        ne = (x_range_max,y_range_max)\n",
    "        SF = zip(sw, ne)\n",
    "\n",
    "        print(\"canvas: \" ,y_range_min, y_range_max, x_range_min, x_range_max)\n",
    "        print(\"region seleccionada: \" , *SF)\n",
    "\n",
    "\n",
    "\n",
    "#             pts=hv.DynamicMap(self.SeleccionaDatos, streams=[RangeXY(transient=True)]) \\\n",
    "#                     .opts( norm=dict(framewise=True))\n",
    "\n",
    "        pts=hv.DynamicMap(self.SeleccionaDatos, streams=[RangeXY(transient=True)]).opts(axiswise=True)\n",
    "          \n",
    "\n",
    "        \n",
    "        #seleccion rango de clientes a radio\n",
    "        #pts.select(n_clientes_a_radio = self.param.sel_rgo_cli)\n",
    "        tasa_sombra=10667/len(self.puntos)\n",
    "        shaded     = datashade( pts ,streams=[RangeXY(transient=True)]\n",
    "                               , cmap=self.param['colormap'] \n",
    "                               , normalization='eq_hist' \n",
    "                               ,x_range=(x_range_min, x_range_max) , y_range=(y_range_min, y_range_max) \n",
    "                               ,x_sampling=10, y_sampling=10\n",
    "                         ).opts(axiswise=True)\n",
    "        #spreaded   = spread(shaded, px=4, how=\"add\")#esta opcion sin rasterize previo da error.\n",
    "        #spreaded   = dynspread(shaded, threshold=0.8, max_px=self.param.spreading, how='over' ).opts(axiswise=True)\n",
    "        spreaded   = dynspread(shaded, threshold=0.8, max_px=1, how='over' ).opts(axiswise=True)\n",
    "#         #esta base_forselect no puede ser un dinamicmap, la creo preciesamente x eso para que sea\n",
    "#         #la base para seleccionar con el stream un rango de puntos, asi podemos filtrar la tabla\n",
    "#         #con la seleccion realizada, pongo el alpha muy bajo para que no se vea.\n",
    "        \n",
    "#         base_forselect=datashade( self.puntos ,streams=[RangeXY(transient=True)]\n",
    "#                                , cmap=self.param['colormap'] \n",
    "#                                , normalization='eq_hist' \n",
    "#                                ,x_range=(x_range_min, x_range_max) , y_range=(y_range_min, y_range_max) \n",
    "#                                  , x_sampling=0.00001, y_sampling=0.00001\n",
    "#                          ).opts(alpha=0.1)\n",
    "#         spreaded_forselect   = dynspread(base_forselect, threshold=0.4\n",
    "#                                          , max_px=self.param.spreading, how='over'\n",
    "#                                         , streams=[RangeXY(transient=True)]).opts( alpha=0.1)\n",
    "        sel_fortabla=hv.streams.RangeXY(source=self.spreaded_forselect)\n",
    "\n",
    "        renderer = hv.renderer('bokeh')\n",
    "\n",
    "#             plot_ptos = renderer.get_plot(pts[0])\n",
    "#             print(\"Info plot_ptos: \", type(plot_ptos),dir(plot_ptos), plot_ptos.streams, plot_ptos.xlim, plot_ptos.ylim)\n",
    "\n",
    "\n",
    "        #spreaded=spreaded.select(lng_mercator=(x_range_min , x_range_max) , lat_mercator=(y_range_min , y_range_max) )\n",
    "        dataplot   = spreaded#.apply.opts(**opts1)\n",
    "        \n",
    "        dataplot= dynspread( datashade(hv.DynamicMap(self.SeleccionaDatos, streams=[RangeXY(transient=True)])\n",
    "                                   , normalization='eq_hist'\n",
    "                                , cmap=self.param['colormap'] \n",
    "                                   , width=conf_width , height=conf_height\n",
    "                                    ,x_range=(x_range_min, x_range_max) , y_range=(y_range_min, y_range_max) \n",
    "                                   ,x_sampling=5, y_sampling=5\n",
    "                                   \n",
    "                                  ) , threshold=0.75, max_px=1, how=\"add\") \n",
    "        \n",
    "        self.plot_shaded=self.plot_shaded.clone(shaded)\n",
    "        self.plot_spreaded=self.plot_spreaded.clone(spreaded)\n",
    "\n",
    "        if self.localidades=='Todas':\n",
    "            #mas_info=hv.Empty()\n",
    "            print(\"min n clientes radio: \", self.set_datos['n_clientes_a_radio'].min() )\n",
    "            valores_sel=self.set_datos['n_clientes_a_radio']\n",
    "            data_uno=self.datos.select(n_clientes_a_radio=10000 )\n",
    "            print(\"registros en data_uno: \", len(data_uno))\n",
    "            mas_info=hv.Points(data_uno, kdims=['lng_mercator', 'lat_mercator'] \n",
    "             , vdims=['PCMNFC', 'PCMNPR', 'dircompleta', 'PCMLNP' ,'n_clientes_a_radio','total_primas'\n",
    "                     ,'PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD'])\n",
    "\n",
    "        else:\n",
    "            mas_info=hv.Points(self.datos, kdims=['lng_mercator', 'lat_mercator'] \n",
    "             , vdims=['PCMNFC', 'PCMNPR', 'dircompleta', 'PCMLNP' ,'n_clientes_a_radio', 'total_primas'\n",
    "                     ,'PCMEDS','PCMNPS','PCMNAT','PCMRDS','PCMEGD'])\\\n",
    "                .opts(tools=[\"hover\"])\n",
    "\n",
    "#             capa_Quadmesh=(hv.util.Dynamic(hd.aggregate(spreaded, streams=[self.box]), operation=hv.QuadMesh ))\\\n",
    "#                                         .opts(tools=[\"hover\",\"save\", \"undo\", \"redo\"]\n",
    "#                                                , alpha=0  , hover_alpha=0.2, hover_color=\"white\"\n",
    "#                                                , show_legend=False )\n",
    "        self.spreaded_forselect=self.spreaded_forselect.select(lng_mercator=(x_range_min, x_range_max) \n",
    "                                          , lat_mercator=(y_range_min, y_range_max)  )\n",
    "\n",
    "        final=(dataplot.opts(tools=[ \"box_select\", \"lasso_select\" ], axiswise=True )  * hv.DynamicMap(self.tiles) \\\n",
    "            * hv.DynamicMap(self.labels) * self.spreaded_forselect)\n",
    "\n",
    "            #\\\n",
    "                #* capa_Quadmesh\n",
    "        \n",
    "#             #rtlink = RangeToolLink(source, target)\n",
    "        #tabla=hv.Table(self.tabla)\n",
    "#             #rtlink = DataLink( dataplot, tabla)\n",
    "#             rtlink =DataLink( dataplot, tabla)\n",
    "\n",
    "        #lo proximo es embed un div (con algun boton de js para exportar datos a excel)\n",
    "        #ver: http://holoviews.org/reference/elements/bokeh/Div.html\n",
    "        #return  pts.opts(tools=[\"box_select\"]) \n",
    "\n",
    "        #obj_puntos=hv.renderer('bokeh').get_plot(final)\n",
    "        #self.seleccion=hv.streams.Selection1D(source=obj_puntos)\n",
    "        print(\"final : \" , type(final ) )\n",
    "        \n",
    "        return ( final.options( axiswise=True,\n",
    "        tools=[ \"box_select\", \"lasso_select\", \"redo\", \"undo\" ],\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        toolbar='above',\n",
    "\n",
    "        #height=600,\n",
    "        #width=600\n",
    "    ) + hv.DynamicMap(self.selected_info, streams=[sel_fortabla]).options(\n",
    "        height=600,\n",
    "        width=800,\n",
    "        toolbar = None \n",
    "    )  + hv.DynamicMap(self.selected_info_box, streams=[sel_fortabla]).options(\n",
    "        height=200,\n",
    "        max_width=800,\n",
    "        toolbar = None \n",
    "    ) + hv.DynamicMap(self.selected_info_scatter, streams=[sel_fortabla]).options(\n",
    "        height=200,\n",
    "        width=800,\n",
    "        toolbar = None \n",
    "    )).opts(merge_tools=False).cols(2)\n",
    "\n",
    "    \n",
    "    \n",
    "        return ( final.options( axiswise=True,\n",
    "        tools=[ \"box_select\", \"lasso_select\", \"redo\", \"undo\" ],\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        toolbar='above',\n",
    "\n",
    "        #height=600,\n",
    "        #width=600\n",
    "    ) + hv.DynamicMap(self.selected_info, streams=[sel_fortabla]).options(\n",
    "        height=600,\n",
    "        width=800,\n",
    "        toolbar = None \n",
    "    )).opts(merge_tools=False).cols(2)\n",
    "\n",
    "\n",
    "\n",
    "        return ( final.options(\n",
    "        tools=[ \"box_select\", \"lasso_select\", \"redo\", \"undo\" ],\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        toolbar='above',\n",
    "\n",
    "        #height=600,\n",
    "        #width=600\n",
    "    ) + hv.DynamicMap(self.selected_info, streams=[ hv.streams.Selection1D(source=final)]).options(\n",
    "        height=600,\n",
    "        width=800,\n",
    "        toolbar = None \n",
    "    )).opts(merge_tools=False)\n",
    "\n",
    "        #return (dataplot * hv.DynamicMap(self.tiles) ) * hv.DynamicMap(self.labels) #\\\n",
    "                   ##* capa_Quadmesh\n",
    "           \n",
    "    \n",
    "\n",
    "explorador=ExploraCMedico(name=\"Situación c.medico Privado y Muface\")\n",
    "#explorador.param._BATCH_PARAM=False\n",
    "#explorador.param.batch_param=True\n",
    "#explorador.transient=True\n",
    "\n",
    "\n",
    "#el truco para que solo coja los cambios del DynamicMap y de self.param... cuando los objetos\n",
    "#cambien, es llamar a la funcion con los parentesis, es decir explorador.prepara_grafico() y no\n",
    "\n",
    "#print(explorador.name, explorador.transient)\n",
    "\n",
    "dashboard=pn.Row(pn.Param(explorador.param, expand_button=False), explorador.prepara_grafico() )\n",
    "    \n",
    "#explorador.event()\n",
    "\n",
    "#la unica forma que he encontrado para recuperar los streams en llamando explorador.evento() post\n",
    "#generacion de la variable dashboar con la llamada a prepara_grafico, si llamo a evento\n",
    "#desde la generacion de la variable dashboard no pinta mas que los parametros el plot no.\n",
    "dashboard.show(websocket_origin='*')    #con esto conseguimos que pueda compartirse desde mi ip, sustituyendo\n",
    "#dashboard\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data_plot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "%matplotlib inline\n",
    "\n",
    "dask_df['n_clientes_a_radio'].compute().hist(bins=30)\n",
    "dask_df['n_clientes_a_radio'].idxmax().compute()\n",
    "dask_df['n_clientes_a_radio'].idxmin().compute()\n",
    "IFrame(src=use_data_plot.iloc[use_data_plot['n_clientes_a_radio'].idxmax()].n_clientes_a_radio, \n",
    "       width=800, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(use_data_plot.columns)\n",
    "#PCMDLC: Localidad punto de servicio\n",
    "#PCMLNP: Loclidad cuadro medico nombre publicable\n",
    "#PCMLPR: Provincia cuadro medico -codigo INE-\n",
    "#PCMLLC: Localidad cuadro meidco localidad -codigo INE-\n",
    "use_data_plot[['PCMLPR', 'PCMDLC', 'PCMLNP']].head(3)\n",
    "use_data_plot['PCMDLC']=use_data_plot['PCMDLC'].apply(lambda x: x.lower().capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_df.describe().compute()\n",
    "#en un dataframe pandas tambien podemos hacer un query:\n",
    "#downtown_listings = listings.query('hood in @downtown_hoods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class pba_param(param.Parameterized):\n",
    "    Nota_export_= param.Parameter(default=\" a\", constant=True)\n",
    "    uno=param.ObjectSelector(default=2, objects=[1,2,3])\n",
    "    print (type(Nota_export_) )\n",
    "    \n",
    "    #@param.depends('Nota_export_')\n",
    "    def change(self):\n",
    "        print(type(self.param.Nota_export_) )\n",
    "        print(type(self.param.uno))\n",
    "        self.param.Nota_export_.constant=False\n",
    "        self.Nota_export_=\"\"\"sssssss\"\"\"\n",
    "        self.param.Nota_export_.constant=True\n",
    "        \n",
    "base = pba_param()\n",
    "base.change()\n",
    "pn.Row(base.param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(pn.widgets.LiteralInput)\n",
    "#defaults, disabled, value\n",
    "dir(param.Parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_html=hv.Div(\"\"\"\n",
    "                    <h1>Div</h1>\n",
    "                    \n",
    "                   \n",
    "                    <h3>A simple demo</h2>\n",
    "\n",
    "                    <figure>\n",
    "                    <img src=\"https://assets.holoviews.org/logo/holoviews_color_icon_500x500.png\" height='200' \n",
    "                    width='200'>\n",
    "                    <figcaption><b>Fig 1:</b> This is a figure caption with $LaTeX$</figcaption>\n",
    "                    \"\"\")\n",
    "show_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = hv.renderer('bokeh')\n",
    "\n",
    "points =hv.Points(np.random.randn(100,2 )).opts(plot=dict(tools=['box_select', 'lasso_select']))\n",
    "ras=datashade(points,aggregator='count', x_sampling=0.00001, y_sampling=0.00001, dynamic=False)\n",
    "sel1 = hv.streams.Selection1D(source=ras)\n",
    "sel2=hv.streams.RangeXY(source=ras)\n",
    "\n",
    "def selected_info2(x_range=None, y_range=None):\n",
    "    print(\"estamos en select info2\")\n",
    "    \n",
    "    print(x_range, y_range)\n",
    "    return points\n",
    "#     arr = points.array()[index]\n",
    "#     if len(arr)==0:\n",
    "#         tabla=hv.Table(points)\n",
    "#     else:\n",
    "#         tabla=hv.Table( points.clone(arr) )\n",
    "        \n",
    "#     print(arr)\n",
    "#     if index:\n",
    "#         label = 'Mean x, y: %.3f, %.3f' % tuple(arr.mean(axis=0))\n",
    "#     else:\n",
    "#         label = 'No selection'\n",
    "#     #return points.clone(arr, label=label).opts(style=dict(color='red'))\n",
    "#     return tabla\n",
    "\n",
    "layout =(ras.opts(tools=[\"box_select\"]) + hv.DynamicMap(selected_info2, streams=[sel2])).opts(merge_tools=False)\n",
    "layout\n",
    "\n",
    "# def recopila_event(**kwargs):\n",
    "#     for a in kwargs:\n",
    "#         print (a)\n",
    "        \n",
    "# dm=hv.DynamicMap(points)\n",
    "# # dm[0].pprint\n",
    "# # print(dir(dm))\n",
    "# # dm.traverse\n",
    "# # elem=dm.split_overlays()\n",
    "# # elem\n",
    "# # dm.overlay\n",
    "# # help(dm.event)\n",
    "# layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "use_data_plot['n_clientes_a_radio'].describe()\n",
    "print(use_data_plot.columns)\n",
    "\n",
    "\n",
    "lst_factu=use_data_plot['PCMNFC'].unique()\n",
    "lst_factu=list(lst_factu)\n",
    "lst_factu=[ x.strip() for x in lst_factu]\n",
    "lst_factu.sort\n",
    "lst_factu.insert(0, 'Todos')\n",
    "lst_factu\n",
    "lst_factu=np.asarray(lst_factu)\n",
    "lst_factu\n",
    "\n",
    "lst_prof=use_data_plot['PCMNPR'].unique()\n",
    "lst_prof=list(lst_prof)\n",
    "lst_prof=[ x.strip() for x in lst_prof]\n",
    "lst_prof.sort\n",
    "lst_prof.insert(0, 'Todos')\n",
    "lst_prof\n",
    "lst_prof=np.asarray(lst_prof)\n",
    "lst_prof\n",
    "\n",
    "lst_espec=use_data_plot['PCMEDS'].unique()\n",
    "lst_espec=list(lst_espec)\n",
    "lst_espec=[ x.strip() for x in lst_espec]\n",
    "lst_espec.sort\n",
    "lst_espec.insert(0, 'Todos')\n",
    "lst_espec\n",
    "lst_espec=np.asarray(lst_espec)\n",
    "lst_espec\n",
    "\n",
    "lst_nomps=use_data_plot['PCMNPS'].unique()\n",
    "lst_nomps=list(lst_nomps)\n",
    "lst_nomps=[ x.strip() for x in lst_nomps]\n",
    "lst_nomps.sort\n",
    "lst_nomps.insert(0, 'Todos')\n",
    "lst_nomps\n",
    "lst_nomps=np.asarray(lst_nomps)\n",
    "lst_nomps\n",
    "\n",
    "lst_natups=use_data_plot['PCMNAT'].unique()\n",
    "lst_natups=list(lst_natups)\n",
    "lst_natups=[ x.strip() for x in lst_natups]\n",
    "lst_natups.sort\n",
    "lst_natups.insert(0, 'Todos')\n",
    "lst_natups\n",
    "lst_natups=np.asarray(lst_natups)\n",
    "lst_natups\n",
    "\n",
    "lst_red=use_data_plot['PCMRDS'].unique()\n",
    "lst_red=list(lst_red)\n",
    "lst_red=[ x.strip() for x in lst_red]\n",
    "lst_red.sort\n",
    "lst_red.insert(0, 'Todos')\n",
    "lst_red\n",
    "lst_red=np.asarray(lst_red)\n",
    "lst_red\n",
    "\n",
    "lst_agrup_servicio=use_data_plot['PCMEGD'].unique()\n",
    "lst_agrup_servicio=list(lst_agrup_servicio)\n",
    "lst_agrup_servicio=[ x.strip() for x in lst_agrup_servicio]\n",
    "lst_agrup_servicio.sort\n",
    "lst_agrup_servicio.insert(0, 'Todos')\n",
    "lst_agrup_servicio\n",
    "lst_agrup_servicio=np.asarray(lst_agrup_servicio)\n",
    "lst_agrup_servicio\n",
    "\n",
    "use_data_plot['PCMLAS'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_def=use_data_plot\n",
    "df_def['lng_mercator']=0.0\n",
    "df_def['lat_mercator']=0.0\n",
    "df_def.loc[:, 'lng_mercator'], df_def.loc[:, 'lat_mercator'] = ds.utils.lnglat_to_meters(df_def['lng'],df_def['lat'])\n",
    "\n",
    "dask_df = dd.from_pandas(df_def, npartitions=mp.cpu_count())\n",
    "print(\"num particiones: \" , dask_df.npartitions)\n",
    "\n",
    "# datos_pba=hv.Dataset(dask_df[['geometry','Texto', 'Cod_CCAA', 'dircompleta', 'lng', 'lat'\n",
    "#                                               , 'PCMDLC', 'PCMNFC', 'PCMNPR' ]]\n",
    "#                  , kdims=['Longitude', 'Latitude']\n",
    "#                  , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ])\n",
    "# datos_pba=datos_pba.select(PCMDLC='Alfajarin')\n",
    "#x_range=(-284064.5868426339, 84135.49382265727),y_range=(5011787.7442349475, 5261637.798972109)\n",
    "#x_range=(-99223.5570432538, -97188.9190735894),y_range=(5106710.538524679, 5109590.921894633))\n",
    "#(-192692.61369985767, -149955.1043369221),y_range=(5113505.071206684, 5154927.58028153))\n",
    "# datos_pba=datos_pba.select(longitude=(-192692.61369985767, -149955.1043369221)\n",
    "#                            , latitude=(5113505.071206684, 5154927.58028153))\n",
    "\n",
    "# pts=hv.Points(dask_df , kdims=['Longitude', 'Latitude']\n",
    "#                  , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ]).opts(axiswise=True\n",
    "#                                                 , width=600, height=400)\n",
    "# cvs = ds.Canvas(600, 400)\n",
    "\n",
    "# agg = cvs.points(dask_df, 'lng', 'lat')\n",
    "\n",
    "# Map of all businesses colored by category.\n",
    "url=\"http://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{Z}/{Y}/{X}.png\"\n",
    "geomap = gv.WMTS(url)\n",
    "dts=hv.Dataset(dask_df ,kdims=['lng_mercator', 'lat_mercator']\n",
    "                              , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ])\n",
    "points = hv.Points(dts\n",
    "                    ,kdims=['lng_mercator', 'lat_mercator']\n",
    "                              , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ]\n",
    "                  )\n",
    "biz_cat = dynspread(datashade(points, color_key=fire, element_type=gv.Image, aggregator=ds.count()))\n",
    "#biz_cat=biz_cat.redim.values(PCMDLC='Alfajarin').opts(framewise=True)\n",
    "biz_cat=biz_cat.select(lng_mercator=(-284064.5868426339, -200000.49382265727),lat_mercator=(5011787.7442349475, 5261637.798972109))\n",
    "map_tiles * biz_cat.opts(framewise=True)\n",
    "#biz_cat.opts(width=800, height=600)\n",
    "# print(\"registros en dataset: \", len(agg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(use_data_plot.columns)\n",
    "use_data_plot[['Shape__Len', 'Shape__Are', 'PCMDLC']].loc[use_data_plot['PCMDLC']=='Borja']\n",
    "cpy_geo=geo_completa\n",
    "#df.drop(columns=['B', 'C'])\n",
    "#cpy_geo.drop(columns=['index_right'], inplace=True)\n",
    "#df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n",
    "cpy_geo=cpy_geo.rename(columns={\"Shape__Are\": \"Area_Provincia\"     })\n",
    "cpy_geo[\"lng_mercator\"]=0\n",
    "cpy_geo[\"lat_mercator\"]=0\n",
    "cpy_geo.loc[:, 'lng_mercator'], cpy_geo.loc[:, 'lat_mercator'] = ds.utils.lnglat_to_meters(cpy_geo['lng'],cpy_geo['lat'])\n",
    "cpy_geo.crs = {'init' :'epsg:4326'}  \n",
    "#ahora reprogamamos al crs de mercator para q coincida con los tiles a superponer\n",
    "cpy_geo=cpy_geo.to_crs({'init': 'epsg:3857'})\n",
    "\n",
    "cpy_munidf=muni_df\n",
    "cpy_munidf.crs = {'init' :'epsg:4326'}  \n",
    "uni_muni=uni_muni.to_crs({'init': 'epsg:3857'})\n",
    "\n",
    "uni_muni = gpd.sjoin(cpy_geo, muni_df[['Shape__Are', 'NAMEUNIT', 'geometry']], how='left',op='within') \n",
    "\n",
    "\n",
    "uni_muni.columns\n",
    "print(cpy_geo.columns)\n",
    "print(muni_df.columns)\n",
    "print(uni_muni.shape[0], geo_completa.shape[0])\n",
    "print(cpy_geo.crs)\n",
    "cpy_geo.columns\n",
    "uni_muni.head()\n",
    "uni_muni[['PCMDLC','dircompleta', 'lng', 'lat']].loc[pd.isnull(uni_muni['NAMEUNIT'] )==True ].head(2)\n",
    "#gdf['geometry'] = gdf.geometry.buffer(2)\n",
    "uni_muni['geometry']=uni_muni['geometry'].buffer(20)\n",
    "uni_muni[['PCMDLC','dircompleta', 'lng', 'lat', 'geometry']].loc[pd.isnull(uni_muni['NAMEUNIT'] )==True ].head(2)\n",
    "#uni_muni.dropna(inplace=True)\n",
    "\n",
    "#dask_df = dd.from_pandas(uni_muni, npartitions=mp.cpu_count())\n",
    "#hvplot solo trabaja con version pandas 0.25\n",
    "#uni_muni.hvplot(global_extent=True, width=500, height=450, tiles=True)\n",
    "# dset_tab=hv.Dataset(uni_muni[['geometry']], kdims=[\"Longitude\", \"Latitude\"])\n",
    "# hv.Polygons(dset_tab).opts(width=400, height=300) * map_tiles"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%opts Image {+framewise}\n",
    "# from holoviews import opts\n",
    "# from holoviews import streams\n",
    "from holoviews.streams import  Buffer\n",
    "from holoviews.operation.datashader import regrid\n",
    "\n",
    "opts1=dict( width=600, height=600,xaxis=None, yaxis=None,bgcolor=\"black\")\n",
    "opts1_t=dict(width=600, height=600, xaxis=None, yaxis=None,bgcolor=\"black\")\n",
    "opts2=dict(x_sampling=10, y_sampling=10 )\n",
    "gopts  = hv.opts.WMTS(xaxis=None, yaxis=None, bgcolor='black', show_grid=False,width=600, height=600)\n",
    "\n",
    "url = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{Z}/{Y}/{X}.jpg'\n",
    "map_tiles=gv.WMTS(url, crs=crs.GOOGLE_MERCATOR)\n",
    "datos=use_data_plot\n",
    "\n",
    "\n",
    "lst_muni=datos['PCMDLC'].unique()\n",
    "lst_muni=list(lst_muni)\n",
    "lst_muni.sort()\n",
    "lst_muni.insert(0,'Todas')\n",
    "\n",
    "cmaps  = dict([(n, cm_n[n]) for n in cm_n.keys() ])\n",
    "\n",
    "#**********************************************************************************************************\n",
    "#                                           NOTAS TECNICAS:\n",
    "#**********************************************************************************************************\n",
    "#Hay varias formas de notificar los cambios en el panel, aquí vamos a utilizar la 2 y 3 ya que siendo las\n",
    "#más complejas, son las más útiles en cuanto a rendimiento:\n",
    "#1.- dependencias signifcadas con el decorador @pn.depends(...), siempre que cambie alguno de los\n",
    "#parametros significados asi, cambiará el proceso y se ejecutará todo de nuevo\n",
    "#2.-Dependencia de un método para DynamicMap: decoraremos igualmente con @pn.dependes(...), lo que cambia\n",
    "#aqui es que al utilizar DynamicMap, el metodo solo se re-ejecutara cuando cambie algun parametro que\n",
    "#este afectado en este DynamicMap\n",
    "#3.-Argumento instancia-objeto de parametro: proporcionaremos una instancia del objeto param en lugar del\n",
    "#valor asociado a ese parametro, así las dependencias se infieren solo cuando se pasa el objeto completo\n",
    "#y sólo cambiarán o se actualizará cuando el valor cambie.\n",
    "#(*): Los enfoques 2 y 3 se basan en una caracteristica de HoloViews llamada streaming, que admiten muchos\n",
    "#tipos de comportamiento dinámico, además de responder a widgets. Por ejemplo la rasterize operación \n",
    "#adjunta una RangeXY streaming que vuelve a agregar los datos cada vez que cambia la ventana gráfica, lo \n",
    "#mismo ocurre en nuesro ejemplo en la operación de datashade.\n",
    "#**********************************************************************************************************\n",
    "class ExploraCMedico(param.Parameterized):\n",
    "#class ExploraCMedico(hv.streams.Stream):\n",
    "\n",
    "    \n",
    "    alpha=param.Magnitude(default=0.5, doc=\"Opacidad mapa\")\n",
    "    #colormap=param.ObjectSelector(default=\"fire\", objects=list(cm_n.keys()))\n",
    "    colormap=param.Selector(cmaps)\n",
    "    localidades=param.ObjectSelector(default=\"Todas\", objects=lst_muni )\n",
    "    set_datos=use_data_plot\n",
    "    spreading     = param.Integer(3, bounds=(0, 5))\n",
    "    muestra_nombres   = param.Boolean(True)\n",
    "    datos=hv.Dataset(use_data_plot[['geometry','Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ]]\n",
    "                 , kdims=['Longitude', 'Latitude']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ])\n",
    "    \n",
    "    #points=hv.Points(datos, ['Longitude', 'Latitude'])\n",
    "    #puntos=hv.Points(datos, ['Longitude', 'Latitude']).opts(framewise=True, axiswise=True)\n",
    "    #mapa_fondo=map_tiles.opts(gopts).opts(alpha=0.5, **opts1)\n",
    "    # selection that gives the current x_range/y_range of the map\n",
    "    #box = hv.streams.RangeXY(transient=True)\n",
    "    puntos=None\n",
    "    \n",
    "    @param.depends('localidades' , watch=True)\n",
    "    def SeleccionaDatos(self, x_range=None, y_range=None):\n",
    "        print(\"estamos en seleccionDatos\", self.params.args, x_range, y_range)\n",
    "        #print(dir( self.param.localidades) )\n",
    "        #print(self.param.localidades.__getstate__(), self.param.localidades.watchers)\n",
    "             \n",
    "       \n",
    "\n",
    "        self.set_datos=use_data_plot\n",
    "        \n",
    "            \n",
    "        if self.localidades=='Todas':\n",
    "            #idx_filtros= [m  for m in ( self.set_datos['PCMDLC'] ==  self.set_datos['PCMDLC']) ]\n",
    "            idx_filtros=[True  for m in  range (self.set_datos.shape[0])   ]\n",
    "            self.set_datos = self.set_datos[idx_filtros]\n",
    "        else:\n",
    "            \n",
    "            idx_filtros=[m  for m in ( self.set_datos['PCMDLC'] == self.localidades) ]\n",
    "            self.set_datos = self.set_datos[idx_filtros]\n",
    "            \n",
    "        \n",
    "        datos_=hv.Dataset(self.set_datos[['geometry','Texto', 'Cod_CCAA', 'dircompleta'\n",
    "                                              , 'PCMDLC', 'PCMNFC', 'PCMNPR' ]]\n",
    "                 , kdims=['Longitude', 'Latitude']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ])\n",
    "        print(\"forma de gedf set_datos en selecciondatos: \", self.set_datos.shape)\n",
    "        print(\"forma de hv dataset datos en selecciondatos: \", len(datos_.data))\n",
    "        \n",
    "        puntos=hv.Points(self.set_datos, ['Longitude', 'Latitude']\n",
    "                     , ['Texto', 'Cod_CCAA', 'dircompleta' , 'PCMDLC', 'PCMNFC', 'PCMNPR' ])\n",
    "                         \n",
    "#         if self.localidades=='Todas':\n",
    "#             set_data=self.datos\n",
    "#         else:\n",
    "#             set_data=self.datos.select(PCMDLC=self.localidades)\n",
    "        \n",
    "#         if x_range is None:\n",
    "#             puntos=hv.Points(set_data, ['Longitude', 'Latitude']\n",
    "#                     , ['Texto', 'Cod_CCAA', 'dircompleta' , 'PCMDLC', 'PCMNFC', 'PCMNPR' ])\n",
    "#         else:\n",
    "#             puntos=hv.Points(set_data, ['Longitude', 'Latitude']\n",
    "#                     , ['Texto', 'Cod_CCAA', 'dircompleta' , 'PCMDLC', 'PCMNFC', 'PCMNPR' ])\\\n",
    "#                         .select( longitude= x_range, latitude=y_range )\n",
    "       \n",
    "        return puntos\n",
    "        \n",
    "        #return self.datos\n",
    "    \n",
    "    \n",
    "    \n",
    "    @param.depends('alpha' , watch=True)\n",
    "    def tiles(self):\n",
    "        #self.mapa_fondo=map_tiles.opts(gopts).opts(alpha=self.alpha, **opts1)\n",
    "        #return self.mapa_fondo\n",
    "        return map_tiles.opts(gopts).opts(alpha=self.alpha, framewise=True, **opts1_t)\n",
    "        #return  gv.tile_sources.CartoDark (alpha=self.alpha, framewise=True, **opts1_t)\n",
    "     \n",
    "    @param.depends('muestra_nombres')\n",
    "    def labels(self):\n",
    "        return gts.StamenLabels.options(level='annotation', alpha=1 if self.muestra_nombres else 0)\n",
    "    #si queiero pasar determinados argumentos solo cuando cambien ellos mismos y no onsiderar cualquier\n",
    "    #cambio de cualquier parametro para ahorrar en rendimiento y no calcular todo todas las veces,\n",
    "    #no puedo repetir las dependencias en los procedimiento de cambio y aqui para pintarlo, yaque,\n",
    "    #lo que pasara es que se pintara con el parametro sincambiar antes de que se notifique el cambio\n",
    "    #en el procedimiento de cambio.\n",
    "    \n",
    "    def prepara_grafico(self, **kwargs):\n",
    "        \n",
    "        print( self.name, self.localidades)\n",
    "        if (not self.set_datos.empty):\n",
    "           \n",
    "           \n",
    "#             sombreador=datashade(hv.DynamicMap(self.SeleccionaDatos), cmap=self.param.colormap\n",
    "#                                  ,   streams=[RangeXY()]\n",
    "#                                  , **opts2)\n",
    "\n",
    "            #*********************************************************************************\n",
    "            #En el caso típico de tener conjuntos de datos mucho mayor que la resolución trama, \n",
    "            #HoloViews operaciones que funcionan en el conjunto de datos completo \n",
    "            #Datashader-basa ( rasterize, aggregate, regrid) son computacionalmente caro; \n",
    "            #los otros no lo son ( shade, spread, dynspread, etc.)\n",
    "            #*********************************************************************************\n",
    "            #el precompute=True en este caso hace que las interacciones sean rápidas, sino\n",
    "            #cada vez que mueves el mapa son 25-40 segundos\n",
    "            #*********************************************************************************\n",
    "            #decido no hacer el rasterize, si lo hago piero el etalle de la distincion del color\n",
    "            #que si hace el datashade\n",
    "            \n",
    "            \n",
    "\n",
    "#             rasterized = rasterize(hv.DynamicMap(self.SeleccionaDatos,streams=[self.box])\n",
    "#                                    , aggregator='count'#, aggregator='any'\n",
    "#                                    , width=600  , height=600, precompute=True\n",
    "                                   \n",
    "#                                   )\n",
    "\n",
    "            #opciones para el datashade:\n",
    "            # odict(Histogram_Equalization='eq_hist', Linear='linear', Log='log', Cube_root='cbrt')\n",
    "#             if self.localidades == 'Todas' :\n",
    "#                 pts=hv.DynamicMap(self.SeleccionaDatos, streams=[RangeXY(transient=True)])\\\n",
    "#                     .opts(norm=dict(framewise=True))\n",
    "#             else:\n",
    "#                 pts=hv.DynamicMap(self.SeleccionaDatos, streams=[RangeXY(transient=True)])\\\n",
    "#                     .redim.value(PCMDLC=self.localidades).opts(norm=dict(framewise=True))\n",
    "                \n",
    "\n",
    "            pts=hv.DynamicMap(self.SeleccionaDatos, streams=[RangeXY(transient=True)])\\\n",
    "                    .opts(norm=dict(framewise=True))\n",
    "            shaded     = datashade( pts ,streams=[RangeXY(transient=True)]\n",
    "                                   , cmap=self.param['colormap'] \n",
    "                                   , normalization='eq_hist' \n",
    "                                   )\n",
    "            #spreaded   = spread(shaded, px=3, how=\"add\")#esta opcion sin rasterize previo da error.\n",
    "            spreaded   = dynspread(shaded, threshold=0.7, max_px=self.param.spreading, how='over'   )\n",
    "            dataplot   = spreaded.apply.opts(**opts1)\n",
    "            \n",
    "            \n",
    "#             capa_Quadmesh=(hv.util.Dynamic(hd.aggregate(spreaded, streams=[self.box]), operation=hv.QuadMesh ))\\\n",
    "#                                         .opts(tools=[\"hover\",\"save\", \"undo\", \"redo\"]\n",
    "#                                                , alpha=0  , hover_alpha=0.2, hover_color=\"white\"\n",
    "#                                                , show_legend=False )\n",
    "            final=dataplot * hv.DynamicMap(self.tiles) \\\n",
    "                * hv.DynamicMap(self.labels) #\\\n",
    "                       #* capa_Quadmesh\n",
    "            return final.options(\n",
    "            tools=[\"save\", \"pan\", \"box_zoom\", \"reset\", \"redo\", \"undo\"],\n",
    "            active_tools=[\"box_zoom\"],\n",
    "            width=800,\n",
    "            height=600\n",
    "        )\n",
    "            #return (dataplot * hv.DynamicMap(self.tiles) ) * hv.DynamicMap(self.labels) #\\\n",
    "                       ##* capa_Quadmesh\n",
    "           \n",
    "    \n",
    "       \n",
    "#     def evento(self,  **kwargs):\n",
    "#         print(\"ouputs_class: \", self.param.outputs(), self.param['colormap'] )\n",
    "#         hv.DynamicMap(self.prepara_grafico,  streams=[RangeXY(transient=True)]\n",
    "#                              , cache_size=0).opts(dynamic=False)\n",
    "        \n",
    "#         if not self.param.outputs() or any(k in kwargs for k in ['colormap', 'alpha', 'localidades']):\n",
    "#            hv.DynamicMap(self.prepara_grafico,  streams=[RangeXY(transient=True)]\n",
    "#                              , cache_size=0).opts(dynamic=False)\n",
    "#         else:\n",
    "#             super(ExploraCMedico, self).event(**kwargs)\n",
    "                \n",
    "#         #if not self.output or any(k in kwargs for k in ['colormap', 'alpha']):\n",
    "#         if any(k in kwargs for k in ['colormap', 'alpha']):\n",
    "#             print(\"pasa por no self.output\")\n",
    "#             hv.DynamicMap(self.prepara_grafico, streams=[RangeXY()], cache_size=0)\n",
    "#         else:\n",
    "#             super(ExploraCMedico, self).evento(**kwargs)\n",
    "            \n",
    "\n",
    "explorador=ExploraCMedico(name=\"Situación c.medico Privado y Muface\")\n",
    "#explorador.param._BATCH_PARAM=False\n",
    "#explorador.param.batch_param=True\n",
    "#explorador.transient=True\n",
    "\n",
    "\n",
    "#el truco para que solo coja los cambios del DynamicMap y de self.param... cuando los objetos\n",
    "#cambien, es llamar a la funcion con los parentesis, es decir explorador.prepara_grafico() y no\n",
    "\n",
    "#print(explorador.name, explorador.transient)\n",
    "\n",
    "dashboard=pn.Row(pn.Param(explorador.param, expand_button=False), explorador.prepara_grafico() )\n",
    "    \n",
    "#explorador.event()\n",
    "\n",
    "#la unica forma que he encontrado para recuperar los streams en llamando explorador.evento() post\n",
    "#generacion de la variable dashboar con la llamada a prepara_grafico, si llamo a evento\n",
    "#desde la generacion de la variable dashboard no pinta mas que los parametros el plot no.\n",
    "dashboard.show(websocket_origin='*')    #con esto conseguimos que pueda compartirse desde mi ip, sustituyendo\n",
    "#dashboard\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__\n",
    "\n",
    "#dd.__package__\n",
    "#dd.__spec__\n",
    "#dd.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard[1].pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts RGB {+framewise} \n",
    "#dashboard.show(websocket_origin='*')    #con esto conseguimos que pueda compartirse desde mi ip, sustituyendo\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pba=hv.DynamicMap(gv.Points(use_data_plot, ['Longitude', 'Latitude']))\n",
    "pba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data_plot[['geometry','Texto', 'Cod_CCAA', 'dircompleta' , 'PCMDLC', 'PCMNFC', 'PCMNPR' ]].head()\n",
    "use_data_plot[['Texto', 'Cod_CCAA', 'dircompleta' , 'PCMDLC', 'PCMNFC', 'PCMNPR' ]].describe()\n",
    "use_data_plot[['Texto', 'Cod_CCAA', 'dircompleta' , 'PCMDLC', 'PCMNFC', 'PCMNPR' ]].isna().sum()\n",
    "\n",
    "use_data_plot[['geometry', 'Texto', 'Cod_CCAA', 'dircompleta' , 'PCMDLC', 'PCMNFC', 'PCMNPR' ]].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "opts1=dict(width=600, height=600,xaxis=None, yaxis=None,bgcolor=\"black\")\n",
    "opts2=dict(width=600, height=600,x_sampling=0.00001, y_sampling=0.00001 ,dynamic=False )\n",
    "gopts  = hv.opts.WMTS(responsive=True, xaxis=None, yaxis=None, bgcolor='black', show_grid=False)\n",
    "\n",
    "url = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{Z}/{Y}/{X}.jpg'\n",
    "map_tiles=gv.WMTS(url, crs=crs.GOOGLE_MERCATOR)\n",
    "datos=use_data_plot\n",
    "\n",
    "\n",
    "lst_muni=datos['PCMDLC'].unique()\n",
    "lst_muni=list(lst_muni)\n",
    "lst_muni.sort()\n",
    "lst_muni.insert(0,'Todas')\n",
    "#**********************************************************************************************************\n",
    "#                                           NOTAS TECNICAS:\n",
    "#**********************************************************************************************************\n",
    "#Hay varias formas de notificar los cambios en el panel, aquí vamos a utilizar la 2 y 3 ya que siendo las\n",
    "#más complejas, son las más útiles en cuanto a rendimiento:\n",
    "#1.- dependencias signifcadas con el decorador @pn.depends(...), siempre que cambie alguno de los\n",
    "#parametros significados asi, cambiará el proceso y se ejecutará todo de nuevo\n",
    "#2.-Dependencia de un método para DynamicMap: decoraremos igualmente con @pn.dependes(...), lo que cambia\n",
    "#aqui es que al utilizar DynamicMap, el metodo solo se re-ejecutara cuando cambie algun parametro que\n",
    "#este afectado en este DynamicMap\n",
    "#3.-Argumento instancia-objeto de parametro: proporcionaremos una instancia del objeto param en lugar del\n",
    "#valor asociado a ese parametro, así las dependencias se infieren solo cuando se pasa el objeto completo\n",
    "#y sólo cambiarán o se actualizará cuando el valor cambie.\n",
    "#(*): Los enfoques 2 y 3 se basan en una caracteristica de HoloViews llamada streaming, que admiten muchos\n",
    "#tipos de comportamiento dinámico, además de responder a widgets. Por ejemplo la rasterize operación \n",
    "#adjunta una RangeXY streaming que vuelve a agregar los datos cada vez que cambia la ventana gráfica, lo \n",
    "#mismo ocurre en nuesro ejemplo en la operación de datashade.\n",
    "#**********************************************************************************************************\n",
    "class ExploraCMedico(param.Parameterized):\n",
    "    alpha=param.Magnitude(default=0.5, doc=\"Opacidad mapa\")\n",
    "    colormap=param.ObjectSelector(default=\"fire\", objects=list(cm_n.keys()))\n",
    "    localidades=param.ObjectSelector(default=\"Todas\", objects=lst_muni )\n",
    "    set_datos=use_data_plot\n",
    "    datos=hv.Dataset(use_data_plot[['geometry','Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ]]\n",
    "                 , kdims=['Longitude', 'Latitude']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ])\n",
    "    \n",
    "    #points=hv.Points(datos, ['Longitude', 'Latitude'])\n",
    "    puntos=hv.Points(datos, ['Longitude', 'Latitude']).opts(framewise=True, axiswise=True)\n",
    "    mapa_fondo=map_tiles.opts(gopts).opts(alpha=0.5, **opts1)\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    @param.depends('localidades' , watch=True)\n",
    "    def SeleccionaDatos(self, *events):\n",
    "        print(\"estamos en seleccionDatos\", events, self.params.args)\n",
    "        print(dir( self.param.localidades) )\n",
    "        print(self.param.localidades.__getstate__(), self.param.localidades.watchers)\n",
    "             \n",
    "       \n",
    "        #primero desactivamos cualquier filtro seleccionando todos los valores del indice\n",
    "        #idx_filtros=[True for i in range( datos.shape[0] ) ]\n",
    "        #plantilla para trabajar con mas de un campo a la vez x si lo necesito\n",
    "#         idx_filtros=[p and m and i and j for p, m, i, j in zip( seleccion.Texto == prov\n",
    "#                                                                    , seleccion.NAMEUNIT == muni \n",
    "#                                                                    , seleccion.POB18 >= lim_poblacion[0]\n",
    "#                                                                    , seleccion.POB18 <= max_poblacion)]\n",
    "        self.set_datos=use_data_plot\n",
    "        if self.localidades=='Todas':\n",
    "            idx_filtros=[m  for m in ( self.set_datos['PCMDLC'] ==  self.set_datos['PCMDLC']) ]\n",
    "            self.set_datos = self.set_datos[idx_filtros]\n",
    "        else:\n",
    "            idx_filtros=[m  for m in ( self.set_datos['PCMDLC'] == self.localidades) ]\n",
    "            self.set_datos = self.set_datos[idx_filtros]\n",
    "            \n",
    "        \n",
    "        self.datos=hv.Dataset(self.set_datos[['geometry','Texto', 'Cod_CCAA', 'dircompleta'\n",
    "                                              , 'PCMDLC', 'PCMNFC', 'PCMNPR' ]]\n",
    "                 , kdims=['Longitude', 'Latitude']\n",
    "                 , vdims=['Texto', 'Cod_CCAA', 'dircompleta', 'PCMDLC', 'PCMNFC', 'PCMNPR' ])\n",
    "        \n",
    "        self.puntos=hv.Points(self.datos, ['Longitude', 'Latitude']).opts(framewise=True, axiswise=True)\n",
    "        return self.puntos\n",
    "        \n",
    "        #return self.datos\n",
    "    \n",
    "    \n",
    "    @param.depends('alpha'  , watch=True)\n",
    "    def tiles(self):\n",
    "        self.mapa_fondo=map_tiles.opts(gopts).opts(alpha=self.alpha, **opts1)\n",
    "        print(\"opciones de mapa de fondo en tiles: \", self.mapa_fondo.opts.info())\n",
    "        return self.mapa_fondo\n",
    "    \n",
    "    #si queiero pasar determinados argumentos solo cuando cambien ellos mismos y no onsiderar cualquier\n",
    "    #cambio de cualquier parametro para ahorrar en rendimiento y no calcular todo todas las veces,\n",
    "    #no puedo repetir las dependencias en los procedimiento de cambio y aqui para pintarlo, yaque,\n",
    "    #lo que pasara es que se pintara con el parametro sincambiar antes de que se notifique el cambio\n",
    "    #en el procedimiento de cambio.\n",
    "    @param.depends( 'colormap' )\n",
    "    def prepara_grafico(self, x_range, y_range, **kwargs):\n",
    "        print (\"alfa es \", self.alpha, \"opciones de mapa fondo: \", self.mapa_fondo.opts.info(), x_range, y_range)\n",
    "        if (not self.set_datos.empty):\n",
    "            #print(x_range, y_range,*kwargs)\n",
    "            #print(type  (self.datos) , len(self.set_datos) )\n",
    "            print(\"n filas datos: \" , self.set_datos.shape)\n",
    "            #puntos=hv.Points(self.datos, ['Longitude', 'Latitude']).opts(framewise=True, axiswise=True)\n",
    "            sombreador=datashade(self.puntos, cmap=cm_n[self.colormap], x_range=x_range, y_range=y_range, **opts2)\n",
    "            dsp_sombreador=dynspread(sombreador,threshold=0.8, max_px=5, how='over')\n",
    "            return self.mapa_fondo * dsp_sombreador\n",
    "       \n",
    "    def evento(self, **kwargs):\n",
    "        \n",
    "        return hv.DynamicMap(self.prepara_grafico, streams=[RangeXY()], cache_size=100)\n",
    "\n",
    "explorador=ExploraCMedico(name=\"Situación c.medico Privado y Muface\")\n",
    "explorador.param._BATCH_PARAM=False\n",
    "dashboard=pn.Row(pn.Param(explorador.param, expand_button=False), explorador.evento() )\n",
    "\n",
    "#dashboard.show(websocket_origin='*')    #con esto conseguimos que pueda compartirse desde mi ip, sustituyendo\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paramnb\n",
    "hv.extension('bokeh', logo=False)\n",
    "pn.extension()\n",
    "\n",
    "map_tiles=   gv.tile_sources.ESRI \n",
    "opts1=dict(width=600, height=600,xaxis=None, yaxis=None,bgcolor=\"black\")\n",
    "opts2=dict(width=600, height=600,x_sampling=0.00001, y_sampling=0.00001 ,dynamic=False)\n",
    "url = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{Z}/{Y}/{X}.jpg'\n",
    "map_tiles=gv.WMTS(url, crs=crs.GOOGLE_MERCATOR)\n",
    "\n",
    "class ExploraCMedico(hv.streams.Stream):\n",
    "    alpha=param.Magnitude(default=0.5, doc=\"Opacidad mapa\")\n",
    "    colormap=param.ObjectSelector(default=\"fire\", objects=list(cm_n.keys()))\n",
    "   \n",
    "    #output = parambokeh.view.Plot()\n",
    "    \n",
    "    def prepara_grafico(self, x_range, y_range, **kwargs):\n",
    "        print(x_range, y_range,*kwargs)\n",
    "        tiles=map_tiles.options(alpha=self.alpha, **opts1)\n",
    "        points=hv.Points(use_data_plot, ['Longitude', 'Latitude'])\n",
    "        return tiles * datashade(points, cmap=cm_n[self.colormap], x_range=x_range, y_range=y_range, **opts2)\n",
    "    def evento(self, **kwargs):\n",
    "        \n",
    "        hv.DynamicMap(self.prepara_grafico, streams=[RangeXY()], cache_size=0)\n",
    "    \n",
    "#         #if not self.output or any(k in kwargs for k in ['colormap', 'alpha']):\n",
    "#         if any(k in kwargs for k in ['colormap', 'alpha']):\n",
    "#             print(\"pasa por no self.output\")\n",
    "#             hv.DynamicMap(self.prepara_grafico, streams=[RangeXY()], cache_size=0)\n",
    "#         else:\n",
    "#             super(ExploraCMedico, self).evento(**kwargs)\n",
    "            \n",
    "        \n",
    "       \n",
    "   \n",
    "    \n",
    "explorador=ExploraCMedico(name=\"Situación cuadro médico muface y privado\")\n",
    "dmap3=hv.DynamicMap(explorador.prepara_grafico, streams=[explorador, RangeXY()])\n",
    "\n",
    "plot3=hv.renderer('bokeh').get_plot(dmap3).state #para verlo aqui y que se ejecute el callback prepara_grafico\n",
    "#hay que quitar la ocpion instance(mode='server'), esto seria si lo ejecutasemos en un servidor de bokeh\n",
    "\n",
    "\n",
    "# paramnb.Widgets(explorador, callback=explorador.event, continuous_update=True)\n",
    "pn.Row(explorador, explorador.event,plot3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.document import Document\n",
    "hv.notebook_extension('bokeh')\n",
    "\n",
    "class StyleOptions(hv.streams.Stream):\n",
    "\n",
    "    alpha = param.Magnitude(default=0.8)\n",
    "    \n",
    "    color = param.ObjectSelector(default='red', objects=['red', 'green', 'blue'])\n",
    "    \n",
    "    line_width = param.Number(default=1, bounds=(0, 10)) \n",
    "    \n",
    "    \n",
    "    \n",
    "viewer = StyleOptions()\n",
    "curve = hv.Curve(np.sin(np.linspace(0, np.pi*3, 100)))\n",
    "dmap = hv.DynamicMap(lambda **kwargs: curve.opts(style=kwargs), streams=[viewer])\n",
    "\n",
    "# Get bokeh model for the plot\n",
    "plot = hv.renderer('bokeh').get_plot(dmap, doc=Document())\n",
    "\n",
    "parambokeh.Widgets(viewer, callback=viewer.event, view_position='right',\n",
    "                   continuous_update=True, plots=[plot])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(pn.widgets.Widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opts = hv.Store.options(backend='bokeh')\n",
    "hv.core.options.OptionTree(opts.items()[0:10], groups=['plot', 'style', 'norm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts2=dict(width=600, height=600,x_sampling=0.00001, y_sampling=0.00001 ,dynamic=False)\n",
    "opts3=dict(width=600, height=600, tools=[\"hover\"])\n",
    "class ExploraCMedico2(hv.streams.Stream):\n",
    "    alpha=param.Magnitude(default=0.5, doc=\"Opacidad mapa\")\n",
    "    colormap=param.ObjectSelector(default=\"fire\", objects=list(cm_n.keys()), instantiate=True)\n",
    "    ckecking=param.ObjectSelector(default=1, objects=[1,2,3])\n",
    "    output = parambokeh.view.Plot()\n",
    "    \n",
    "    \n",
    "    def prepara_grafico2(self, x_range=None, y_range=None, **kwargs):\n",
    "        print(x_range, y_range)\n",
    "        tiles=map_tiles.options(alpha=self.alpha, **opts1)\n",
    "        points=hv.Points(use_data_plot, kdims= ['Longitude', 'Latitude'])\n",
    "        return tiles * datashade(points, cmap=cm_n[self.colormap], x_range=x_range, y_range=y_range, **opts2)\n",
    "       \n",
    "#         return (points* tiles).opts(\n",
    "#             opts.Points(cmap=cm_n[self.colormap], **opts3)\n",
    "#             ,opts.Layout(shared_axes=True)\n",
    "#          )\n",
    "    \n",
    "    def evento(self, **kwargs):\n",
    "        #if not self.output or any(k in kwargs for k in ['colormap', 'alpha']):\n",
    "        print(self.output)\n",
    "        if not self.output or any(k in kwargs for k in ['colormap', 'alpha']):\n",
    "            print(\"pasa por no self.output\")\n",
    "            self.output=prepara_grafico2\n",
    "        else:\n",
    "            super(ExploraCMedico2, self).event(**kwargs)\n",
    "            \n",
    "explorador2=ExploraCMedico2(name=\"Situación cuadro médico muface y privado\")\n",
    "dmap3=hv.DynamicMap(explorador2.prepara_grafico2, streams=[explorador2, RangeXY()])  \n",
    "plot2=hv.renderer('bokeh').get_plot(dmap3)#para verlo aqui y que se ejecute el callback prepara_grafico\n",
    "#hay que quitar la ocpion instance(mode='server'), esto seria si lo ejecutasemos en un servidor de bokeh\n",
    "print(plot2.state)\n",
    "#pn.Row(explorador2, pn.Column( explorador2.event ,plot2.state))\n",
    "parambokeh.Widgets(explorador2, callback=explorador2.event,  on_init=True, view_position='right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cm_n.keys() )\n",
    "list(cm_n.values())\n",
    "\n",
    "class BaseClass(param.Parameterized):\n",
    "    x                       = param.Parameter(default=3.14, doc=\"X position\")\n",
    "    y                       = param.Parameter(default=\"Not editable\", constant=True)\n",
    "    string_value            = param.String(default=\"str\", doc=\"A string\")\n",
    "    num_int                 = param.Integer(50000, bounds=(-200, 100000))\n",
    "    unbounded_int           = param.Integer(23)\n",
    "    float_with_hard_bounds  = param.Number(8.2, bounds=(7.5, 10))\n",
    "    float_with_soft_bounds  = param.Number(0.5, bounds=(0, None), softbounds=(0,2))\n",
    "    unbounded_float         = param.Number(30.01, precedence=0)\n",
    "    hidden_parameter        = param.Number(2.718, precedence=-1)\n",
    "    integer_range           = param.Range(default=(3, 7), bounds=(0, 10))\n",
    "    float_range             = param.Range(default=(0, 1.57), bounds=(0, 3.145))\n",
    "    dictionary              = param.Dict(default={\"a\": 2, \"b\": 9})\n",
    "    colormap=param.ObjectSelector(default=\"fire\", objects=list(cm_n.keys()))\n",
    "    select_fn               = param.ObjectSelector(default=list,objects=[list, set, dict])\n",
    "\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "base = BaseClass()\n",
    "pn.Row( base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{Z}/{Y}/{X}.jpg'\n",
    "map_tiles=gv.WMTS(url, crs=crs.GOOGLE_MERCATOR)\n",
    "help(map_tiles.opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Notas\n",
    "\n",
    "#dmap.opts(active_tools=['wheel_zoom'])\n",
    "renderer = hv.renderer('bokeh')\n",
    "layout_plot = renderer.get_plot(dmap)\n",
    "print(layout_plot)\n",
    "print(dir(layout_plot))\n",
    "print(type(layout_plot.tools), type(layout_plot.toolbar))\n",
    "layout_plot._ElementPlot__params\n",
    "at=layout_plot._ElementPlot__params['active_tools']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "at.bounds\n",
    "print(at.constant, at.default, at.name, at.label, at.allow_None)\n",
    "print(dir(at))\n",
    "#help(at)\n",
    "at.doc\n",
    "print(dmap.opts.info())\n",
    "mipath=hv.Path(dmap)\n",
    "hv.output(backend='bokeh')\n",
    "#hv.output(dmap)\n",
    "hv.output.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si quiero trabajar con tools y activar ganchos para manejarlas, aqui tengo info:\n",
    "#https://stackoverflow.com/questions/50415434/how-to-set-active-tools-in-holoviews/50416512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_parquet_kwargs = {\"engine\": \"pyarrow\",\n",
    "                   \"compression\": \"snappy\",\n",
    "                   \"index\": False}\n",
    "\n",
    "#pbaCoord.to_parquet(\"clientes_muface_zaragoza.parquet\", **_parquet_kwargs)\n",
    "\n",
    "#dcm = dd.read_parquet('clientes_muface_zaragoza.parquet')\n",
    "dcm = pd.read_parquet('clientes_muface_zaragoza.parquet')\n",
    "table = pa.Table.from_pandas(dcm)\n",
    "#print(table.schema)\n",
    "print( dcm.loc[dcm['estado_gmaps']=='OK'].shape[0] , ' coordenadas obtenidas frente a un total de: ', dcm.shape[0] )\n",
    "#dcm.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#PLANTILLA PARA GUARDAR DATOS EN BLOQUE EN ARCHIVO PARQUET\n",
    "chunksize=10000 # es el número de lineas que queremos leer por bloque de datos\n",
    "\n",
    "pqwriter = None\n",
    "for i, df in enumerate(pd.read_csv('sample.csv', chunksize=chunksize)):\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    # en el primer bloque abrimos pqwriter.\n",
    "    if i == 0:\n",
    "        # create a parquet write object giving it an output file\n",
    "        pqwriter = pq.ParquetWriter('sample.parquet', table.schema)\n",
    "        pqwriter.write_table(table)\n",
    "    # subsequent chunks can be written to the same file\n",
    "    else:\n",
    "        pqwriter.write_table(table)\n",
    "\n",
    "# close the parquet writer\n",
    "if pqwriter:\n",
    "    pqwriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_cm.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset=0.5\n",
    "pts=300\n",
    "blues = (np.random.normal( offset,size=pts), np.random.normal( offset,size=pts), -1 * np.ones((pts)))\n",
    "hv.Points(blues, vdims=['c']).opts(color=dim('c'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(dim) #dim es para normalizar los datos o categorizarlos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
